{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Plugboard is an event-driven modelling and orchestration framework in Python for simulating and driving complex processes with many interconnected stateful components.</p> <p>You can use it to define models in Python and connect them together easily so that data automatically moves between them. After running your model on a laptop, you can then scale out on multiple processors, or go to a compute cluster in the cloud.</p> <p>Some examples of what you can build with Plugboard include:</p> <ul> <li>Digital twin models of complex processes:<ul> <li>It can easily handle common problems in industrial process simulation like material recirculation;</li> <li>Models can be composed from different underlying components, e.g. physics-based simulations, machine-learning, AI models;</li> </ul> </li> <li>AI integrations:<ul> <li>You can feed data to/from different LLMs using Plugboard components;</li> <li>Easily reconfigure and swap model providers for optimal performance.</li> </ul> </li> </ul>"},{"location":"#key-features","title":"\ud83d\udd8b\ufe0f Key Features","text":"<ul> <li>Reusable classes containing the core framework, which you can extend to define your own model logic;</li> <li>Support for different simulation paradigms: discrete time and event based.</li> <li>YAML model specification format for saving model definitions, allowing you to run the same model locally or in cloud infrastructure;</li> <li>A command line interface for executing models;</li> <li>Built to handle the data intensive simulation requirements of industrial process applications;</li> <li>Modern implementation with Python 3.12 and above based around asyncio with complete type annotation coverage;</li> <li>Built-in integrations for loading/saving data from cloud storage and SQL databases;</li> <li>Detailed logging of component inputs, outputs and state for monitoring and process mining or surrogate modelling use-cases.</li> </ul>"},{"location":"#installation","title":"\ud83d\udd0c Installation","text":"<p>Plugboard requires Python &gt;= 3.12. Install the package with pip inside a virtual env as below. <pre><code>python -m pip install plugboard\n</code></pre></p> <p>Optional integrations for different cloud providers can be installed using <code>plugboard[aws]</code>, <code>plugboard[azure]</code> or <code>plugboard[gcp]</code>.</p> <p>Support for parallelisation can be installed using <code>plugboard[ray]</code>.</p>"},{"location":"#usage","title":"\ud83d\ude80 Usage","text":"<p>Plugboard is built to help you with two things: defining process models, and executing those models. There are two main ways to interact with plugboard: via the Python API; or, via the CLI using model definitions saved in yaml format.</p>"},{"location":"#building-models-with-the-python-api","title":"Building models with the Python API","text":"<p>A model is made up of one or more components, though Plugboard really shines when you have many! First we start by defining the <code>Component</code>s within our model. Components can have only inputs, only outputs, or both. To keep it simple we just have two components here, showing the most basic functionality. Each component has several methods which are called at different stages during model execution: <code>init</code> for optional initialisation actions; <code>step</code> to take a single step forward through time; <code>run</code> to execute all steps; and <code>destroy</code> for optional teardown actions. <pre><code>import typing as _t\nfrom plugboard.component import Component, IOController as IO\nfrom plugboard.schemas import ComponentArgsDict\n\nclass A(Component):\n    io = IO(outputs=[\"out_1\"])\n\n    def __init__(self, iters: int, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._iters = iters\n\n    async def init(self) -&gt; None:\n        self._seq = iter(range(self._iters))\n\n    async def step(self) -&gt; None:\n        try:\n            self.out_1 = next(self._seq)\n        except StopIteration:\n            await self.io.close()\n\n\nclass B(Component):\n    io = IO(inputs=[\"in_1\"])\n\n    def __init__(self, path: str, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._path = path\n\n    async def init(self) -&gt; None:\n        self._f = open(self._path, \"w\")\n\n    async def step(self) -&gt; None:\n        out = 2 * self.in_1\n        self._f.write(f\"{out}\\n\")\n\n    async def destroy(self) -&gt; None:\n        self._f.close()\n</code></pre></p> <p>Now we take these components, connect them up as a <code>Process</code>, and fire off the model. Using the <code>Process</code> context handler takes care of calling <code>init</code> at the beginning and <code>destroy</code> at the end for all <code>Component</code>s. Calling <code>Process.run</code> triggers all the components to start iterating through all their inputs until a termination condition is reached. Simulations proceed in an event-driven manner: when inputs arrive, the components are triggered to step forward in time. The framework handles the details of the inter-component communication, you just need to specify the logic of your components, and the connections between them. <pre><code>from plugboard.connector import AsyncioConnector\nfrom plugboard.process import LocalProcess\nfrom plugboard.schemas import ConnectorSpec\n\nprocess = LocalProcess(\n    components=[A(name=\"component-a\", iters=5), B(name=\"component-b\", path=\"b.txt\")],\n    connectors=[\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"component-a.out_1\", target=\"component-b.in_1\"),\n        )\n    ],\n)\nasync with process:\n    await process.run()\n</code></pre></p> <p>Visually, we've created the model below, with Plugboard automatically handling the flow of data between the two components. <pre><code>flowchart LR\n  component-a@{ shape: rounded, label: A&lt;br&gt;**component-a** } --&gt; component-b@{ shape: rounded, label: B&lt;br&gt;**component-b** }</code></pre></p>"},{"location":"#executing-pre-defined-models-on-the-cli","title":"Executing pre-defined models on the CLI","text":"<p>In many cases, we want to define components once, with suitable parameters, and then use them repeatedly in different simulations. Plugboard enables this workflow with model specification files in yaml format. Once the components have been defined, the simple model above can be represented as follows. <pre><code># my-model.yaml\nplugboard:\n  process:\n    args:\n      components:\n      - type: hello_world.A\n        args:\n          name: \"component-a\"\n          iters: 10\n      - type: hello_world.B\n        args:\n          name: \"component-b\"\n          path: \"./b.txt\"\n      connectors:\n      - source: \"component-a.out_1\"\n        target: \"component-b.in_1\"\n</code></pre></p> <p>We can now run this model using the plugboard CLI with the command: <pre><code>plugboard process run my-model.yaml\n</code></pre></p>"},{"location":"#documentation","title":"\ud83d\udcd6 Documentation","text":"<p>For more information including a detailed API reference and step-by-step usage examples, refer to the documentation site. We recommend diving into the tutorials for a step-by-step to getting started.</p>"},{"location":"#roadmap","title":"\ud83d\udc3e Roadmap","text":"<p>Plugboard is under active development, with new features in the works:</p> <ul> <li>Support for strongly typed data messages and validation based on pydantic.</li> <li>Support for different parallelisation patterns such as: single-threaded with coroutines, single-host multi process, or distributed with Ray in Kubernetes.</li> <li>Data exchange between components with popular messaging technologies like RabbitMQ and Google Pub/Sub.</li> <li>Support for different message exchange patterns such as: one-to-one, one-to-many, many-to-one etc via a broker; or peer-to-peer with http requests.</li> </ul>"},{"location":"#contributions","title":"\ud83d\udc4b Contributions","text":"<p>Contributions are welcomed and warmly received! For bug fixes and smaller feature requests feel free to open an issue on this repo. For any larger changes please get in touch with us to discuss first. More information for developers can be found in the contributing section of the docs.</p>"},{"location":"#licence","title":"\u2696\ufe0f Licence","text":"<p>Plugboard is offered under the Apache 2.0 Licence so it's free for personal or commercial use within those terms.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for your interest in Plugboard. Contributions are welcomed and warmly received! For bug fixes and smaller feature requests feel free to open an issue on our Github repo. For any larger changes please get in touch with us to discuss first.</p>"},{"location":"contributing/#pr-process","title":"\ud83d\ude3b PR process","text":"<p>We use Conventional Commits on our main branch, so prefix your pull request titles with a commit type: <code>feat</code>, <code>fix</code>, <code>chore</code>, etc.</p>"},{"location":"contributing/#development-setup","title":"\ud83d\udcbb Development setup","text":"<p>For small changes or to get up-and-running quickly, we recommend GitHub codespaces, which provides you with a ready-to-use development environment.</p> <p>For local development we recommend VSCode.</p>"},{"location":"contributing/#python-dependencies","title":"Python dependencies","text":"<p>Dependencies are managed using uv. Install the project using <pre><code>uv sync --all-extras --group test --group docs\n</code></pre></p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>Tests are run in pytest, which you can run with <pre><code>uv run pytest .\n</code></pre></p>"},{"location":"contributing/#linting","title":"Linting","text":"<p>We use ruff for code formatting and style. Install the pre-commit hook by running <pre><code>uv run pre-commit install\n</code></pre></p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>The package documentation uses Material for MkDocs and can be viewed locally by running <pre><code>uv run mkdocs serve\n</code></pre></p>"},{"location":"api/component/component/","title":"component","text":"<p>Component submodule providing functionality related to components and their execution.</p>"},{"location":"api/component/component/#plugboard.component.Component","title":"Component","text":"<pre><code>Component(\n    *,\n    name: str,\n    initial_values: Optional[dict[str, Iterable]] = None,\n    parameters: Optional[dict] = None,\n    state: Optional[StateBackend] = None,\n    constraints: Optional[dict] = None,\n)\n</code></pre> <p>               Bases: <code>ABC</code>, <code>ExportMixin</code></p> <p><code>Component</code> base class for all components in a process model.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>The name of the component.</p> <code>io</code> <code>IOController</code> <p>The <code>IOController</code> for the component, specifying inputs, outputs, and events.</p> <code>exports</code> <code>Optional[list[str]]</code> <p>Optional; The exportable fields from the component during distributed runs in addition to input and output fields.</p>"},{"location":"api/component/component/#plugboard.component.Component.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Unique ID for <code>Component</code>.</p>"},{"location":"api/component/component/#plugboard.component.Component.state","title":"state  <code>property</code>","text":"<pre><code>state: Optional[StateBackend]\n</code></pre> <p>State backend for the process.</p>"},{"location":"api/component/component/#plugboard.component.Component.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(key: str, value: Any) -&gt; None\n</code></pre> <p>Sets attributes on the component.</p> <p>If the attribute is an input field, it is set in the field input buffer for the current step. This data is consumed by the <code>step</code> method when it is called and must be reset for subsequent steps.</p>"},{"location":"api/component/component/#plugboard.component.Component.connect_state","title":"connect_state  <code>async</code>","text":"<pre><code>connect_state(state: Optional[StateBackend] = None) -&gt; None\n</code></pre> <p>Connects the <code>Component</code> to the <code>StateBackend</code>.</p>"},{"location":"api/component/component/#plugboard.component.Component.destroy","title":"destroy  <code>async</code>","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Performs tear-down actions for <code>Component</code>.</p>"},{"location":"api/component/component/#plugboard.component.Component.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Performs component initialisation actions.</p>"},{"location":"api/component/component/#plugboard.component.Component.run","title":"run  <code>async</code>","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Executes component logic for all steps to completion.</p>"},{"location":"api/component/component/#plugboard.component.Component.step","title":"step  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Executes component logic for a single step.</p>"},{"location":"api/component/component/#plugboard.component.IOController","title":"IOController","text":"<pre><code>IOController(\n    inputs: Optional[Any] = None,\n    outputs: Optional[Any] = None,\n    initial_values: Optional[dict[str, Iterable]] = None,\n    input_events: Optional[list[Type[Event]]] = None,\n    output_events: Optional[list[Type[Event]]] = None,\n    namespace: str = IO_NS_UNSET,\n    component: Optional[Component] = None,\n)\n</code></pre> <p><code>IOController</code> manages input/output to/from components.</p>"},{"location":"api/component/component/#plugboard.component.IOController.is_closed","title":"is_closed  <code>property</code>","text":"<pre><code>is_closed: bool\n</code></pre> <p>Returns <code>True</code> if the <code>IOController</code> is closed, <code>False</code> otherwise.</p>"},{"location":"api/component/component/#plugboard.component.IOController.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes all input/output channels.</p>"},{"location":"api/component/component/#plugboard.component.IOController.connect","title":"connect  <code>async</code>","text":"<pre><code>connect(connectors: list[Connector]) -&gt; None\n</code></pre> <p>Connects the input/output fields to input/output channels.</p>"},{"location":"api/component/component/#plugboard.component.IOController.queue_event","title":"queue_event","text":"<pre><code>queue_event(event: Event) -&gt; None\n</code></pre> <p>Queues an event for output.</p>"},{"location":"api/component/component/#plugboard.component.IOController.read","title":"read  <code>async</code>","text":"<pre><code>read() -&gt; None\n</code></pre> <p>Reads data and/or events from input channels.</p> <p>Read behaviour is dependent on the specific combination of input fields, output fields, and input events. In general, all components will have at a minimum the system defined input events, such as <code>StopEvent</code>. Logic for the various cases is as follows:</p> <ul> <li>At least one input field: the method waits until either all input fields have received   data or an input event is received, and returns after whichever occurs first.</li> <li>No input fields but at least one output field: the method waits for a short amount of   time to give chance for input events to be received before returning so that the control   flow can continue on to processing output events.</li> <li>No input fields or output fields: this is the pure event driven case where the method   waits until an input event is received, and returns after the first received event.</li> </ul>"},{"location":"api/component/component/#plugboard.component.IOController.write","title":"write  <code>async</code>","text":"<pre><code>write() -&gt; None\n</code></pre> <p>Writes data to output channels.</p>"},{"location":"api/connector/connector/","title":"connector","text":"<p>Connector submodule providing functionality related to component connectors and data exchange.</p>"},{"location":"api/connector/connector/#plugboard.connector.Connector","title":"Connector","text":"<pre><code>Connector(spec: ConnectorSpec, *args: Any, **kwargs: Any)\n</code></pre> <p>               Bases: <code>ABC</code>, <code>ExportMixin</code></p> <p><code>Connector</code> provides <code>Channel</code>s for communication between a specified source and target.</p>"},{"location":"api/connector/connector/#plugboard.connector.Connector.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Unique ID for <code>Connector</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.Connector.connect_recv","title":"connect_recv  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>connect_recv() -&gt; Channel\n</code></pre> <p>Returns a <code>Channel</code> for receiving messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.Connector.connect_send","title":"connect_send  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>connect_send() -&gt; Channel\n</code></pre> <p>Returns a <code>Channel</code> for sending messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.Channel","title":"Channel","text":"<pre><code>Channel(\n    *args: Any, maxsize: int = CHAN_MAXSIZE, **kwargs: Any\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p><code>Channel</code> defines an interface for data communication.</p> <p>Initialises the <code>Channel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>maxsize</code> <code>int</code> <p>Optional; The message capacity of the <code>Channel</code>.</p> <code>CHAN_MAXSIZE</code>"},{"location":"api/connector/connector/#plugboard.connector.Channel.is_closed","title":"is_closed  <code>property</code>","text":"<pre><code>is_closed: bool\n</code></pre> <p>Returns <code>True</code> if the <code>Channel</code> is closed, <code>False</code> otherwise.</p> <p>When a <code>Channel</code> is closed, it can no longer be used to send messages, though there may still be some messages waiting to be read.</p>"},{"location":"api/connector/connector/#plugboard.connector.Channel.maxsize","title":"maxsize  <code>property</code>","text":"<pre><code>maxsize: int\n</code></pre> <p>Returns the message capacity of the <code>Channel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.Channel.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the <code>Channel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.Channel.recv","title":"recv  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>recv() -&gt; _t.Any\n</code></pre> <p>Receives an item from the <code>Channel</code> and returns it.</p>"},{"location":"api/connector/connector/#plugboard.connector.Channel.send","title":"send  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>send(msg: Any) -&gt; None\n</code></pre> <p>Sends an item through the <code>Channel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>Any</code> <p>The item to be sent through the <code>Channel</code>.</p> required"},{"location":"api/connector/connector/#plugboard.connector.AsyncioConnector","title":"AsyncioConnector","text":"<pre><code>AsyncioConnector(\n    *args: Any, maxsize: int = CHAN_MAXSIZE, **kwargs: Any\n)\n</code></pre> <p>               Bases: <code>Connector</code></p> <p><code>AsyncioConnector</code> connects components using <code>AsyncioChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.AsyncioConnector.connect_recv","title":"connect_recv  <code>async</code>","text":"<pre><code>connect_recv() -&gt; AsyncioChannel\n</code></pre> <p>Returns an <code>AsyncioChannel</code> for receiving messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.AsyncioConnector.connect_send","title":"connect_send  <code>async</code>","text":"<pre><code>connect_send() -&gt; AsyncioChannel\n</code></pre> <p>Returns an <code>AsyncioChannel</code> for sending messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.AsyncioChannel","title":"AsyncioChannel","text":"<pre><code>AsyncioChannel(\n    *args: Any,\n    maxsize: int = CHAN_MAXSIZE,\n    queue: Optional[Queue] = None,\n    subscribers: Optional[set[Queue]] = None,\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>Channel</code></p> <p><code>AsyncioChannel</code> enables async data exchange between coroutines on the same host.</p> <p>Instantiates <code>AsyncioChannel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>maxsize</code> <code>int</code> <p>Optional; Queue maximum item capacity.</p> <code>CHAN_MAXSIZE</code> <code>queue</code> <code>Optional[Queue]</code> <p>Optional; asyncio.Queue to use for data exchange.</p> <code>None</code> <code>subscribers</code> <code>Optional[set[Queue]]</code> <p>Optional; Set of output asyncio.Queues in pubsub mode.</p> <code>None</code>"},{"location":"api/connector/connector/#plugboard.connector.AsyncioChannel.recv","title":"recv  <code>async</code>","text":"<pre><code>recv() -&gt; _t.Any\n</code></pre> <p>Returns an item received from the <code>Channel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.AsyncioChannel.send","title":"send  <code>async</code>","text":"<pre><code>send(item: Any) -&gt; None\n</code></pre> <p>Sends an item through the <code>Channel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.SerdeChannel","title":"SerdeChannel","text":"<pre><code>SerdeChannel(\n    *args: Any, maxsize: int = CHAN_MAXSIZE, **kwargs: Any\n)\n</code></pre> <p>               Bases: <code>Channel</code>, <code>ABC</code></p> <p><code>SerdeChannel</code> base class for channels that use serialised messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.SerdeChannel.recv","title":"recv  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>recv() -&gt; bytes\n</code></pre> <p>Receives a serialised message from the <code>Channel</code> and returns it.</p> <p>Note: Receiving data involves an unpickling deserialisation step. There are security implications to consider when unpickling data. It is assumed that data received through a channel is trusted.</p>"},{"location":"api/connector/connector/#plugboard.connector.SerdeChannel.send","title":"send  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>send(msg: bytes) -&gt; None\n</code></pre> <p>Sends an serialised message through the <code>Channel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>bytes</code> <p>The message to be sent through the <code>Channel</code>.</p> required"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQConnector","title":"RabbitMQConnector","text":"<pre><code>RabbitMQConnector(*args: Any, **kwargs: Any)\n</code></pre> <p>               Bases: <code>Connector</code></p> <p><code>RabbitMQConnector</code> connects components via RabbitMQ AMQP broker.</p> <p>Uses exclusive queues for pub-sub mode to ensure that each subscriber receives its own copy of each message. In direct mode, uses a single queue for all subscribers, allowing them to share the same messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQConnector.connect_recv","title":"connect_recv  <code>async</code>","text":"<pre><code>connect_recv(\n    rabbitmq_conn: AbstractRobustConnection = Provide[\n        DI.rabbitmq_conn\n    ],\n) -&gt; RabbitMQChannel\n</code></pre> <p>Returns a <code>RabbitMQ</code> channel for receiving messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQConnector.connect_send","title":"connect_send  <code>async</code>","text":"<pre><code>connect_send(\n    rabbitmq_conn: AbstractRobustConnection = Provide[\n        DI.rabbitmq_conn\n    ],\n) -&gt; RabbitMQChannel\n</code></pre> <p>Returns a <code>RabbitMQ</code> channel for sending messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQChannel","title":"RabbitMQChannel","text":"<pre><code>RabbitMQChannel(\n    *args: Any,\n    send_exchange: Optional[AbstractExchange] = None,\n    recv_queue: Optional[AbstractQueue] = None,\n    topic: str = \"\",\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>SerdeChannel</code></p> <p><code>RabbitMQChannel</code> for sending and receiving messages via RabbitMQ AMQP broker.</p> <p>Instantiates a <code>RabbitMQChannel</code>.</p> <p>Uses RabbitMQ AMQP message broker to provide communication between components on different processes. Requires a RabbitMQ broker to be running with the url (and credentials if required) set in the <code>RABBITMQ_URL</code> environment variable.</p> <p>Parameters:</p> Name Type Description Default <code>send_exchange</code> <code>Optional[AbstractExchange]</code> <p>Optional; The RabbitMQ exchange for sending messages.</p> <code>None</code> <code>recv_queue</code> <code>Optional[AbstractQueue]</code> <p>Optional; The RabbitMQ queue for receiving messages.</p> <code>None</code> <code>topic</code> <code>str</code> <p>Optional; The topic for the <code>RabbitMQChannel</code>, defaults to an empty string. Only relevant in the case of pub-sub mode channels.</p> <code>''</code>"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQChannel.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the <code>RabbitMQChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQChannel.recv","title":"recv  <code>async</code>","text":"<pre><code>recv() -&gt; bytes\n</code></pre> <p>Receive a message from the RabbitMQ channel.</p>"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQChannel.send","title":"send  <code>async</code>","text":"<pre><code>send(msg: bytes) -&gt; None\n</code></pre> <p>Send a message to the RabbitMQ channel.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayConnector","title":"RayConnector","text":"<pre><code>RayConnector(*args: Any, **kwargs: Any)\n</code></pre> <p>               Bases: <code>Connector</code></p> <p><code>RayConnector</code> connects components using <code>RayChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayConnector.connect_recv","title":"connect_recv  <code>async</code>","text":"<pre><code>connect_recv() -&gt; RayChannel\n</code></pre> <p>Returns a <code>RayChannel</code> for receiving messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayConnector.connect_send","title":"connect_send  <code>async</code>","text":"<pre><code>connect_send() -&gt; RayChannel\n</code></pre> <p>Returns a <code>RayChannel</code> for sending messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayChannel","title":"RayChannel","text":"<pre><code>RayChannel(\n    actor_options: Optional[dict] = None, **kwargs: Any\n)\n</code></pre> <p>               Bases: <code>Channel</code></p> <p><code>RayChannel</code> enables async data exchange between coroutines on a Ray cluster.</p> <p>Instantiates <code>RayChannel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>actor_options</code> <code>Optional[dict]</code> <p>Optional; Options to pass to the Ray actor. Defaults to {\"num_cpus\": 0}.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to the the underlying <code>Channel</code>.</p> <code>{}</code>"},{"location":"api/connector/connector/#plugboard.connector.RayChannel.is_closed","title":"is_closed  <code>property</code>","text":"<pre><code>is_closed: bool\n</code></pre> <p>Returns <code>True</code> if the <code>RayChannel</code> is closed, <code>False</code> otherwise.</p> <p>When a <code>RayChannel</code> is closed, it can no longer be used to send messages, though there may still be some messages waiting to be read.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayChannel.maxsize","title":"maxsize  <code>property</code>","text":"<pre><code>maxsize: int\n</code></pre> <p>Returns the message capacity of the <code>RayChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayChannel.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the <code>RayChannel</code> and terminates the underlying actor.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayChannel.recv","title":"recv  <code>async</code>","text":"<pre><code>recv() -&gt; _t.Any\n</code></pre> <p>Returns an item received from the <code>RayChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayChannel.send","title":"send  <code>async</code>","text":"<pre><code>send(item: Any) -&gt; None\n</code></pre> <p>Sends an item through the <code>RayChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQConnector","title":"ZMQConnector","text":"<pre><code>ZMQConnector(\n    *args: Any,\n    settings: Settings = Provide[DI.settings],\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>_ZMQConnector</code></p> <p><code>ZMQConnector</code> connects components using <code>ZMQChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQConnector.zmq_address","title":"zmq_address  <code>property</code>","text":"<pre><code>zmq_address: str\n</code></pre> <p>The ZMQ address used for communication.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQConnector.connect_recv","title":"connect_recv  <code>async</code>","text":"<pre><code>connect_recv() -&gt; ZMQChannel\n</code></pre> <p>Returns a <code>ZMQChannel</code> for receiving messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQConnector.connect_send","title":"connect_send  <code>async</code>","text":"<pre><code>connect_send() -&gt; ZMQChannel\n</code></pre> <p>Returns a <code>ZMQChannel</code> for sending messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQChannel","title":"ZMQChannel","text":"<pre><code>ZMQChannel(\n    *args: Any,\n    send_socket: Optional[Socket] = None,\n    recv_socket: Optional[Socket] = None,\n    topic: str = \"\",\n    maxsize: int = 2000,\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>SerdeChannel</code></p> <p><code>ZMQChannel</code> enables data exchange between processes using ZeroMQ.</p> <p>Instantiates <code>ZMQChannel</code>.</p> <p>Uses ZeroMQ to provide communication between components on different processes. Note that maxsize is not a hard limit because the operating system will buffer TCP messages before they reach the channel. <code>ZMQChannel</code> provides better performance than <code>RayChannel</code>, but is only suitable for use on a single host. For multi-host communication, use <code>RayChannel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>send_socket</code> <code>Optional[Socket]</code> <p>Optional; The ZeroMQ socket for sending messages.</p> <code>None</code> <code>recv_socket</code> <code>Optional[Socket]</code> <p>Optional; The ZeroMQ socket for receiving messages.</p> <code>None</code> <code>topic</code> <code>str</code> <p>Optional; The topic for the <code>ZMQChannel</code>, defaults to an empty string. Only relevant in the case of pub-sub mode channels.</p> <code>''</code> <code>maxsize</code> <code>int</code> <p>Optional; Queue maximum item capacity, defaults to 2000.</p> <code>2000</code>"},{"location":"api/connector/connector/#plugboard.connector.ZMQChannel.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the <code>ZMQChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQChannel.recv","title":"recv  <code>async</code>","text":"<pre><code>recv() -&gt; bytes\n</code></pre> <p>Receives a message from the <code>ZMQChannel</code> and returns it.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQChannel.send","title":"send  <code>async</code>","text":"<pre><code>send(msg: bytes) -&gt; None\n</code></pre> <p>Sends a message through the <code>ZMQChannel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>bytes</code> <p>The message to be sent through the <code>ZMQChannel</code>.</p> required"},{"location":"api/diagram/diagram/","title":"diagram","text":"<p>Provides classes and helper functions to visualise Plugboard processes.</p>"},{"location":"api/diagram/diagram/#plugboard.diagram.Diagram","title":"Diagram","text":"<pre><code>Diagram(**kwargs: Any)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p><code>Diagram</code> base class for creating diagrams of Plugboard processes.</p> <p>Instantiates <code>Diagram</code>.</p>"},{"location":"api/diagram/diagram/#plugboard.diagram.Diagram.diagram","title":"diagram  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>diagram: str\n</code></pre> <p>Returns a string representation of the diagram.</p>"},{"location":"api/diagram/diagram/#plugboard.diagram.Diagram.from_process","title":"from_process  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>from_process(process: Process, **kwargs: Any) -&gt; Diagram\n</code></pre> <p>Create the diagram.</p> <p>Parameters:</p> Name Type Description Default <code>process</code> <code>Process</code> <p>The <code>Process</code> object to create the diagram from.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for the diagram backend.</p> <code>{}</code>"},{"location":"api/diagram/diagram/#plugboard.diagram.MermaidDiagram","title":"MermaidDiagram","text":"<pre><code>MermaidDiagram(spec: str)\n</code></pre> <p>               Bases: <code>Diagram</code></p> <p><code>MermaidDiagram</code> class for creating diagrams of Plugboard processes using Mermaid.</p> <p>Instantiates <code>MermaidDiagram</code>.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>str</code> <p>The string representation of the diagram.</p> required"},{"location":"api/diagram/diagram/#plugboard.diagram.MermaidDiagram.diagram","title":"diagram  <code>property</code>","text":"<pre><code>diagram: str\n</code></pre> <p>Returns a string representation of the diagram.</p>"},{"location":"api/diagram/diagram/#plugboard.diagram.MermaidDiagram.url","title":"url  <code>property</code>","text":"<pre><code>url: str\n</code></pre> <p>Returns a URL to the diagram on Mermaid Live Editor.</p>"},{"location":"api/diagram/diagram/#plugboard.diagram.MermaidDiagram.from_process","title":"from_process  <code>classmethod</code>","text":"<pre><code>from_process(\n    process: Process, **kwargs: Any\n) -&gt; MermaidDiagram\n</code></pre> <p>Create the diagram.</p> <p>Parameters:</p> Name Type Description Default <code>process</code> <code>Process</code> <p>The <code>Process</code> object to create the diagram from.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for the diagram backend.</p> <code>{}</code>"},{"location":"api/diagram/diagram/#plugboard.diagram.markdown_diagram","title":"markdown_diagram","text":"<pre><code>markdown_diagram(process: Process) -&gt; str\n</code></pre> <p>Returns a markdown representation of a <code>Process</code>.</p>"},{"location":"api/events/events/","title":"events","text":"<p>Provides models and utilities for handling events.</p>"},{"location":"api/events/events/#plugboard.events.Event","title":"Event","text":"<p>               Bases: <code>PlugboardBaseModel</code>, <code>ABC</code></p> <p><code>Event</code> is a base model for all events.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>Type of the <code>Event</code>.</p> <code>id</code> <code>UUID4</code> <p>UUID v4 unique identifier for the <code>Event</code>.</p> <code>timestamp</code> <code>UTCDateTime</code> <p>UTC timestamp for the <code>Event</code>.</p> <code>source</code> <code>str</code> <p>Source of the <code>Event</code>.</p> <code>version</code> <code>str</code> <p>Version of the <code>Event</code>.</p> <code>data</code> <code>dict[str, Any] | BaseModel</code> <p>Data associated with the <code>Event</code>.</p> <code>metadata</code> <code>dict[str, str]</code> <p>Metadata for the <code>Event</code>.</p>"},{"location":"api/events/events/#plugboard.events.Event.handler","title":"handler  <code>classmethod</code>","text":"<pre><code>handler(method: AsyncCallable) -&gt; AsyncCallable\n</code></pre> <p>Registers a class method as an event handler.</p>"},{"location":"api/events/events/#plugboard.events.Event.safe_type","title":"safe_type  <code>classmethod</code>","text":"<pre><code>safe_type(event_type: Optional[str] = None) -&gt; str\n</code></pre> <p>Returns a safe event type string for use in broker topic strings.</p>"},{"location":"api/events/events/#plugboard.events.SystemEvent","title":"SystemEvent","text":"<p>               Bases: <code>Event</code>, <code>ABC</code></p> <p><code>SystemEvent</code> is a base model for system events.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>Type of the <code>SystemEvent</code>.</p> <code>id</code> <code>UUID4</code> <p>UUID v4 unique identifier for the <code>SystemEvent</code>.</p> <code>timestamp</code> <code>UTCDateTime</code> <p>UTC timestamp for the <code>SystemEvent</code>.</p> <code>source</code> <code>str</code> <p>Source of the <code>SystemEvent</code>.</p> <code>version</code> <code>str</code> <p>Version of the <code>SystemEvent</code>.</p> <code>data</code> <code>dict[str, Any] | BaseModel</code> <p>Data associated with the <code>SystemEvent</code>.</p> <code>metadata</code> <code>dict[str, str]</code> <p>Metadata for the <code>SystemEvent</code>.</p>"},{"location":"api/events/events/#plugboard.events.StopEvent","title":"StopEvent","text":"<p>               Bases: <code>SystemEvent</code></p> <p><code>StopEvent</code> is a system event to stop the application.</p>"},{"location":"api/events/events/#plugboard.events.EventConnectorBuilder","title":"EventConnectorBuilder","text":"<pre><code>EventConnectorBuilder(connector_builder: ConnectorBuilder)\n</code></pre> <p><code>EventConnectorBuilder</code> constructs connectors for component event handlers.</p>"},{"location":"api/events/events/#plugboard.events.EventConnectorBuilder.build","title":"build","text":"<pre><code>build(components: list[Component]) -&gt; dict[str, Connector]\n</code></pre> <p>Returns mapping of connectors for events handled by components.</p>"},{"location":"api/events/events/#plugboard.events.EventHandlers","title":"EventHandlers","text":"<p><code>EventHandlers</code> provides a decorator for registering event handlers.</p>"},{"location":"api/events/events/#plugboard.events.EventHandlers.add","title":"add  <code>classmethod</code>","text":"<pre><code>add(\n    event: Type[Event] | Event,\n) -&gt; _t.Callable[[AsyncCallable], AsyncCallable]\n</code></pre> <p>Decorator that registers class methods as handlers for specific event types.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Type[Event] | Event</code> <p>Event class this handler processes</p> required <p>Returns:</p> Name Type Description <code>Callable</code> <code>Callable[[AsyncCallable], AsyncCallable]</code> <p>Decorated method</p>"},{"location":"api/events/events/#plugboard.events.EventHandlers.get","title":"get  <code>classmethod</code>","text":"<pre><code>get(\n    _class: Type, event: Type[Event] | Event\n) -&gt; AsyncCallable\n</code></pre> <p>Retrieve a handler for a specific class and event type.</p> <p>Parameters:</p> Name Type Description Default <code>_class</code> <code>Type</code> <p>Class to handle event for</p> required <code>event</code> <code>Type[Event] | Event</code> <p>Event class or instance to handle</p> required <p>Returns:</p> Name Type Description <code>Callable</code> <code>AsyncCallable</code> <p>The event handler method</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If no handler found for class or event type</p>"},{"location":"api/exceptions/exceptions/","title":"exceptions","text":"<p>Provides exceptions for Plugboard.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.ChannelClosedError","title":"ChannelClosedError","text":"<p>               Bases: <code>ChannelError</code></p> <p>Raised when a closed channel is accessed.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.ChannelError","title":"ChannelError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised for channel related errors.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.ChannelNotConnectedError","title":"ChannelNotConnectedError","text":"<p>               Bases: <code>ChannelError</code></p> <p>Raised when using a channel that is not connected.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.ChannelSetupError","title":"ChannelSetupError","text":"<p>               Bases: <code>ChannelError</code></p> <p>Raised when a channel is setup incorrectly.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.ConstraintError","title":"ConstraintError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a constraint is violated.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.EventError","title":"EventError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised for event related errors.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.IOControllerError","title":"IOControllerError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised for IO controller related errors.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.IOSetupError","title":"IOSetupError","text":"<p>               Bases: <code>IOControllerError</code></p> <p>Raised when an IO controller is setup incorrectly.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.IOStreamClosedError","title":"IOStreamClosedError","text":"<p>               Bases: <code>IOControllerError</code></p> <p><code>IOStreamClosedError</code> is raised when an IO stream is closed.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.NoMoreDataException","title":"NoMoreDataException","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is no more data to fetch.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.NotFoundError","title":"NotFoundError","text":"<p>               Bases: <code>StateBackendError</code></p> <p>Raised when a resource is not found.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.NotInitialisedError","title":"NotInitialisedError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised attempting to step or run a <code>Process</code> or <code>Component</code> that has not been initialised.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.RegistryError","title":"RegistryError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an unknown class is requested from the ClassRegistry.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.StateBackendError","title":"StateBackendError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised for <code>StateBackend</code> related errors.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.UnrecognisedEventError","title":"UnrecognisedEventError","text":"<p>               Bases: <code>EventError</code></p> <p>Raised when an unrecognised event is encountered.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.ValidationError","title":"ValidationError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an invalid <code>Process</code> or <code>Component</code> is encountered.</p>"},{"location":"api/library/library/","title":"library","text":"<p>Provides implementations of Plugboard objects for use in user models.</p>"},{"location":"api/library/library/#plugboard.library.DataReader","title":"DataReader","text":"<pre><code>DataReader(\n    field_names: list[str],\n    chunk_size: Optional[int] = None,\n    **kwargs: Unpack[ComponentArgsDict],\n)\n</code></pre> <p>               Bases: <code>Component</code>, <code>ABC</code></p> <p>Abstract base class for reading data.</p> <p>Instantiates the <code>DataReader</code>.</p> <p>Parameters:</p> Name Type Description Default <code>field_names</code> <code>list[str]</code> <p>The names of the fields to read from the data source.</p> required <code>chunk_size</code> <code>Optional[int]</code> <p>The size of the data chunk to read from the data source.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[ComponentArgsDict]</code> <p>Additional keyword arguments for <code>Component</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.DataReader.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Initialises the <code>DataReader</code>.</p>"},{"location":"api/library/library/#plugboard.library.DataReader.step","title":"step  <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Reads data from the source and updates outputs.</p>"},{"location":"api/library/library/#plugboard.library.DataWriter","title":"DataWriter","text":"<pre><code>DataWriter(\n    field_names: list[str],\n    chunk_size: Optional[int] = None,\n    **kwargs: Unpack[ComponentArgsDict],\n)\n</code></pre> <p>               Bases: <code>Component</code>, <code>ABC</code></p> <p>Abstract base class for writing data.</p> <p>Instantiates the <code>DataWriter</code>.</p> <p>Parameters:</p> Name Type Description Default <code>field_names</code> <code>list[str]</code> <p>The names of the fields to write to the data source.</p> required <code>chunk_size</code> <code>Optional[int]</code> <p>The size of the data chunk to read from the DataFrame.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[ComponentArgsDict]</code> <p>Additional keyword arguments for <code>Component</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.DataWriter.run","title":"run  <code>async</code>","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Runs the <code>DataWriter</code>.</p>"},{"location":"api/library/library/#plugboard.library.DataWriter.step","title":"step  <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Trigger save when buffer is at target size.</p>"},{"location":"api/library/library/#plugboard.library.FileReader","title":"FileReader","text":"<pre><code>FileReader(\n    path: str | Path,\n    storage_options: Optional[dict[str, Any]] = None,\n    **kwargs: Unpack[DataReaderArgsSpec],\n)\n</code></pre> <p>               Bases: <code>DataReader</code></p> <p>Reads data from a file.</p> <p>Supported formats: CSV, GZIP-compressed CSV, Parquet. The file can be stored locally or on an fsspec-compatible cloud storage service.</p> <p>Instantiates the <code>FileReader</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>The path to the file to read.</p> required <code>storage_options</code> <code>Optional[dict[str, Any]]</code> <p>Optional; Additional options for the fsspec-compatible filesystem.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[DataReaderArgsSpec]</code> <p>Additional keyword arguments for <code>DataReader</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.FileWriter","title":"FileWriter","text":"<pre><code>FileWriter(\n    path: str | Path,\n    storage_options: Optional[dict[str, Any]] = None,\n    **kwargs: Unpack[DataWriterArgsSpec],\n)\n</code></pre> <p>               Bases: <code>DataWriter</code></p> <p>Writes data to a file. If the file already exists, it will be overwritten.</p> <p>Supported formats: CSV, GZIP-compressed CSV, Parquet. The file can be stored locally or on an fsspec-compatible cloud storage service.</p> <p>Instantiates the <code>FileWriter</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>The path to the file to write.</p> required <code>storage_options</code> <code>Optional[dict[str, Any]]</code> <p>Optional; Additional options for the fsspec-compatible filesystem.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[DataWriterArgsSpec]</code> <p>Additional keyword arguments for <code>DataWriter</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.LLMChat","title":"LLMChat","text":"<pre><code>LLMChat(\n    llm: str = \"llama_index.llms.openai.OpenAI\",\n    system_prompt: Optional[str] = None,\n    context_window: int = 0,\n    response_model: Optional[Type[BaseModel] | str] = None,\n    expand_response: bool = False,\n    llm_kwargs: Optional[dict[str, Any]] = None,\n    **kwargs: Unpack[ComponentArgsDict],\n)\n</code></pre> <p>               Bases: <code>Component</code></p> <p><code>LLMChat</code> is a component for interacting with large language models (LLMs).</p> <p>Requires the optional <code>plugboard[llm]</code> installation. The default LLM is OpenAI, and requires the <code>OPENAI_API_KEY</code> environment variable to be set. Other LLMs supported by llama-index can be used: see here for available models. Additional llama-index dependencies may be required for specific models.</p> <p>Structured output is supported by providing a Pydantic model as the <code>response_model</code> argument. This can optionally be unpacked into individual output fields by setting <code>expand_response=True</code>, otherwise the LLM response will be stored in the <code>response</code> output field.</p> <p>Instantiates <code>LLMChat</code>.</p> <p>Parameters:</p> Name Type Description Default <code>llm</code> <code>str</code> <p>The LLM class to use from llama-index.</p> <code>'llama_index.llms.openai.OpenAI'</code> <code>system_prompt</code> <code>Optional[str]</code> <p>Optional; System prompt to prepend to the context window.</p> <code>None</code> <code>context_window</code> <code>int</code> <p>The number of previous messages to include in the context window.</p> <code>0</code> <code>response_model</code> <code>Optional[Type[BaseModel] | str]</code> <p>Optional; A Pydantic model to structure the response. Can be specified as a string identifying the namespaced class to use.</p> <code>None</code> <code>expand_response</code> <code>bool</code> <p>Setting this to <code>True</code> when using a structured response model will cause the individual attributes of the response model to be added as output fields.</p> <code>False</code> <code>llm_kwargs</code> <code>Optional[dict[str, Any]]</code> <p>Additional keyword arguments for the LLM.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[ComponentArgsDict]</code> <p>Additional keyword arguments for <code>Component</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.SQLReader","title":"SQLReader","text":"<pre><code>SQLReader(\n    connection_string: str,\n    query: str,\n    params: Optional[dict[str, Any]] = None,\n    connect_args: Optional[dict[str, Any]] = None,\n    **kwargs: Unpack[DataReaderArgsSpec],\n)\n</code></pre> <p>               Bases: <code>DataReader</code></p> <p>Reads data from an SQL database using a supplied query and optional parameters.</p> <p>The underlying database connection is managed by SQLAlchemy: both synchronous and asynchronous drivers are supported.</p> <p>Instantiates the <code>SQLReader</code>.</p> <p>Parameters:</p> Name Type Description Default <code>connection_string</code> <code>str</code> <p>The connection string for the database.</p> required <code>query</code> <code>str</code> <p>The SQL query to run on the database.</p> required <code>params</code> <code>Optional[dict[str, Any]]</code> <p>Optional; Parameters to pass to the query.</p> <code>None</code> <code>connect_args</code> <code>Optional[dict[str, Any]]</code> <p>Optional; Additional options for the database connection.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[DataReaderArgsSpec]</code> <p>Additional keyword arguments for <code>DataReader</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.SQLWriter","title":"SQLWriter","text":"<pre><code>SQLWriter(\n    connection_string: str,\n    table: str,\n    connect_args: Optional[dict[str, Any]] = None,\n    **kwargs: Unpack[DataWriterArgsSpec],\n)\n</code></pre> <p>               Bases: <code>DataWriter</code></p> <p>Writes data to an SQL database. The specified table must already exist.</p> <p>The underlying database connection is managed by SQLAlchemy: both synchronous and asynchronous drivers are supported.</p> <p>Instantiates the <code>SQLWriter</code>.</p> <p>Parameters:</p> Name Type Description Default <code>connection_string</code> <code>str</code> <p>The connection string for the database.</p> required <code>table</code> <code>str</code> <p>The name of the table to write to, which must already exist.</p> required <code>connect_args</code> <code>Optional[dict[str, Any]]</code> <p>Optional; Additional options for the database connection.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[DataWriterArgsSpec]</code> <p>Additional keyword arguments for <code>DataWriter</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.WebsocketBase","title":"WebsocketBase","text":"<pre><code>WebsocketBase(\n    uri: str,\n    connect_args: dict[str, Any] | None = None,\n    **kwargs: Unpack[ComponentArgsDict],\n)\n</code></pre> <p>               Bases: <code>Component</code>, <code>ABC</code></p> <p>Base <code>Component</code> for websocket connections.</p> <p>See websockets for more info on the underlying websocket library.</p> <p>Instantiates the <code>Component</code>.</p> <p>Parameters:</p> Name Type Description Default <code>uri</code> <code>str</code> <p>The URI of the WebSocket server.</p> required <code>connect_args</code> <code>dict[str, Any] | None</code> <p>Optional; Additional arguments to pass to the WebSocket connection.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[ComponentArgsDict]</code> <p>Additional keyword arguments for <code>Component</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.WebsocketBase.destroy","title":"destroy  <code>async</code>","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Closes the websocket connection.</p>"},{"location":"api/library/library/#plugboard.library.WebsocketBase.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Initializes the websocket connection.</p>"},{"location":"api/library/library/#plugboard.library.WebsocketReader","title":"WebsocketReader","text":"<pre><code>WebsocketReader(\n    initial_message: Any | None = None,\n    skip_messages: int = 0,\n    parse_json: bool = False,\n    **kwargs: Unpack[WebsocketArgsDict],\n)\n</code></pre> <p>               Bases: <code>WebsocketBase</code></p> <p>Reads data from a websocket connection.</p> <p>Instantiates the <code>WebsocketReader</code>.</p> <p>See here for possible connection arguments that can be passed using <code>connect_args</code>. This <code>WebsocketReader</code> will run until interrupted, and automatically reconnect if the server connection is lost.</p> <p>Parameters:</p> Name Type Description Default <code>initial_message</code> <code>Any | None</code> <p>Optional; The initial message to send to the WebSocket server on connection. Can be used to subscribe to a specific topic.</p> <code>None</code> <code>skip_messages</code> <code>int</code> <p>The number of messages to ignore before starting to read messages.</p> <code>0</code> <code>parse_json</code> <code>bool</code> <p>Whether to parse the received data as JSON.</p> <code>False</code> <code>**kwargs</code> <code>Unpack[WebsocketArgsDict]</code> <p>Additional keyword arguments for <code>WebsocketBase</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.WebsocketReader.step","title":"step  <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Reads a message from the websocket connection.</p>"},{"location":"api/library/library/#plugboard.library.WebsocketWriter","title":"WebsocketWriter","text":"<pre><code>WebsocketWriter(\n    parse_json: bool = False,\n    **kwargs: Unpack[WebsocketArgsDict],\n)\n</code></pre> <p>               Bases: <code>WebsocketBase</code></p> <p>Writes data to a websocket connection.</p> <p>Instantiates the <code>WebsocketWriter</code>.</p> <p>See here for possible connection arguments that can be passed using <code>connect_args</code>.</p> <p>Parameters:</p> Name Type Description Default <code>parse_json</code> <code>bool</code> <p>Whether to convert the data to JSON before sending.</p> <code>False</code> <code>**kwargs</code> <code>Unpack[WebsocketArgsDict]</code> <p>Additional keyword arguments for <code>WebsocketBase</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.WebsocketWriter.step","title":"step  <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Writes a message to the websocket connection.</p>"},{"location":"api/process/process/","title":"process","text":"<p>Process submodule providing functionality related to processes and their execution.</p>"},{"location":"api/process/process/#plugboard.process.Process","title":"Process","text":"<pre><code>Process(\n    components: Iterable[Component],\n    connectors: Iterable[Connector],\n    name: Optional[str] = None,\n    parameters: Optional[dict] = None,\n    state: Optional[StateBackend] = None,\n)\n</code></pre> <p>               Bases: <code>ExportMixin</code>, <code>ABC</code></p> <p><code>Process</code> is a base class for managing components in a model.</p> <p>Instantiates a <code>Process</code>.</p> <p>Parameters:</p> Name Type Description Default <code>components</code> <code>Iterable[Component]</code> <p>The components in the <code>Process</code>.</p> required <code>connectors</code> <code>Iterable[Connector]</code> <p>The connectors between the components.</p> required <code>name</code> <code>Optional[str]</code> <p>Optional; Name for this <code>Process</code>.</p> <code>None</code> <code>parameters</code> <code>Optional[dict]</code> <p>Optional; Parameters for the <code>Process</code>.</p> <code>None</code> <code>state</code> <code>Optional[StateBackend]</code> <p>Optional; <code>StateBackend</code> for the <code>Process</code>.</p> <code>None</code>"},{"location":"api/process/process/#plugboard.process.Process.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Unique ID for <code>Process</code>.</p>"},{"location":"api/process/process/#plugboard.process.Process.is_initialised","title":"is_initialised  <code>property</code>","text":"<pre><code>is_initialised: bool\n</code></pre> <p>Returns whether the <code>Process</code> is initialised.</p>"},{"location":"api/process/process/#plugboard.process.Process.state","title":"state  <code>property</code>","text":"<pre><code>state: StateBackend\n</code></pre> <p>State backend for the process.</p>"},{"location":"api/process/process/#plugboard.process.Process.__aenter__","title":"__aenter__  <code>async</code>","text":"<pre><code>__aenter__() -&gt; Process\n</code></pre> <p>Enters the context manager.</p>"},{"location":"api/process/process/#plugboard.process.Process.__aexit__","title":"__aexit__  <code>async</code>","text":"<pre><code>__aexit__(\n    exc_type: Optional[Type[BaseException]],\n    exc_value: Optional[BaseException],\n    traceback: Optional[TracebackType],\n) -&gt; None\n</code></pre> <p>Exits the context manager.</p>"},{"location":"api/process/process/#plugboard.process.Process.connect_state","title":"connect_state  <code>async</code>","text":"<pre><code>connect_state(state: Optional[StateBackend] = None) -&gt; None\n</code></pre> <p>Connects the <code>Process</code> to the <code>StateBackend</code>.</p>"},{"location":"api/process/process/#plugboard.process.Process.destroy","title":"destroy  <code>async</code>","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Performs tear-down actions for the <code>Process</code> and its <code>Component</code>s.</p>"},{"location":"api/process/process/#plugboard.process.Process.init","title":"init  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Performs component initialisation actions.</p>"},{"location":"api/process/process/#plugboard.process.Process.run","title":"run  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Runs the process to completion.</p>"},{"location":"api/process/process/#plugboard.process.Process.step","title":"step  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Executes a single step for the process.</p>"},{"location":"api/process/process/#plugboard.process.LocalProcess","title":"LocalProcess","text":"<pre><code>LocalProcess(\n    components: Iterable[Component],\n    connectors: Iterable[Connector],\n    name: Optional[str] = None,\n    parameters: Optional[dict] = None,\n    state: Optional[StateBackend] = None,\n)\n</code></pre> <p>               Bases: <code>Process</code></p> <p><code>LocalProcess</code> manages components in a process model on a single processor.</p>"},{"location":"api/process/process/#plugboard.process.LocalProcess.destroy","title":"destroy  <code>async</code>","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Performs tear-down actions for the <code>LocalProcess</code> and its <code>Component</code>s.</p>"},{"location":"api/process/process/#plugboard.process.LocalProcess.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Performs component initialisation actions.</p>"},{"location":"api/process/process/#plugboard.process.LocalProcess.run","title":"run  <code>async</code>","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Runs the process to completion.</p>"},{"location":"api/process/process/#plugboard.process.LocalProcess.step","title":"step  <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Executes a single step for the process.</p>"},{"location":"api/process/process/#plugboard.process.RayProcess","title":"RayProcess","text":"<pre><code>RayProcess(\n    components: Iterable[Component],\n    connectors: Iterable[Connector],\n    name: Optional[str] = None,\n    parameters: Optional[dict] = None,\n    state: Optional[StateBackend] = None,\n)\n</code></pre> <p>               Bases: <code>Process</code></p> <p><code>RayProcess</code> manages components in a process model on a multiple Ray actors.</p> <p>Instantiates a <code>RayProcess</code>.</p> <p>Parameters:</p> Name Type Description Default <code>components</code> <code>Iterable[Component]</code> <p>The components in the <code>Process</code>.</p> required <code>connectors</code> <code>Iterable[Connector]</code> <p>The connectors between the components.</p> required <code>name</code> <code>Optional[str]</code> <p>Optional; Name for this <code>Process</code>.</p> <code>None</code> <code>parameters</code> <code>Optional[dict]</code> <p>Optional; Parameters for the <code>Process</code>.</p> <code>None</code> <code>state</code> <code>Optional[StateBackend]</code> <p>Optional; <code>StateBackend</code> for the <code>Process</code>.</p> <code>None</code>"},{"location":"api/process/process/#plugboard.process.RayProcess.destroy","title":"destroy  <code>async</code>","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Performs tear-down actions for the <code>RayProcess</code> and its <code>Component</code>s.</p>"},{"location":"api/process/process/#plugboard.process.RayProcess.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Performs component initialisation actions.</p>"},{"location":"api/process/process/#plugboard.process.RayProcess.run","title":"run  <code>async</code>","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Runs the process to completion.</p>"},{"location":"api/process/process/#plugboard.process.RayProcess.step","title":"step  <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Executes a single step for the process.</p>"},{"location":"api/schemas/schemas/","title":"schemas","text":"<p>Provides schemas used in Plugboard.</p> <p>This includes:</p> <ul> <li>Pydantic models for specifying Plugboard objects;</li> <li><code>TypeDict</code> definitions for constructor <code>**kwargs</code>.</li> </ul>"},{"location":"api/schemas/schemas/#plugboard.schemas.Direction","title":"Direction  <code>module-attribute</code>","text":"<pre><code>Direction = Literal['min', 'max']\n</code></pre> <p>A type for the direction of optimisation.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ParameterSpec","title":"ParameterSpec  <code>module-attribute</code>","text":"<pre><code>ParameterSpec = Union[\n    FloatParameterSpec,\n    IntParameterSpec,\n    CategoricalParameterSpec,\n]\n</code></pre> <p>A union type for all parameter specifications.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.CategoricalParameterSpec","title":"CategoricalParameterSpec","text":"<p>               Bases: <code>BaseFieldSpec</code></p> <p>Specification for a categorical parameter.</p> <p>See: https://docs.ray.io/en/latest/tune/api/search_space.html.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['ray.tune.choice']</code> <p>The type of the parameter.</p> <code>categories</code> <code>list[Any]</code> <p>The categories of the parameter.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ComponentArgsDict","title":"ComponentArgsDict","text":"<p>               Bases: <code>TypedDict</code></p> <p><code>TypedDict</code> of the <code>Component</code> constructor arguments.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ComponentArgsSpec","title":"ComponentArgsSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of the <code>Component</code> constructor arguments.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the <code>Component</code>.</p> <code>initial_values</code> <code>dict[str, Any]</code> <p>Initial values for the <code>Component</code>.</p> <code>parameters</code> <code>dict[str, Any]</code> <p>Parameters for the <code>Component</code>.</p> <code>constraints</code> <code>dict[str, Any]</code> <p>Constraints for the <code>Component</code>.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ComponentSpec","title":"ComponentSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of a <code>Component</code>.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>The type of the <code>Component</code>.</p> <code>args</code> <code>ComponentArgsSpec</code> <p>The arguments for the <code>Component</code>.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ConfigSpec","title":"ConfigSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Configuration for a Plugboard simulation.</p> <p>Attributes:</p> Name Type Description <code>plugboard</code> <code>ProcessConfigSpec</code> <p>A <code>ProcessConfig</code> that specifies the Plugboard <code>Process</code>.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ConnectorBuilderArgsDict","title":"ConnectorBuilderArgsDict","text":"<p>               Bases: <code>TypedDict</code></p> <p><code>TypedDict</code> of the <code>Connector</code> constructor arguments.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ConnectorBuilderArgsSpec","title":"ConnectorBuilderArgsSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of the <code>Connector</code> constructor arguments.</p> <p>Attributes:</p> Name Type Description <code>parameters</code> <code>dict[str, Any]</code> <p>Parameters for the <code>Connector</code>.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ConnectorBuilderSpec","title":"ConnectorBuilderSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of a <code>ConnectorBuilder</code>.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>The type of the <code>ConnectorBuilder</code>.</p> <code>args</code> <code>ConnectorBuilderArgsSpec</code> <p>Optional; The arguments for the <code>ConnectorBuilder</code>.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ConnectorMode","title":"ConnectorMode","text":"<p>               Bases: <code>StrEnum</code></p> <p>Defines the mode of a connector.</p> <p>Attributes:</p> Name Type Description <code>PIPELINE</code> <p>one-in-one-out task queue.</p> <code>PUBSUB</code> <p>one-to-many event distribution.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ConnectorSocket","title":"ConnectorSocket","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p><code>ConnectorSocket</code> defines a source or target connection point on a <code>Connector</code>.</p> <p>There are two typical types of connections in use: those between attributes of components; and those connecting components with events which they either emit or consume. When connecting two component attributes together, the <code>entity</code> is the name of the component, and the <code>descriptor</code> is the name of the attribute. When connecting components with events, the <code>entity</code> is the name of the event, and the <code>descriptor</code> is either \"publishers\" or \"subscribers\" as appropriate.</p> <p>Attributes:</p> Name Type Description <code>entity</code> <code>str</code> <p>The name of the entity.</p> <code>descriptor</code> <code>str</code> <p>The name of the descriptor on the entity.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ConnectorSocket.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Unique ID for <code>ConnectorSocket</code>.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ConnectorSocket.connects_to","title":"connects_to","text":"<pre><code>connects_to(entities: Container[str]) -&gt; bool\n</code></pre> <p>Returns <code>True</code> if the <code>ConnectorSocket</code> connects to any of the named entities.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ConnectorSocket.from_ref","title":"from_ref  <code>classmethod</code>","text":"<pre><code>from_ref(ref: str) -&gt; _t.Self\n</code></pre> <p>Creates a <code>ConnectorSocket</code> from a reference string.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ConnectorSpec","title":"ConnectorSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p><code>ConnectorSpec</code> defines a connection between two entities.</p> <p>Attributes:</p> Name Type Description <code>source</code> <code>ConnectorSocket</code> <p>The source endpoint.</p> <code>target</code> <code>ConnectorSocket</code> <p>The target endpoint.</p> <code>mode</code> <code>ConnectorMode</code> <p>The mode of the connector.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ConnectorSpec.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Unique ID for <code>ConnectorSpec</code>.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.Entity","title":"Entity","text":"<p>               Bases: <code>StrEnum</code></p> <p>Entity names.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.Entity.id_prefix","title":"id_prefix  <code>property</code>","text":"<pre><code>id_prefix: str\n</code></pre> <p>Returns prefix for generating unique entity ids.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.Entity.id_regex","title":"id_regex  <code>property</code>","text":"<pre><code>id_regex: str\n</code></pre> <p>Returns regex for validating entity ids.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.FloatParameterSpec","title":"FloatParameterSpec","text":"<p>               Bases: <code>BaseFieldSpec</code></p> <p>Specification for a uniform float parameter.</p> <p>See: https://docs.ray.io/en/latest/tune/api/search_space.html.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['ray.tune.uniform']</code> <p>The type of the parameter.</p> <code>lower</code> <code>float</code> <p>The lower bound of the parameter.</p> <code>upper</code> <code>float</code> <p>The upper bound of the parameter.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.IODirection","title":"IODirection","text":"<p>               Bases: <code>StrEnum</code></p> <p><code>IODirection</code> defines the type of IO operation.</p> <p>Attributes:</p> Name Type Description <code>INPUT</code> <p>Specifies an input to a <code>Component</code>.</p> <code>OUTPUT</code> <p>Specifies an output to a <code>Component</code>.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.IntParameterSpec","title":"IntParameterSpec","text":"<p>               Bases: <code>BaseFieldSpec</code></p> <p>Specification for a uniform integer parameter.</p> <p>See: https://docs.ray.io/en/latest/tune/api/search_space.html.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['ray.tune.randint']</code> <p>The type of the parameter.</p> <code>lower</code> <code>int</code> <p>The lower bound of the parameter.</p> <code>upper</code> <code>int</code> <p>The upper bound of the parameter.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ObjectiveSpec","title":"ObjectiveSpec","text":"<p>               Bases: <code>BaseFieldSpec</code></p> <p>Specification for an objective field.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.OptunaSpec","title":"OptunaSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification for the Optuna configuration.</p> <p>See: https://docs.ray.io/en/latest/tune/api/doc/ray.tune.search.optuna.OptunaSearch.html and https://optuna.readthedocs.io/en/stable/reference/index.html for more information on the Optuna configuration.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['ray.tune.search.optuna.OptunaSearch']</code> <p>The algorithm type to load.</p> <code>study_name</code> <code>str | None</code> <p>Optional; The name of the study.</p> <code>storage</code> <code>str | None</code> <p>Optional; The storage URI to save the optimisation results to.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ProcessArgsDict","title":"ProcessArgsDict","text":"<p>               Bases: <code>TypedDict</code></p> <p><code>TypedDict</code> of the <code>Process</code> constructor arguments.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ProcessArgsSpec","title":"ProcessArgsSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of the <code>Process</code> constructor arguments.</p> <p>Attributes:</p> Name Type Description <code>components</code> <code>Annotated[list[ComponentSpec], Len(min_length=1)]</code> <p>Specifies each <code>Component</code> in the <code>Process</code>.</p> <code>connectors</code> <code>list[ConnectorSpec]</code> <p>Specifies the connections between each <code>Component</code>.</p> <code>name</code> <code>Optional[str]</code> <p>Unique identifier for <code>Process</code>.</p> <code>parameters</code> <code>dict[str, Any]</code> <p>Parameters for the <code>Process</code>.</p> <code>state</code> <code>StateBackendSpec</code> <p>Optional; Specifies the <code>StateBackend</code> used for the <code>Process</code>.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ProcessConfigSpec","title":"ProcessConfigSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>A <code>ProcessSpec</code> within a Plugboard configuration.</p> <p>Attributes:</p> Name Type Description <code>process</code> <code>ProcessSpec</code> <p>A <code>ProcessSpec</code> that specifies the process, or a path to a YAML file containing the process specification.</p> <code>tune</code> <code>TuneSpec | None</code> <p>Optional; A <code>TuneSpec</code> that specifies an optimisation configuration.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.ProcessSpec","title":"ProcessSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of a Plugboard <code>Process</code>.</p> <p>Attributes:</p> Name Type Description <code>args</code> <code>ProcessArgsSpec</code> <p>The arguments for the <code>Process</code>.</p> <code>type</code> <code>Literal['plugboard.process.LocalProcess', 'plugboard.process.RayProcess']</code> <p>The type of <code>Process</code> to build.</p> <code>connector_builder</code> <code>ConnectorBuilderSpec</code> <p>The <code>ConnectorBuilder</code> to use for the <code>Process</code>.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.StateBackendArgsDict","title":"StateBackendArgsDict","text":"<p>               Bases: <code>TypedDict</code></p> <p><code>TypedDict</code> of the <code>StateBackend</code> constructor arguments.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.StateBackendArgsSpec","title":"StateBackendArgsSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of the <code>StateBackend</code> constructor arguments.</p> <p>Attributes:</p> Name Type Description <code>job_id</code> <code>Optional[str]</code> <p>The unique id for the job.</p> <code>metadata</code> <code>dict[str, Any]</code> <p>Metadata for a run.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.StateBackendSpec","title":"StateBackendSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of a Plugboard <code>StateBackend</code>.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>The type of the <code>StateBackend</code>.</p> <code>args</code> <code>StateBackendArgsSpec</code> <p>The arguments for the <code>StateBackend</code>.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.Status","title":"Status","text":"<p>               Bases: <code>StrEnum</code></p> <p><code>Status</code> describes the status of either a <code>Component</code> or a <code>Process</code>.</p> <p>Attributes:</p> Name Type Description <code>CREATED</code> <p>The <code>Component</code> or <code>Process</code> has been created but not yet started.</p> <code>INIT</code> <p>The <code>Component</code> or <code>Process</code> has been initialised but has not started running.</p> <code>RUNNING</code> <p>The <code>Component</code> or <code>Process</code> is currently running.</p> <code>WAITING</code> <p>The <code>Component</code> or <code>Process</code> is waiting for input.</p> <code>COMPLETED</code> <p>The <code>Component</code> or <code>Process</code> has completed successfully.</p> <code>FAILED</code> <p>The <code>Component</code> or <code>Process</code> has failed.</p> <code>STOPPED</code> <p>The <code>Component</code> or <code>Process</code> has been cancelled or stopped.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.Status.is_terminal","title":"is_terminal  <code>property</code>","text":"<pre><code>is_terminal: bool\n</code></pre> <p>Returns whether the status is terminal.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.TuneArgsDict","title":"TuneArgsDict","text":"<p>               Bases: <code>TypedDict</code></p> <p><code>TypedDict</code> of the <code>Tuner</code> constructor arguments.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.TuneArgsSpec","title":"TuneArgsSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of the arguments for the <code>Tune</code> class.</p> <p>Attributes:</p> Name Type Description <code>objective</code> <code>ObjectiveSpec | list[ObjectiveSpec]</code> <p>The location of the objective(s) to optimise for in the <code>Process</code>.</p> <code>parameters</code> <code>list[ParameterSpec]</code> <p>The parameters to optimise over.</p> <code>num_samples</code> <code>PositiveInt</code> <p>The number of samples to draw during the optimisation.</p> <code>mode</code> <code>Direction | list[Direction]</code> <p>The mode of optimisation. For multi-objective optimisation, this should be a list containing a direction for each objective.</p> <code>max_concurrent</code> <code>PositiveInt | None</code> <p>The maximum number of concurrent trials.</p> <code>algorithm</code> <code>Union[OptunaSpec]</code> <p>The algorithm to use for the optimisation.</p>"},{"location":"api/schemas/schemas/#plugboard.schemas.TuneSpec","title":"TuneSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Configuration for an optimisation job.</p> <p>Attributes:</p> Name Type Description <code>args</code> <code>TuneArgsSpec</code> <p>The arguments for the <code>Tune</code> job.</p>"},{"location":"api/state/state/","title":"state","text":"<p>State submodule providing functionality related to persisting process or component state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend","title":"StateBackend","text":"<pre><code>StateBackend(\n    job_id: Optional[str] = None,\n    metadata: Optional[dict] = None,\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>ABC</code>, <code>ExportMixin</code></p> <p><code>StateBackend</code> defines an interface for managing process state.</p> <p>Instantiates <code>StateBackend</code>.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>Optional[str]</code> <p>The unique id for the job.</p> <code>None</code> <code>metadata</code> <code>Optional[dict]</code> <p>Metadata key value pairs.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code>"},{"location":"api/state/state/#plugboard.state.StateBackend.created_at","title":"created_at  <code>property</code>","text":"<pre><code>created_at: str\n</code></pre> <p>Returns date and time of job creation.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.job_id","title":"job_id  <code>property</code>","text":"<pre><code>job_id: str\n</code></pre> <p>Returns the job id for the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.metadata","title":"metadata  <code>property</code>","text":"<pre><code>metadata: dict\n</code></pre> <p>Returns metadata attached to the job.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.__aenter__","title":"__aenter__  <code>async</code>","text":"<pre><code>__aenter__() -&gt; StateBackend\n</code></pre> <p>Enters the context manager.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.__aexit__","title":"__aexit__  <code>async</code>","text":"<pre><code>__aexit__(\n    exc_type: Optional[Type[BaseException]],\n    exc_value: Optional[BaseException],\n    traceback: Optional[TracebackType],\n) -&gt; None\n</code></pre> <p>Exits the context manager.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.destroy","title":"destroy  <code>async</code>","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Destroys the <code>StateBackend</code>.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.get_component","title":"get_component  <code>async</code>","text":"<pre><code>get_component(component_id: str) -&gt; dict\n</code></pre> <p>Returns a component from the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.get_connector","title":"get_connector  <code>async</code>","text":"<pre><code>get_connector(connector_id: str) -&gt; dict\n</code></pre> <p>Returns a connector from the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.get_process","title":"get_process  <code>async</code>","text":"<pre><code>get_process(process_id: str) -&gt; dict\n</code></pre> <p>Returns a process from the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Initialises the <code>StateBackend</code>.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.upsert_component","title":"upsert_component  <code>async</code>","text":"<pre><code>upsert_component(component: Component) -&gt; None\n</code></pre> <p>Upserts a component into the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.upsert_connector","title":"upsert_connector  <code>async</code>","text":"<pre><code>upsert_connector(connector: Connector) -&gt; None\n</code></pre> <p>Upserts a connector into the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.upsert_process","title":"upsert_process  <code>async</code>","text":"<pre><code>upsert_process(\n    process: Process, with_components: bool = False\n) -&gt; None\n</code></pre> <p>Upserts a process into the state.</p>"},{"location":"api/state/state/#plugboard.state.DictStateBackend","title":"DictStateBackend","text":"<pre><code>DictStateBackend(*args: Any, **kwargs: Any)\n</code></pre> <p>               Bases: <code>StateBackend</code></p> <p><code>DictStateBackend</code> provides state persistence for single process runs.</p> <p>Instantiates <code>DictStateBackend</code>.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend","title":"SqliteStateBackend","text":"<pre><code>SqliteStateBackend(\n    db_path: str = \"plugboard.db\", *args: Any, **kwargs: Any\n)\n</code></pre> <p>               Bases: <code>StateBackend</code></p> <p><code>SqliteStateBackend</code> handles single host persistent state.</p> <p>Initializes <code>SqliteStateBackend</code> with <code>db_path</code>.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.get_component","title":"get_component  <code>async</code>","text":"<pre><code>get_component(component_id: str) -&gt; dict\n</code></pre> <p>Returns a component from the state.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.get_connector","title":"get_connector  <code>async</code>","text":"<pre><code>get_connector(connector_id: str) -&gt; dict\n</code></pre> <p>Returns a connector from the state.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.get_process","title":"get_process  <code>async</code>","text":"<pre><code>get_process(process_id: str) -&gt; dict\n</code></pre> <p>Returns a process from the state.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Initializes the <code>SqliteStateBackend</code>.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.upsert_component","title":"upsert_component  <code>async</code>","text":"<pre><code>upsert_component(component: Component) -&gt; None\n</code></pre> <p>Upserts a component into the state.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.upsert_connector","title":"upsert_connector  <code>async</code>","text":"<pre><code>upsert_connector(connector: Connector) -&gt; None\n</code></pre> <p>Upserts a connector into the state.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.upsert_process","title":"upsert_process  <code>async</code>","text":"<pre><code>upsert_process(\n    process: Process, with_components: bool = False\n) -&gt; None\n</code></pre> <p>Upserts a process into the state.</p>"},{"location":"api/tune/tune/","title":"tune","text":"<p>Tune submodule for configuring optimisation jobs.</p>"},{"location":"api/tune/tune/#plugboard.tune.Tuner","title":"Tuner","text":"<pre><code>Tuner(\n    *,\n    objective: ObjectiveSpec | list[ObjectiveSpec],\n    parameters: list[ParameterSpec],\n    num_samples: int,\n    mode: Direction | list[Direction] = \"max\",\n    max_concurrent: Optional[int] = None,\n    algorithm: Optional[OptunaSpec] = None,\n)\n</code></pre> <p>A class for running optimisation on Plugboard processes.</p> <p>Instantiates the <code>Tuner</code> class.</p> <p>Parameters:</p> Name Type Description Default <code>objective</code> <code>ObjectiveSpec | list[ObjectiveSpec]</code> <p>The objective(s) to optimise for in the <code>Process</code>.</p> required <code>parameters</code> <code>list[ParameterSpec]</code> <p>The parameters to optimise over.</p> required <code>num_samples</code> <code>int</code> <p>The number of trial samples to use for the optimisation.</p> required <code>mode</code> <code>Direction | list[Direction]</code> <p>The direction of the optimisation.</p> <code>'max'</code> <code>max_concurrent</code> <code>Optional[int]</code> <p>The maximum number of concurrent trials. Defaults to None, which means that Ray will use its default concurrency of 1 trial per CPU core.</p> <code>None</code> <code>algorithm</code> <code>Optional[OptunaSpec]</code> <p>Configuration for the underlying Optuna algorithm used for optimisation.</p> <code>None</code>"},{"location":"api/tune/tune/#plugboard.tune.Tuner.is_multi_objective","title":"is_multi_objective  <code>property</code>","text":"<pre><code>is_multi_objective: bool\n</code></pre> <p>Returns <code>True</code> if the optimisation is multi-objective.</p>"},{"location":"api/tune/tune/#plugboard.tune.Tuner.result_grid","title":"result_grid  <code>property</code>","text":"<pre><code>result_grid: ResultGrid\n</code></pre> <p>Returns a [<code>ResultGrid</code>][ray.tune.ResultGrid] summarising the optimisation results.</p>"},{"location":"api/tune/tune/#plugboard.tune.Tuner.run","title":"run","text":"<pre><code>run(\n    spec: ProcessSpec,\n) -&gt; ray.tune.Result | list[ray.tune.Result]\n</code></pre> <p>Run the optimisation job on Ray.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>ProcessSpec</code> <p>The <code>ProcessSpec</code> to optimise.</p> required <p>Returns:</p> Type Description <code>Result | list[Result]</code> <p>Either one or a list of [<code>Result</code>][ray.tune.Result] objects containing the best trial</p> <code>Result | list[Result]</code> <p>result. Use the <code>result_grid</code> property to get full trial results.</p>"},{"location":"api/utils/","title":"utils","text":"<p>Provides utility functions for use throughout the code.</p>"},{"location":"api/utils/#plugboard.utils.ClassRegistry","title":"ClassRegistry","text":"<p>               Bases: <code>ABC</code>, <code>Generic[T]</code></p> <p>A registry of Plugboard classes.</p>"},{"location":"api/utils/#plugboard.utils.ClassRegistry.add","title":"add  <code>classmethod</code>","text":"<pre><code>add(\n    plugboard_class: type[T], key: Optional[Hashable] = None\n) -&gt; None\n</code></pre> <p>Add a class to the registry.</p> <p>Parameters:</p> Name Type Description Default <code>plugboard_class</code> <code>type[T]</code> <p>The class to register.</p> required <code>key</code> <code>Optional[Hashable]</code> <p>Optional; The key to register the class under.</p> <code>None</code>"},{"location":"api/utils/#plugboard.utils.ClassRegistry.build","title":"build  <code>classmethod</code>","text":"<pre><code>build(\n    plugboard_class: Hashable, *args: Any, **kwargs: Any\n) -&gt; T\n</code></pre> <p>Builds a Plugboard object.</p> <p>Parameters:</p> Name Type Description Default <code>plugboard_class</code> <code>Hashable</code> <p>The key corresponding to the required class.</p> required <code>*args</code> <code>Any</code> <p>Positional arguments to pass to the class constructor.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments to pass to the class constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>T</code> <p>An object of the required class.</p>"},{"location":"api/utils/#plugboard.utils.ClassRegistry.get","title":"get  <code>classmethod</code>","text":"<pre><code>get(plugboard_class: Hashable) -&gt; type[T]\n</code></pre> <p>Returns a class from the registry.</p> <p>Parameters:</p> Name Type Description Default <code>plugboard_class</code> <code>Hashable</code> <p>The key corresponding to the required class.</p> required <p>Returns:</p> Type Description <code>type[T]</code> <p>The class.</p>"},{"location":"api/utils/#plugboard.utils.DI","title":"DI","text":"<p>               Bases: <code>BaseContainer</code></p> <p><code>DI</code> is a dependency injection container for plugboard.</p>"},{"location":"api/utils/#plugboard.utils.EntityIdGen","title":"EntityIdGen","text":"<p>EntityIdGen generates entity ids.</p>"},{"location":"api/utils/#plugboard.utils.EntityIdGen.id","title":"id  <code>classmethod</code>","text":"<pre><code>id(entity: Entity) -&gt; str\n</code></pre> <p>Returns a unique entity id.</p> <p>Parameters:</p> Name Type Description Default <code>entity</code> <code>Entity</code> <p>The entity to generate an id for.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The generated id.</p>"},{"location":"api/utils/#plugboard.utils.EntityIdGen.is_job_id","title":"is_job_id  <code>classmethod</code>","text":"<pre><code>is_job_id(id: str) -&gt; bool\n</code></pre> <p>Checks if an id is a job id.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The id to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the id is a job id.</p>"},{"location":"api/utils/#plugboard.utils.EntityIdGen.job_id","title":"job_id  <code>classmethod</code>","text":"<pre><code>job_id() -&gt; str\n</code></pre> <p>Returns a unique job id.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The generated job id.</p>"},{"location":"api/utils/#plugboard.utils.EntityIdGen.parse","title":"parse  <code>classmethod</code>","text":"<pre><code>parse(id: str) -&gt; tuple[Entity, str]\n</code></pre> <p>Parses an entity id.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The entity id to parse.</p> required <p>Returns:</p> Type Description <code>tuple[Entity, str]</code> <p>tuple[Entity, str]: The parsed entity and id.</p>"},{"location":"api/utils/#plugboard.utils.ExportMixin","title":"ExportMixin","text":"<p><code>AsDictMixin</code> provides functionality for converting objects to dict.</p>"},{"location":"api/utils/#plugboard.utils.ExportMixin._convert_exportable_objs","title":"_convert_exportable_objs  <code>staticmethod</code>","text":"<pre><code>_convert_exportable_objs(obj: Any) -&gt; _t.Any\n</code></pre> <p>Recursively converts <code>Exportable</code> objects to their <code>export</code> representation.</p>"},{"location":"api/utils/#plugboard.utils.ExportMixin.dict","title":"dict","text":"<pre><code>dict() -&gt; dict\n</code></pre> <p>Returns dict representation of object.</p>"},{"location":"api/utils/#plugboard.utils.ExportMixin.export","title":"export","text":"<pre><code>export() -&gt; dict\n</code></pre> <p>Returns dict representation of object for later reconstruction.</p>"},{"location":"api/utils/#plugboard.utils.ExportMixin.json","title":"json","text":"<pre><code>json() -&gt; bytes\n</code></pre> <p>Returns JSON representation of object as bytes.</p>"},{"location":"api/utils/#plugboard.utils.Exportable","title":"Exportable","text":"<p>               Bases: <code>Protocol</code></p> <p><code>Exportable</code> protocol for objects that can be exported.</p>"},{"location":"api/utils/#plugboard.utils.Exportable.export","title":"export","text":"<pre><code>export() -&gt; dict\n</code></pre> <p>Returns dict representation of object for later reconstruction.</p>"},{"location":"api/utils/#plugboard.utils.add_sys_path","title":"add_sys_path","text":"<pre><code>add_sys_path(path: str | PathLike) -&gt; Iterator\n</code></pre> <p>Temporarily add <code>path</code> to <code>sys.path</code>.</p>"},{"location":"api/utils/#plugboard.utils.build_actor_wrapper","title":"build_actor_wrapper","text":"<pre><code>build_actor_wrapper(cls: type[T]) -&gt; type[_ActorWrapper[T]]\n</code></pre> <p>Builds an actor wrapper around a class.</p> <p>This is useful for handling classes that are modified at runtime, e.g. via wrapped methods, and therefore not supported by the <code>ray.remote</code> decorator.</p> <p>The wrapper methods will have the same name as the original methods, but where nested in class attributes the method names will be prefixed accordingly. The wrapper also provides a <code>getattr</code> and <code>setattr</code> method to access the wrapped object's properties.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>type[T]</code> <p>The class to wrap.</p> required <p>Returns:</p> Type Description <code>type[_ActorWrapper[T]]</code> <p>A new class that wraps the original class and can be used as a Ray actor.</p>"},{"location":"api/utils/#plugboard.utils.depends_on_optional","title":"depends_on_optional","text":"<pre><code>depends_on_optional(\n    module_name: str, extra: Optional[str] = None\n) -&gt; _t.Callable\n</code></pre> <p>Decorator to check for optional dependencies.</p> <p>Parameters:</p> Name Type Description Default <code>module_name</code> <code>str</code> <p>The name of the module to check for.</p> required <code>extra</code> <code>Optional[str]</code> <p>Optional; The name of the extra that the module is associated with. Defaults to the module name.</p> <code>None</code>"},{"location":"api/utils/#plugboard.utils.gather_except","title":"gather_except  <code>async</code>","text":"<pre><code>gather_except(*coros: Coroutine) -&gt; list[_t.Any]\n</code></pre> <p>Attempts to gather the given coroutines, raising any exceptions.</p>"},{"location":"api/utils/#plugboard.utils.gen_rand_str","title":"gen_rand_str","text":"<pre><code>gen_rand_str(chars: int = RANDOM_CHAR_COUNT) -&gt; str\n</code></pre> <p>Generates a random string of a fixed length and character set.</p> <p>With 16 chars in [a-zA-Z0-9], at 1000 ids/second it would take ~1000 years or 30T ids for &gt;= 1% chance of at least one collision. See here for details: https://zelark.github.io/nano-id-cc/</p> <p>Note: This function is not suitable for cryptographic purposes; it is intended to generate random strings for unique identifiers only.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Random fixed length string.</p>"},{"location":"api/utils/#plugboard.utils.is_on_ray_worker","title":"is_on_ray_worker","text":"<pre><code>is_on_ray_worker() -&gt; bool\n</code></pre> <p>Returns <code>True</code> if called from a Ray worker.</p>"},{"location":"api/utils/#plugboard.utils.run_coro_sync","title":"run_coro_sync","text":"<pre><code>run_coro_sync(\n    coro: Coroutine, timeout: Optional[float] = None\n) -&gt; _t.Any\n</code></pre> <p>Runs a coroutine synchronously, returning the result.</p> <p>This is useful for async code run from synchronous CLI entrypoints. In the test environment, it will run the coroutine in the current event loop, if present, otherwise it will create a new event loop for the coroutine.</p>"},{"location":"api/utils/settings/settings/","title":"settings","text":"<p>Provides Plugboard's settings.</p>"},{"location":"api/utils/settings/settings/#plugboard.utils.settings.Settings","title":"Settings","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Settings for Plugboard.</p> <p>Attributes:</p> Name Type Description <code>flags</code> <code>_FeatureFlags</code> <p>Feature flags for Plugboard.</p> <code>log_level</code> <code>LogLevel</code> <p>The log level to use.</p> <code>log_structured</code> <code>bool</code> <p>Whether to render logs to JSON. Defaults to JSON if not running in a terminal session.</p>"},{"location":"api/utils/settings/settings/#plugboard.utils.settings._FeatureFlags","title":"_FeatureFlags","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Feature flags for Plugboard.</p> <p>Attributes:</p> Name Type Description <code>zmq_pubsub_proxy</code> <code>bool</code> <p>If set to true, runs a ZMQ proxy in a separate process for pubsub.</p> <code>multiprocessing_fork</code> <code>bool</code> <p>If set to true, uses fork mode for multiprocessing.</p>"},{"location":"examples/demos/fundamentals/001_simple_model/simple-model/","title":"Simple 3-node model","text":"In\u00a0[\u00a0]: Copied! <pre>import typing as _t\n\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.component import Component\nfrom plugboard.component import IOController as IO\nfrom plugboard.schemas import ComponentArgsDict, ConnectorSpec\nfrom plugboard.process import LocalProcess\nfrom plugboard.library import FileReader, FileWriter\n</pre> import typing as _t  from plugboard.connector import AsyncioConnector from plugboard.component import Component from plugboard.component import IOController as IO from plugboard.schemas import ComponentArgsDict, ConnectorSpec from plugboard.process import LocalProcess from plugboard.library import FileReader, FileWriter <p>The <code>FileReader</code> component is provided by Plugboard. It takes the content of a CSV and emits the values row-by-row. Our CSV contains a single <code>value</code> column, so we configure the <code>field_names</code> argument to expect that.</p> In\u00a0[\u00a0]: Copied! <pre>input_data = FileReader(name=\"input_data\", path=\"input.csv\", field_names=[\"value\"])\n</pre> input_data = FileReader(name=\"input_data\", path=\"input.csv\", field_names=[\"value\"]) <p>Next, we implement a component to compute a running total using its internal state.</p> In\u00a0[\u00a0]: Copied! <pre>class RunningTotal(Component):\n    # Define the inputs and outputs of the component\n    io = IO(inputs=[\"value\"], outputs=[\"total_value\"])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        # Set the initial running total to 0\n        self._running_total = 0\n\n    async def step(self) -&gt; None:\n        # The main logic of the component\n        self._running_total += self.value\n        self.total_value = self._running_total\n        await super().step()\n</pre> class RunningTotal(Component):     # Define the inputs and outputs of the component     io = IO(inputs=[\"value\"], outputs=[\"total_value\"])      def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         # Set the initial running total to 0         self._running_total = 0      async def step(self) -&gt; None:         # The main logic of the component         self._running_total += self.value         self.total_value = self._running_total         await super().step() In\u00a0[\u00a0]: Copied! <pre>total = RunningTotal(name=\"total\")\n</pre> total = RunningTotal(name=\"total\") <p>At this point, it is possible to test the component in the notebook by initialising it, setting its input value, then calling <code>step()</code>.</p> In\u00a0[\u00a0]: Copied! <pre>await total.init()\ntotal.value = 10  # Set the value input to 10\nawait total.step()  # Run the component\nprint(total.total_value)  # Print the total value output\ntotal.value = 20  # Set the value input to 20\nawait total.step()  # Run the component\nprint(total.total_value)  # Print the total value output\n</pre> await total.init() total.value = 10  # Set the value input to 10 await total.step()  # Run the component print(total.total_value)  # Print the total value output total.value = 20  # Set the value input to 20 await total.step()  # Run the component print(total.total_value)  # Print the total value output <p>Now re-instantiate <code>total</code> to reset its state.</p> In\u00a0[\u00a0]: Copied! <pre>total = RunningTotal(name=\"total\")\n</pre> total = RunningTotal(name=\"total\") <p>For the output we can use the built-in <code>FileWriter</code> component, configured to expect an input called <code>value_to_save</code>.</p> In\u00a0[\u00a0]: Copied! <pre>output_data = FileWriter(name=\"output_data\", path=\"output.csv\", field_names=[\"value_to_save\"])\n</pre> output_data = FileWriter(name=\"output_data\", path=\"output.csv\", field_names=[\"value_to_save\"]) <p>Now connect the components together in a <code>LocalProcess</code>.</p> In\u00a0[\u00a0]: Copied! <pre>process = LocalProcess(\n    components=[input_data, total, output_data],\n    connectors=[\n        # Connect input_data to total\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"input_data.value\", target=\"total.value\"),\n        ),\n        # Connect total to output_data\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"total.total_value\", target=\"output_data.value_to_save\"),\n        ),\n    ],\n)\n</pre> process = LocalProcess(     components=[input_data, total, output_data],     connectors=[         # Connect input_data to total         AsyncioConnector(             spec=ConnectorSpec(source=\"input_data.value\", target=\"total.value\"),         ),         # Connect total to output_data         AsyncioConnector(             spec=ConnectorSpec(source=\"total.total_value\", target=\"output_data.value_to_save\"),         ),     ], ) <p>Now we can initialise and run the simulation.</p> In\u00a0[\u00a0]: Copied! <pre>async with process:\n    await process.run()\n</pre> async with process:     await process.run() <p>Finally check we have the output data saved in <code>output.csv</code>.</p> In\u00a0[\u00a0]: Copied! <pre>!cat output.csv\n</pre> !cat output.csv"},{"location":"examples/demos/fundamentals/001_simple_model/simple-model/#simple-3-node-model","title":"Simple 3-node model\u00b6","text":"<p>This model demonstrates how to create different types of component and link them together. We use a built-in plugboard component to load timeseries data from a CSV file. A second node computes a rolling sum of these values. Finally another built-in component saves the output to a different CSV.</p>"},{"location":"examples/demos/llm/001_data_filter/llm-filtering/","title":"LLM for data filtering","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nfrom getpass import getpass\n\nimport pandas as pd\nfrom pydantic import BaseModel\n\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.schemas import ConnectorSpec\nfrom plugboard.process import LocalProcess\nfrom plugboard.library import FileReader, FileWriter, LLMChat\n</pre> import os from getpass import getpass  import pandas as pd from pydantic import BaseModel  from plugboard.connector import AsyncioConnector from plugboard.schemas import ConnectorSpec from plugboard.process import LocalProcess from plugboard.library import FileReader, FileWriter, LLMChat In\u00a0[\u00a0]: Copied! <pre>if \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n</pre> if \"OPENAI_API_KEY\" not in os.environ:     os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \") <p>The <code>FileReader</code> and <code>FileWriter</code> components are provided by plugboard: set the up to load the input CSV file and save the model result to <code>output.csv</code>.</p> In\u00a0[\u00a0]: Copied! <pre>input_data = FileReader(name=\"input_data\", path=\"input.csv\", field_names=[\"temperature\"])\noutput_data = FileWriter(\n    name=\"output_data\",\n    path=\"output.csv\",\n    field_names=[\"raw_temperature\", \"corrected_temperature\", \"was_corrected\"],\n)\n</pre> input_data = FileReader(name=\"input_data\", path=\"input.csv\", field_names=[\"temperature\"]) output_data = FileWriter(     name=\"output_data\",     path=\"output.csv\",     field_names=[\"raw_temperature\", \"corrected_temperature\", \"was_corrected\"], ) <p>For the noise filter, we need to set up an <code>LLMChat</code> component to correct the temperature readings. To do this we need:</p> <ol> <li>A Pydantic response model to specify the format we would like the output in;</li> <li>A system prompt that provides instructions to the LLM about how we would like the data corrected;</li> <li>Configuration on <code>LLMChat</code> to keep context in the chat history, so that the model knows about previous values of the temperature that it has seen.</li> </ol> In\u00a0[\u00a0]: Copied! <pre>class CleanTemperature(BaseModel):\n    temperature: float\n    was_corrected: bool\n\n\nsystem_prompt = \"\"\"\nYou are going to receive temperature values read from a sensor. These frequently contain errors that need to be corrected.\nExample errors are: missing decimal point, missing digit, decimal point in the wrong place, etc.\nYou need to correct the temperature values and indicate whether they were corrected or not.\nFor context, the temperature values are in Celsius and are not expected to change more than 2 degrees between readings.\nIf you cannot tell what the correct value should be you should output the last known correct value.\n\"\"\"\n\nllm = LLMChat(\n    name=\"llm\",\n    system_prompt=system_prompt,\n    # This needs GPT-4o or similar to work well\n    llm_kwargs={\"model\": \"gpt-4o\"},\n    response_model=CleanTemperature,\n    # Expand the response into separate fields: llm.temperature and llm.was_corrected\n    expand_response=True,\n    # Include context so that the model can use the last known correct value\n    context_window=5,\n)\n</pre> class CleanTemperature(BaseModel):     temperature: float     was_corrected: bool   system_prompt = \"\"\" You are going to receive temperature values read from a sensor. These frequently contain errors that need to be corrected. Example errors are: missing decimal point, missing digit, decimal point in the wrong place, etc. You need to correct the temperature values and indicate whether they were corrected or not. For context, the temperature values are in Celsius and are not expected to change more than 2 degrees between readings. If you cannot tell what the correct value should be you should output the last known correct value. \"\"\"  llm = LLMChat(     name=\"llm\",     system_prompt=system_prompt,     # This needs GPT-4o or similar to work well     llm_kwargs={\"model\": \"gpt-4o\"},     response_model=CleanTemperature,     # Expand the response into separate fields: llm.temperature and llm.was_corrected     expand_response=True,     # Include context so that the model can use the last known correct value     context_window=5, ) <p>Now connect the components together in a <code>LocalProcess</code>.</p> In\u00a0[\u00a0]: Copied! <pre>process = LocalProcess(\n    components=[input_data, llm, output_data],\n    connectors=[\n        # Connect input_data to LLM\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"input_data.temperature\", target=\"llm.prompt\"),\n        ),\n        # Connect both the raw input and LLM output to the output_data\n        AsyncioConnector(\n            spec=ConnectorSpec(\n                source=\"input_data.temperature\", target=\"output_data.raw_temperature\"\n            )\n        ),\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"llm.temperature\", target=\"output_data.corrected_temperature\")\n        ),\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"llm.was_corrected\", target=\"output_data.was_corrected\")\n        ),\n    ],\n)\n</pre> process = LocalProcess(     components=[input_data, llm, output_data],     connectors=[         # Connect input_data to LLM         AsyncioConnector(             spec=ConnectorSpec(source=\"input_data.temperature\", target=\"llm.prompt\"),         ),         # Connect both the raw input and LLM output to the output_data         AsyncioConnector(             spec=ConnectorSpec(                 source=\"input_data.temperature\", target=\"output_data.raw_temperature\"             )         ),         AsyncioConnector(             spec=ConnectorSpec(source=\"llm.temperature\", target=\"output_data.corrected_temperature\")         ),         AsyncioConnector(             spec=ConnectorSpec(source=\"llm.was_corrected\", target=\"output_data.was_corrected\")         ),     ], ) <p>Now we can initialise and run the simulation.</p> In\u00a0[\u00a0]: Copied! <pre>async with process:\n    await process.run()\n</pre> async with process:     await process.run() <p>Now take a look at the data in <code>output.csv</code> and see how the model did.</p> In\u00a0[\u00a0]: Copied! <pre>pd.read_csv(\"output.csv\")\n</pre> pd.read_csv(\"output.csv\")","tags":["llm"]},{"location":"examples/demos/llm/001_data_filter/llm-filtering/#llm-for-data-filtering","title":"LLM for data filtering\u00b6","text":"<p>This model is a simple demonstration of how to use an LLM in a Plugboard model. In this case, we're going to use it to filter noisy data. The <code>input.csv</code> contains a sample of some temperature data that has been corrupted by various errors. We use the LLM to make corrections to the data where necessary.</p> <p>To run this model you will need to set the <code>OPENAI_API_KEY</code> environment variable.</p>","tags":["llm"]},{"location":"examples/demos/llm/002_bluesky_websocket/bluesky-websocket/","title":"Streaming data: processing a websocket feed","text":"In\u00a0[\u00a0]: Copied! <pre>import asyncio\nimport os\nimport typing as _t\nfrom getpass import getpass\n\nimport httpx\nfrom pydantic import BaseModel, Field\n\nfrom plugboard.component import Component, IOController\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.schemas import ConnectorSpec\nfrom plugboard.process import LocalProcess\nfrom plugboard.library import FileWriter, LLMChat, WebsocketReader\n</pre> import asyncio import os import typing as _t from getpass import getpass  import httpx from pydantic import BaseModel, Field  from plugboard.component import Component, IOController from plugboard.connector import AsyncioConnector from plugboard.schemas import ConnectorSpec from plugboard.process import LocalProcess from plugboard.library import FileWriter, LLMChat, WebsocketReader In\u00a0[\u00a0]: Copied! <pre>if \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n</pre> if \"OPENAI_API_KEY\" not in os.environ:     os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \") <p>We'll subscribe to BlueSky posts from the following news outlets.</p> <ul> <li>Reuters</li> <li>Bloomberg</li> <li>CNBC</li> <li>Financial Times</li> <li>Wall Street Journal</li> <li>Yahoo Finance</li> </ul> <p>The BlueSky API filters according to DIDs - a unique identifier for each user that we'll need to lookup.</p> In\u00a0[\u00a0]: Copied! <pre>async def fetch_bluesky_did(client: httpx.AsyncClient, user_name: str) -&gt; str:\n    response = await client.get(\n        \"https://bsky.social/xrpc/com.atproto.identity.resolveHandle\", params={\"handle\": user_name}\n    )\n    return response.json()[\"did\"]\n</pre> async def fetch_bluesky_did(client: httpx.AsyncClient, user_name: str) -&gt; str:     response = await client.get(         \"https://bsky.social/xrpc/com.atproto.identity.resolveHandle\", params={\"handle\": user_name}     )     return response.json()[\"did\"] In\u00a0[\u00a0]: Copied! <pre>user_handles = [\n    \"reuters.com\",\n    \"bloomberg.com\",\n    \"cnbc.com\",\n    \"financialtimes.com\",\n    \"wsj.com\",\n    \"yahoofinance.com\",\n]\nasync with httpx.AsyncClient() as client:\n    bluesky_dids = await asyncio.gather(\n        *[fetch_bluesky_did(client, handle) for handle in user_handles]\n    )\n# Bluesky uses the \"wantedDids\" parameter to specify the DIDs of the users we want to filter\nfilter_spec = \"&amp;\".join([f\"wantedDids={did}\" for did in bluesky_dids])\n</pre> user_handles = [     \"reuters.com\",     \"bloomberg.com\",     \"cnbc.com\",     \"financialtimes.com\",     \"wsj.com\",     \"yahoofinance.com\", ] async with httpx.AsyncClient() as client:     bluesky_dids = await asyncio.gather(         *[fetch_bluesky_did(client, handle) for handle in user_handles]     ) # Bluesky uses the \"wantedDids\" parameter to specify the DIDs of the users we want to filter filter_spec = \"&amp;\".join([f\"wantedDids={did}\" for did in bluesky_dids]) <p>Now we have the DIDs for BlueSky, setup a <code>WebsocketReader</code> to stream posts into a Plugboard process. Using the Jetstream instructions we'll filter on posts from the users we are interested in.</p> In\u00a0[\u00a0]: Copied! <pre>websocket = WebsocketReader(\n    name=\"bluesky-feed\",\n    uri=f\"wss://jetstream2.us-east.bsky.network/subscribe?wantedCollections=app.bsky.feed.post&amp;{filter_spec}\",\n    parse_json=True,\n)\n</pre> websocket = WebsocketReader(     name=\"bluesky-feed\",     uri=f\"wss://jetstream2.us-east.bsky.network/subscribe?wantedCollections=app.bsky.feed.post&amp;{filter_spec}\",     parse_json=True, ) <p>Next we need a <code>Component</code> to extract the post text and timestamp each message received from BlueSky.</p> In\u00a0[\u00a0]: Copied! <pre>class ExtractMessage(Component):\n    \"\"\"Extracts text and timestamp from a BlueSky message dictionary.\"\"\"\n\n    io = IOController(inputs=[\"message\"], outputs=[\"text\", \"time_stamp\"])\n\n    async def step(self) -&gt; None:\n        try:\n            # Surround text with quotes so that is is correctly formatted in CSV output\n            self.text = f'\"{websocket.message[\"commit\"][\"record\"][\"text\"].replace(\"\\n\", \" \")}\"'\n            self.time_stamp = websocket.message[\"commit\"][\"record\"][\"createdAt\"]\n        except KeyError:\n            # Skip messages that aren't correctly formatted\n            pass\n\n\nextract = ExtractMessage(name=\"extract-message\")\n</pre> class ExtractMessage(Component):     \"\"\"Extracts text and timestamp from a BlueSky message dictionary.\"\"\"      io = IOController(inputs=[\"message\"], outputs=[\"text\", \"time_stamp\"])      async def step(self) -&gt; None:         try:             # Surround text with quotes so that is is correctly formatted in CSV output             self.text = f'\"{websocket.message[\"commit\"][\"record\"][\"text\"].replace(\"\\n\", \" \")}\"'             self.time_stamp = websocket.message[\"commit\"][\"record\"][\"createdAt\"]         except KeyError:             # Skip messages that aren't correctly formatted             pass   extract = ExtractMessage(name=\"extract-message\") <p>Next, let's setup an LLM component to analyse the messages as they arrive from BlueSky and carry out sentiment analysis. We'll use the LLM in structured-output mode, so that we have known outputs from the component.</p> In\u00a0[\u00a0]: Copied! <pre>class MessageInformation(BaseModel):\n    category: _t.Literal[\"markets\", \"companies\", \"economics\", \"other\"]\n    market_relevance: float = Field(..., ge=0, le=100)\n    sentiment: _t.Literal[\"positive\", \"negative\", \"neutral\"]\n\n\nsystem_prompt = \"\"\"\nYou are going to be shown headlines from business news services. For each headline, please provide the following:\n- The category of the headline (markets, companies, economics, other)\n- The market relevance of the headline to financial markets on a scale of 0 (least relevant) to 100 (most relevant)\n- The sentiment of the headline (positive, negative, neutral).\n\"\"\"\n\nllm = LLMChat(\n    name=\"llm\",\n    system_prompt=system_prompt,\n    llm_kwargs={\"model\": \"gpt-4o\"},\n    response_model=MessageInformation,\n    # Expand the response into separate fields\n    expand_response=True,\n)\n</pre> class MessageInformation(BaseModel):     category: _t.Literal[\"markets\", \"companies\", \"economics\", \"other\"]     market_relevance: float = Field(..., ge=0, le=100)     sentiment: _t.Literal[\"positive\", \"negative\", \"neutral\"]   system_prompt = \"\"\" You are going to be shown headlines from business news services. For each headline, please provide the following: - The category of the headline (markets, companies, economics, other) - The market relevance of the headline to financial markets on a scale of 0 (least relevant) to 100 (most relevant) - The sentiment of the headline (positive, negative, neutral). \"\"\"  llm = LLMChat(     name=\"llm\",     system_prompt=system_prompt,     llm_kwargs={\"model\": \"gpt-4o\"},     response_model=MessageInformation,     # Expand the response into separate fields     expand_response=True, ) <p>Finally, we'll use the <code>FileWriter</code> component to save the output to CSV.</p> In\u00a0[\u00a0]: Copied! <pre># Set chunk size to 1 so that data is saved to disk as each message arrives\nsave = FileWriter(\n    name=\"save\",\n    path=\"bluesky-messages.csv\",\n    chunk_size=1,\n    field_names=[\"text\", \"time_stamp\", \"category\", \"market_relevance\", \"sentiment\"],\n)\n</pre> # Set chunk size to 1 so that data is saved to disk as each message arrives save = FileWriter(     name=\"save\",     path=\"bluesky-messages.csv\",     chunk_size=1,     field_names=[\"text\", \"time_stamp\", \"category\", \"market_relevance\", \"sentiment\"], ) <p>Now build the <code>LocalProcess</code> and connect all of the components together.</p> In\u00a0[\u00a0]: Copied! <pre>connect = lambda in_, out_: AsyncioConnector(spec=ConnectorSpec(source=in_, target=out_))\nprocess = LocalProcess(\n    components=[websocket, extract, llm, save],\n    connectors=[\n        # Connect websocket to extract\n        connect(\"bluesky-feed.message\", \"extract-message.message\"),\n        # Save the time_stamp and text from the extract component\n        connect(\"extract-message.time_stamp\", \"save.time_stamp\"),\n        connect(\"extract-message.text\", \"save.text\"),\n        # Connect the extracted message to the LLM\n        connect(\"extract-message.text\", \"llm.prompt\"),\n        # Connect the LLM outputs to the save component\n        connect(\"llm.category\", \"save.category\"),\n        connect(\"llm.market_relevance\", \"save.market_relevance\"),\n        connect(\"llm.sentiment\", \"save.sentiment\"),\n    ],\n)\n</pre> connect = lambda in_, out_: AsyncioConnector(spec=ConnectorSpec(source=in_, target=out_)) process = LocalProcess(     components=[websocket, extract, llm, save],     connectors=[         # Connect websocket to extract         connect(\"bluesky-feed.message\", \"extract-message.message\"),         # Save the time_stamp and text from the extract component         connect(\"extract-message.time_stamp\", \"save.time_stamp\"),         connect(\"extract-message.text\", \"save.text\"),         # Connect the extracted message to the LLM         connect(\"extract-message.text\", \"llm.prompt\"),         # Connect the LLM outputs to the save component         connect(\"llm.category\", \"save.category\"),         connect(\"llm.market_relevance\", \"save.market_relevance\"),         connect(\"llm.sentiment\", \"save.sentiment\"),     ], ) <p>Now run the model. The websocket input will run forever, continuing to stream new data, so when you are ready to stop the process you will need to manually interrupt it. Open the output CSV file to see the data that has been captured. Keep in mind that some of the news sources publish infrequently outside of their business hours, so depending on when you run the code you might need to leave it for a while to collect some data.</p> In\u00a0[\u00a0]: Copied! <pre>async with process:\n    await process.run()\n</pre> async with process:     await process.run()","tags":["llm","io","streaming"]},{"location":"examples/demos/llm/002_bluesky_websocket/bluesky-websocket/#streaming-data-processing-a-websocket-feed","title":"Streaming data: processing a websocket feed\u00b6","text":"<p>This model will run on a continuous stream of data provided by BlueSky's firehose websocket. We'll subscribe to posts from some business news feeds and then use an LLM to carry out sentiment analysis on each message.</p> <p>To run this model you will need to set the <code>OPENAI_API_KEY</code> environment variable.</p>","tags":["llm","io","streaming"]},{"location":"examples/demos/physics-models/001-hot-water-tank/hot-water-tank/","title":"Hot water tank model","text":"In\u00a0[\u00a0]: Copied! <pre>import typing as _t\n\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.component import Component\nfrom plugboard.component import IOController as IO\nfrom plugboard.schemas import ComponentArgsDict, ConnectorSpec\nfrom plugboard.process import LocalProcess\nfrom plugboard.library import FileWriter\n</pre> import typing as _t  from plugboard.connector import AsyncioConnector from plugboard.component import Component from plugboard.component import IOController as IO from plugboard.schemas import ComponentArgsDict, ConnectorSpec from plugboard.process import LocalProcess from plugboard.library import FileWriter In\u00a0[\u00a0]: Copied! <pre>WATER_SPECIFIC_HEAT = 4186  # J/(kg\u00b0C)\nWATER_DENSITY = 1.0  # kg/L\n</pre> WATER_SPECIFIC_HEAT = 4186  # J/(kg\u00b0C) WATER_DENSITY = 1.0  # kg/L In\u00a0[\u00a0]: Copied! <pre>class HotWaterTank(Component):\n    \"\"\"This component represents an insulated hot water tank with an on/off heating element.\"\"\"\n\n    io = IO(inputs=[\"heating_element\", \"prev_temperature\"], outputs=[\"temperature\"])\n\n    def __init__(\n        self,\n        volume: float,\n        heater_power: float,\n        insulation_r: float,\n        ambient_temp: float,\n        delta_t: float = 60,\n        **kwargs: _t.Unpack[ComponentArgsDict],\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        # Set the initial running total to 0\n        self._heater_power_watts = heater_power * 1000  # W\n        self._water_mass = volume * WATER_DENSITY  # kg\n        self._heat_capacity = self._water_mass * WATER_SPECIFIC_HEAT  # J/\u00b0C\n        self._delta_t = delta_t  # s\n        self._insulation_r = insulation_r  # \u00b0C/W\n        self._ambient_temp = ambient_temp  # \u00b0C\n\n    async def step(self) -&gt; None:\n        # Apply heater power to the water\n        self.temperature = self.prev_temperature\n        if self.heating_element:\n            self.temperature += self._heater_power_watts * self._delta_t / self._heat_capacity\n        # Apply heat loss to the environment\n        heat_loss = (\n            (self.prev_temperature - self._ambient_temp) / self._insulation_r * self._delta_t\n        )\n        self.temperature -= heat_loss / self._heat_capacity\n</pre> class HotWaterTank(Component):     \"\"\"This component represents an insulated hot water tank with an on/off heating element.\"\"\"      io = IO(inputs=[\"heating_element\", \"prev_temperature\"], outputs=[\"temperature\"])      def __init__(         self,         volume: float,         heater_power: float,         insulation_r: float,         ambient_temp: float,         delta_t: float = 60,         **kwargs: _t.Unpack[ComponentArgsDict],     ) -&gt; None:         super().__init__(**kwargs)         # Set the initial running total to 0         self._heater_power_watts = heater_power * 1000  # W         self._water_mass = volume * WATER_DENSITY  # kg         self._heat_capacity = self._water_mass * WATER_SPECIFIC_HEAT  # J/\u00b0C         self._delta_t = delta_t  # s         self._insulation_r = insulation_r  # \u00b0C/W         self._ambient_temp = ambient_temp  # \u00b0C      async def step(self) -&gt; None:         # Apply heater power to the water         self.temperature = self.prev_temperature         if self.heating_element:             self.temperature += self._heater_power_watts * self._delta_t / self._heat_capacity         # Apply heat loss to the environment         heat_loss = (             (self.prev_temperature - self._ambient_temp) / self._insulation_r * self._delta_t         )         self.temperature -= heat_loss / self._heat_capacity In\u00a0[\u00a0]: Copied! <pre>class ThermostatController(Component):\n    \"\"\"This component represents a thermostat with hysteresis.\"\"\"\n\n    io = IO(inputs=[\"setpoint\", \"temperature\"], outputs=[\"heating_element\"])\n\n    def __init__(self, hysteresis: float, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._hysteresis = hysteresis\n\n    async def step(self) -&gt; None:\n        if self.temperature &lt; self.setpoint - self._hysteresis:\n            self.heating_element = True\n        elif self.temperature &gt; self.setpoint + self._hysteresis:\n            self.heating_element = False\n</pre> class ThermostatController(Component):     \"\"\"This component represents a thermostat with hysteresis.\"\"\"      io = IO(inputs=[\"setpoint\", \"temperature\"], outputs=[\"heating_element\"])      def __init__(self, hysteresis: float, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._hysteresis = hysteresis      async def step(self) -&gt; None:         if self.temperature &lt; self.setpoint - self._hysteresis:             self.heating_element = True         elif self.temperature &gt; self.setpoint + self._hysteresis:             self.heating_element = False <p>We'll use a <code>Constant</code> value to represent the setpoint and trigger the rest of the model.</p> In\u00a0[\u00a0]: Copied! <pre>class Constant(Component):\n    \"\"\"This component represents a constant value.\"\"\"\n\n    io = IO(outputs=[\"value\"])\n\n    def __init__(\n        self, value: float, n_iterations: int, **kwargs: _t.Unpack[ComponentArgsDict]\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self.value = value\n        self._remaining_iterations = n_iterations\n\n    async def step(self) -&gt; None:\n        self._remaining_iterations -= 1\n        if self._remaining_iterations &lt;= 0:\n            await self.io.close()\n</pre> class Constant(Component):     \"\"\"This component represents a constant value.\"\"\"      io = IO(outputs=[\"value\"])      def __init__(         self, value: float, n_iterations: int, **kwargs: _t.Unpack[ComponentArgsDict]     ) -&gt; None:         super().__init__(**kwargs)         self.value = value         self._remaining_iterations = n_iterations      async def step(self) -&gt; None:         self._remaining_iterations -= 1         if self._remaining_iterations &lt;= 0:             await self.io.close() In\u00a0[\u00a0]: Copied! <pre>setpoint = Constant(name=\"setpoint\", value=60, n_iterations=24 * 60)\ntank = HotWaterTank(\n    name=\"tank\",\n    initial_values={\"prev_temperature\": [58], \"heating_element\": [False]},\n    volume=150,\n    heater_power=1.1,\n    insulation_r=0.9,\n    ambient_temp=20,\n)\nthermostat = ThermostatController(name=\"controller\", hysteresis=1)\nsave = FileWriter(\n    name=\"save\", path=\"temperature.csv\", field_names=[\"heater\", \"temperature\", \"setpoint\"]\n)\n</pre> setpoint = Constant(name=\"setpoint\", value=60, n_iterations=24 * 60) tank = HotWaterTank(     name=\"tank\",     initial_values={\"prev_temperature\": [58], \"heating_element\": [False]},     volume=150,     heater_power=1.1,     insulation_r=0.9,     ambient_temp=20, ) thermostat = ThermostatController(name=\"controller\", hysteresis=1) save = FileWriter(     name=\"save\", path=\"temperature.csv\", field_names=[\"heater\", \"temperature\", \"setpoint\"] ) <p>Now connect the components together in a <code>LocalProcess</code>.</p> In\u00a0[\u00a0]: Copied! <pre>process = LocalProcess(\n    components=[setpoint, tank, thermostat, save],\n    connectors=[\n        # Connect setpoint to controller\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"setpoint.value\", target=\"controller.setpoint\"),\n        ),\n        # Connect controller to tank\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"controller.heating_element\", target=\"tank.heating_element\"),\n        ),\n        # Connect tank to controller\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"tank.temperature\", target=\"controller.temperature\"),\n        ),\n        # Connect tank to itself to save the previous temperature\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"tank.temperature\", target=\"tank.prev_temperature\"),\n        ),\n        # Connect tank, controller and setpoint to save\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"tank.temperature\", target=\"save.temperature\"),\n        ),\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"controller.heating_element\", target=\"save.heater\"),\n        ),\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"setpoint.value\", target=\"save.setpoint\"),\n        ),\n    ],\n)\n</pre> process = LocalProcess(     components=[setpoint, tank, thermostat, save],     connectors=[         # Connect setpoint to controller         AsyncioConnector(             spec=ConnectorSpec(source=\"setpoint.value\", target=\"controller.setpoint\"),         ),         # Connect controller to tank         AsyncioConnector(             spec=ConnectorSpec(source=\"controller.heating_element\", target=\"tank.heating_element\"),         ),         # Connect tank to controller         AsyncioConnector(             spec=ConnectorSpec(source=\"tank.temperature\", target=\"controller.temperature\"),         ),         # Connect tank to itself to save the previous temperature         AsyncioConnector(             spec=ConnectorSpec(source=\"tank.temperature\", target=\"tank.prev_temperature\"),         ),         # Connect tank, controller and setpoint to save         AsyncioConnector(             spec=ConnectorSpec(source=\"tank.temperature\", target=\"save.temperature\"),         ),         AsyncioConnector(             spec=ConnectorSpec(source=\"controller.heating_element\", target=\"save.heater\"),         ),         AsyncioConnector(             spec=ConnectorSpec(source=\"setpoint.value\", target=\"save.setpoint\"),         ),     ], ) <p>Now we can initialise and run the simulation.</p> In\u00a0[\u00a0]: Copied! <pre>async with process:\n    await process.run()\n</pre> async with process:     await process.run() <p>Finally check we have the output data saved in <code>temperature.csv</code>.</p> In\u00a0[\u00a0]: Copied! <pre>try:\n    import pandas as pd\n\n    fig = pd.read_csv(\"temperature.csv\").plot(\n        backend=\"plotly\",\n        y=[\"temperature\", \"setpoint\"],\n        title=\"Temperature vs. Setpoint\",\n        labels={\"index\": \"Time (min)\", \"value\": \"Temperature (\u00b0C)\"},\n    )\nexcept (ImportError, ValueError):\n    print(\"Please install plotly to run this cell.\")\n    fig = None\nfig\n</pre> try:     import pandas as pd      fig = pd.read_csv(\"temperature.csv\").plot(         backend=\"plotly\",         y=[\"temperature\", \"setpoint\"],         title=\"Temperature vs. Setpoint\",         labels={\"index\": \"Time (min)\", \"value\": \"Temperature (\u00b0C)\"},     ) except (ImportError, ValueError):     print(\"Please install plotly to run this cell.\")     fig = None fig","tags":["physics-models"]},{"location":"examples/demos/physics-models/001-hot-water-tank/hot-water-tank/#hot-water-tank-model","title":"Hot water tank model\u00b6","text":"<p>This model demonstrates how Plugboard can be used to connect physics-based models. We'll build a component to simulate the temperature of an insulated hot-water tank, along with another to control the tank's heating element.</p>","tags":["physics-models"]},{"location":"examples/tutorials/event-driven-models/","title":"Event-driven models","text":"<p>Tutorial coming soon.</p>","tags":["tutorial"]},{"location":"examples/tutorials/hello-world/","title":"Hello world","text":"<p>Plugboard is built to help you with two things: defining process models, and executing those models. There are two main ways to interact with Plugboard: via the Python API; or, via the CLI using model definitions saved in yaml format. In this introductory tutorial we'll do both, before building up to more complex models in later tutorials.</p>","tags":["tutorial"]},{"location":"examples/tutorials/hello-world/#building-models-with-the-python-api","title":"Building models with the Python API","text":"<p>First we start by defining each <code>Component</code> we want in our model. Components can have only inputs, only outputs, or both. To keep it simple we just have two components here, showing the most basic functionality. Each component has several methods which are called at different stages during model execution: <code>init</code> for optional initialisation actions; <code>step</code> to take a single step forward through time; <code>run</code> to execute all steps; and <code>destroy</code> for optional teardown actions.</p> <p>Info</p> <p>A model is made up of one or more components, though Plugboard really shines when you have many!</p>","tags":["tutorial"]},{"location":"examples/tutorials/hello-world/#defining-components","title":"Defining components","text":"<p>Let's define two components, <code>A</code> and <code>B</code>. <code>A</code> puts data into the model by generating numbers from a sequence. <code>B</code> takes input from <code>A</code>, doubles it, then saves it to a file. We build each component as a reusable Python class, implementing the main logic in a <code>step</code> method. <pre><code>import asyncio\nimport typing as _t\n\nfrom plugboard.component import Component, IOController as IO\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.process import LocalProcess\nfrom plugboard.schemas import ComponentArgsDict, ConnectorSpec\n\nclass A(Component):\n    io = IO(outputs=[\"out_1\"]) # (1)!\n\n    def __init__(self, iters: int, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._iters = iters\n\n    async def init(self) -&gt; None:\n        self._seq = iter(range(self._iters)) # (2)!\n\n    async def step(self) -&gt; None:\n        try:\n            self.out_1 = next(self._seq) # (3)!\n        except StopIteration:\n            await self.io.close() # (5)!\n\nclass B(Component):\n    io = IO(inputs=[\"in_1\"])\n\n    def __init__(self, path: str, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._path = path\n\n    async def init(self) -&gt; None:\n        self._f = open(self._path, \"w\")\n\n    async def step(self) -&gt; None:\n        out = 2 * self.in_1\n        self._f.write(f\"{out}\\n\")\n\n    async def destroy(self) -&gt; None:\n        self._f.close() # (4)!\n</code></pre></p> <ol> <li>This is where we configure the inputs and outputs for each <code>Component</code>.</li> <li><code>init</code> gets called before we run the model. It is optional, and used for any setup required on the <code>Component</code>.</li> <li><code>step</code> gets called at each step forward throughout the model execution. This is where the main business logic must be defined.</li> <li><code>destroy</code> is optional, and can be used to clean up any resources used by the <code>Component</code>.</li> <li><code>A</code> is responsible for stopping the model when it is complete, which we can do by calling <code>self.io.close()</code>.</li> </ol> <p>Note</p> <ul> <li>Each component has an <code>io</code> attribute in its definition, where we specify the names of the inputs and outputs. In this simple example, <code>A</code> has a single output, while <code>B</code> has a single input.</li> <li>During the <code>step</code> method, the inputs and outputs are available as attributes: so assigning to <code>self.out_1</code> lets us set the output of <code>A</code>, and reading <code>self.in_1</code> allows us to read the input of <code>B</code>.</li> <li>Notice how each component can have additional parameters in the <code>__init__</code> constructor, allowing us to give our components configurable settings like the output file path.</li> </ul>","tags":["tutorial"]},{"location":"examples/tutorials/hello-world/#setting-up-a-process","title":"Setting up a <code>Process</code>","text":"<p>Now we take these components, connect them up as a <code>Process</code>, and fire off the model. When instantiating each component we must provide a <code>name</code>, which we can use to help define the connections between them. Using a <code>ConnectorSpec</code> object, we tell Plugboard to connect the <code>out_1</code> output of the <code>a</code> component to the <code>in_1</code> input of <code>b</code>. Visually, the model will look like this:</p> <pre><code>flowchart LR\n    a@{ shape: rounded, label: A&lt;br&gt;**a** } --&gt; b@{ shape: rounded, label: B&lt;br&gt;**b** }</code></pre> <p>The rest of the code is boilerplate: calling <code>run()</code> on the <code>Process</code> object triggers all the components to start iterating through all their inputs until a termination condition is reached. We're using <code>LocalProcess</code> here, because we are running this model locally with no parallel computation (will explore this in a later tutorial).</p> <p>Simulations proceed in an event-driven manner: when inputs arrive, the components are triggered to step forward in time. The framework handles the details of the inter-component communication, you just need to specify the logic of your components, and the connections between them. <pre><code>process = LocalProcess(\n    components=[A(name=\"a\", iters=5), B(name=\"b\", path=\"b.txt\")],\n    connectors=[\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"a.out_1\", target=\"b.in_1\"),\n        )\n    ],\n)\nasync with process:\n    await process.run()\n</code></pre></p>","tags":["tutorial"]},{"location":"examples/tutorials/hello-world/#executing-pre-defined-models-on-the-cli","title":"Executing pre-defined models on the CLI","text":"<p>In many cases, we want to define components once, with suitable parameters, and then use them repeatedly in different simulations. Plugboard enables this workflow with model specification files yaml format. Once the components have been defined, the simple model above can be represented with a yaml file like this: <pre><code>plugboard:\n  process:\n    args:\n      components:\n      - type: hello_world.A  # (1)!\n        args:\n          name: \"a\"\n          iters: 10  # (2)!\n      - type: hello_world.B\n        args:\n          name: \"b\"\n          path: \"./b.txt\"\n      connectors:\n      - source: \"a.out_1\"\n        target: \"b.in_1\"\n</code></pre></p> <ol> <li>This identifies the <code>A</code> class within the <code>hello_world</code> module.</li> <li>The <code>iters</code> parameter is required for the component - try adjusting to change how long the model runs for.</li> </ol> <p>Note</p> <p>Notice how we use <code>type</code> to tell Plugboard where our components are defined within Python code (within the <code>hello_world</code> module). Creating models in yaml format like this also makes it easy to track and adjust their configurable parameters: try editing the file path or <code>iters</code> parameter to change the behaviour of the model.</p> <p>We can now run this model using the plugboard CLI with the command: <pre><code>plugboard process run model.yaml\n</code></pre></p> <p>You should see that an output <code>.txt</code> file has been created, showing the the model as run successfully. Congratulations - you have built and run your first Plugboard model!</p> <p>In the following tutorials we will build up some more complex components and processes to demonstrate the power of the framework.</p>","tags":["tutorial"]},{"location":"examples/tutorials/more-complex-process/","title":"A more complex process","text":"<p>In the last example our <code>Process</code> consisted of just two components. Usually we use many more components, allowing you to break down your model into separate parts that you can build/test individually. Plugboard allows for branching and looping connections between your components.</p> <p>In this tutorial we'll also demonstrate how to make components reusable between different processes.</p>","tags":["tutorial"]},{"location":"examples/tutorials/more-complex-process/#define-some-components","title":"Define some components","text":"<p>First of all, let's define five different components:</p> <ul> <li><code>Random</code> will generate random numbers to feed into our model;</li> <li><code>Offset</code> adds a fixed offset to its inputs;</li> <li><code>Scale</code> will multiple its input by a fixed scale factor;</li> <li><code>Sum</code> will take in two inputs and add them together;</li> <li><code>Save</code> will write its input to a text file.</li> </ul> <p>We can put the code for each of these in <code>components.py</code>. <pre><code>import random\nimport typing as _t\n\nfrom plugboard.component import Component, IOController as IO\nfrom plugboard.schemas import ComponentArgsDict\n\nclass Random(Component):\n    io = IO(outputs=[\"x\"])\n\n    def __init__(\n            self,\n            iters: int,  # (1)!\n            low: float = 0,\n            high: float = 10,\n            **kwargs: _t.Unpack[ComponentArgsDict]\n        ) -&gt; None:\n        super().__init__(**kwargs)\n        self._iters = 0\n        self._low = low\n        self._high = high\n        self._max_iters = iters\n\n    async def step(self) -&gt; None:\n        if self._iters &lt; self._max_iters:\n            self.x = random.uniform(self._low, self._high)\n            self._iters += 1\n            return\n        await self.io.close()\n\nclass Offset(Component):\n    \"\"\"Implements `x = a + offset`.\"\"\"\n    io = IO(inputs=[\"a\"], outputs=[\"x\"]) # (2)!\n\n    def __init__(self, offset: float = 0, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._offset = offset\n\n    async def step(self) -&gt; None:\n        self.x = self.a + self._offset\n\nclass Scale(Component):\n    \"\"\"Implements `x = a * scale`.\"\"\"\n    io = IO(inputs=[\"a\"], outputs=[\"x\"])\n\n    def __init__(self, scale: float = 1, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._scale = scale\n\n    async def step(self) -&gt; None:\n        self.x = self.a * self._scale\n\nclass Sum(Component):\n    \"\"\"Implements `x = a + b`.\"\"\"\n    io = IO(inputs=[\"a\", \"b\"], outputs=[\"x\"]) # (3)!\n\n    async def step(self) -&gt; None:\n        self.x = self.a + self.b\n\nclass Save(Component):\n    io = IO(inputs=[\"value_to_save\"])\n\n    def __init__(self, path: str, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._path = path\n\n    async def init(self) -&gt; None:\n        self._f = open(self._path, \"w\")\n\n    async def step(self) -&gt; None:\n        self._f.write(f\"{self.value_to_save}\\n\")\n\n    async def destroy(self) -&gt; None:\n        self._f.close()\n</code></pre></p> <ol> <li>The <code>Component</code> needs three different parameters: <code>iters</code> to control how many iterations the model runs for, <code>low</code> and <code>high</code> to control the range of the random number generator.</li> <li>A <code>Component</code> with both inputs and outputs.</li> <li>Here we have multiple inputs.</li> </ol>","tags":["tutorial"]},{"location":"examples/tutorials/more-complex-process/#create-branching-connections-in-a-process","title":"Create branching connections in a <code>Process</code>","text":"<p>Next, we'll connect the components together to form this model:</p> <pre><code>flowchart LR\n    offset@{ shape: rounded, label: Offset&lt;br&gt;**offset** } --&gt; sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** }\n    random@{ shape: rounded, label: Random&lt;br&gt;**random** } --&gt; offset@{ shape: rounded, label: Offset&lt;br&gt;**offset** }\n    random@{ shape: rounded, label: Random&lt;br&gt;**random** } ----&gt; save-input@{ shape: rounded, label: Save&lt;br&gt;**save-input** }\n    random@{ shape: rounded, label: Random&lt;br&gt;**random** } --&gt; scale@{ shape: rounded, label: Scale&lt;br&gt;**scale** }\n    scale@{ shape: rounded, label: Scale&lt;br&gt;**scale** } --&gt; sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** }\n    sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** } --&gt; save-output@{ shape: rounded, label: Save&lt;br&gt;**save-output** }</code></pre> <p>Note</p> <p>See how we branch the output of the <code>Random</code> component into three different places: a <code>Save</code> component (so that we can record our model input), <code>Offset</code> and <code>Scale</code>.</p> <p>Now in <code>branching.py</code> we import these components, connect them together and run the model. <pre><code>import asyncio\n\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.process import LocalProcess\nfrom plugboard.schemas import ConnectorSpec\n\nfrom components import Offset, Random, Save, Scale, Sum\n\n\nasync def main() -&gt; None:\n    connect = lambda in_, out_: AsyncioConnector(  # (1)!\n        spec=ConnectorSpec(source=in_, target=out_)\n    )\n    process = LocalProcess(\n        components=[  # (2)!\n            Random(name=\"random\", iters=5, low=0, high=10),\n            Offset(name=\"offset\", offset=10),\n            Scale(name=\"scale\", scale=2),\n            Sum(name=\"sum\"),\n            Save(name=\"save-input\", path=\"input.txt\"),\n            Save(name=\"save-output\", path=\"output.txt\"),\n        ],\n        connectors=[  # (3)!\n            connect(\"random.x\", \"save-input.value_to_save\"),\n            connect(\"random.x\", \"offset.a\"),\n            connect(\"random.x\", \"scale.a\"),\n            connect(\"offset.x\", \"sum.a\"),\n            connect(\"scale.x\", \"sum.b\"),\n            connect(\"sum.x\", \"save-output.value_to_save\"),\n        ],\n    )\n    async with process:  # (3)!\n        await process.run()\n</code></pre></p> <ol> <li>We'll use this lambda to abbreviate the connectors below.</li> <li>Instantiate each of the components here with any necessary parameters.</li> <li>Here is where we define all of the connections in our model: <code>source</code> and <code>target</code> are of the form <code>component_name.io_name</code>. So the first item connects the <code>x</code> output on the <code>random</code> component to the <code>value_to_save</code> input on <code>save-input</code>.</li> <li>As in the previous tutorial, this is equivalent to calling <code>await process.init()</code>, followed by <code>await process.run()</code> and then <code>await process.destroy()</code>.</li> </ol> <p>Now run <code>python branching.py</code> and you will see the <code>input.txt</code> and <code>output.txt</code> files generated showing that the model has run.</p>","tags":["tutorial"]},{"location":"examples/tutorials/more-complex-process/#create-a-loop-connection","title":"Create a loop connection","text":"<p>In some cases you might want to create a loop in your model. This is commonly the case where you need to include feedback: for example you might have a component modelling the temperature of a heated hot-water tank and another one representing an automatic controller that turns the heating element on and off.</p> <p>To make models like this work in Plugboard you will need to specify <code>initial_values</code> somewhere in the loop: this ensures that each of the <code>Component</code> objects can get all their inputs at the first call to <code>process.step()</code>, allowing the model to start running.</p> <p>Consider this model in which the <code>Sum</code> component will accumulate a scaled part of its value at every iteration:</p> <pre><code>flowchart LR\n    random@{ shape: rounded, label: Random&lt;br&gt;**random** } --&gt; sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** }\n    scale@{ shape: rounded, label: Scale&lt;br&gt;**scale** } --&gt; sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** }\n    sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** } --&gt; save-output@{ shape: rounded, label: Save&lt;br&gt;**save-output** }\n    sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** } --&gt;|\"&lt;i&gt;a&lt;sub&gt;t=0&lt;/sub&gt;=0&lt;/i&gt;\"| scale@{ shape: rounded, label: Scale&lt;br&gt;**scale** }</code></pre> <p>Tip</p> <p>The diagrams in these tutorials are created in Mermaid syntax. You can make them directly in Plugboard using the <code>markdown_diagram</code> function. Alternatively if you have a YAML config file you can run <code>plugboard process diagram your-yaml-file.yaml</code> on the command line.</p> <p>Creating diagrams can be a useful way to keep track of the different parts of your model as you build it out, and also helps to you to document how the model works.</p> <p>We'll provide an initial input value of <code>a = 0</code> to the <code>Scale</code> component, allowing the model to run. Implementing this in <code>loop.py</code> we have: <pre><code>import asyncio\n\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.process import LocalProcess\nfrom plugboard.schemas import ConnectorSpec\n\nfrom components import Random, Save, Scale, Sum\n\n\nasync def main() -&gt; None:\n    connect = lambda in_, out_: AsyncioConnector(\n        spec=ConnectorSpec(source=in_, target=out_)\n    )\n    process = LocalProcess(\n        components=[\n            Random(name=\"random\", iters=5, low=0, high=10),\n            Sum(name=\"sum\"),\n            Scale(name=\"scale\", initial_values={\"a\": [0]}, scale=0.5),  # (1)!\n            Save(name=\"save-output\", path=\"cumulative-sum.txt\"),\n        ],\n        connectors=[\n            connect(\"random.x\", \"sum.a\"),\n            connect(\"sum.x\", \"scale.a\"),\n            connect(\"scale.x\", \"sum.b\"),\n            connect(\"sum.x\", \"save-output.value_to_save\"),\n        ],\n    )\n    async with process:\n        await process.run()\n</code></pre></p> <ol> <li>We specify our initial value for the <code>Scale</code> input here.</li> </ol> <p>Note</p> <p>Initial values are specified as lists in Plugboard, allowing you to specify a sequence of them. The component will read the first element in the initial value at the first call to <code>step()</code> and so on until there are no more initial values left to consume. Usually you won't need more than one initial value, so the list typically contains a single element as in this example.</p> <p>Setting <code>initial_values = {\"a\": [0]}</code> means that we want the <code>a</code> input to be set to <code>0</code> on the first step and then revert to reading its input as usual.</p>","tags":["tutorial"]},{"location":"examples/tutorials/more-complex-process/#next-steps","title":"Next steps","text":"<p>You've now learned how to build up complex model layouts in Plugboard. In the next tutorial we'll show how powerful a Plugboard model can be as we start to include different types of <code>Component</code>.</p>","tags":["tutorial"]},{"location":"examples/tutorials/more-components/","title":"More components","text":"<p>Plugboard's <code>Component</code> objects can run anything you can code in Python. This includes:</p> <ul> <li>Using your own or third-party Python packages;</li> <li>External calls to APIs, e.g. data sources or hosted models;</li> <li>Shell commands on your own machine, for example to execute third-party binaries that you want to integrate with.</li> </ul> <p>It even ships with some pre-built components in <code>plugboard.library</code> to help you with common tasks.</p> <p>Info</p> <p>Plugboard was originally built to help data scientists working on industrial process simulations. Python provides a familar environment to integrate different parts of a simulation, for example combining the output of a traditional process control simulation with a machine-learning model.</p> <p>In this tutorial we'll build a model to process data through an LLM and showcase some different components along the way.</p>","tags":["tutorial","logging","llm","io"]},{"location":"examples/tutorials/more-components/#using-an-llm-in-plugboard","title":"Using an LLM in Plugboard","text":"<p>We're going to build a model that loads rows of data from a CSV and then uses an LLM to extract information about the geographical place referred to in each row. We'll then query an API to get the latest weather for each location.</p> <pre><code> flowchart LR\n    llm@{ shape: rounded, label: LLMChat&lt;br&gt;**llm** } --&gt; weather@{ shape: rounded, label: WeatherAPI&lt;br&gt;**weather** }\n    llm@{ shape: rounded, label: LLMChat&lt;br&gt;**llm** } --&gt; save-results@{ shape: rounded, label: FileWriter&lt;br&gt;**save-results** }\n    load-text@{ shape: rounded, label: FileReader&lt;br&gt;**load-text** } --&gt; llm@{ shape: rounded, label: LLMChat&lt;br&gt;**llm** }\n    weather@{ shape: rounded, label: WeatherAPI&lt;br&gt;**weather** } --&gt; save-results@{ shape: rounded, label: FileWriter&lt;br&gt;**save-results** }</code></pre>","tags":["tutorial","logging","llm","io"]},{"location":"examples/tutorials/more-components/#loading-and-saving-data","title":"Loading and saving data","text":"<p>In previous tutorials we wrote our own components for reading/writing files. Here we are going to use the built-in <code>FileReader</code> and <code>FileWriter</code> components. These are much more useful for building practical models, as they can access a variety of file formats both locally and in cloud storage. <pre><code>load_text = FileReader(name=\"load-text\", path=\"input.csv\", field_names=[\"text\"])\nsave_output = FileWriter(\n    name=\"save-results\",\n    path=\"output.csv\",\n    field_names=[\"location\", \"temperature\", \"wind_speed\"],\n)\n</code></pre></p>","tags":["tutorial","logging","llm","io"]},{"location":"examples/tutorials/more-components/#sending-the-data-to-an-llm","title":"Sending the data to an LLM","text":"<p>We're going to use the <code>LLMChat</code> to access OpenAI: <pre><code>llm = LLMChat(\n    name=\"llm\",\n    system_prompt=\"Identify a geographical location from the input and provide its latitude and longitude\",\n    response_model=Location,\n    expand_response=True,  # (2)!\n)\n</code></pre></p> <ol> <li><code>LLMChat</code> can use structured output to process the LLM response into a known format. Here we define a Pydantic model that specifies everything we're expecting back.</li> <li>Setting <code>expand_response = True</code> will unpack <code>location</code>, <code>latitude</code> and <code>longitude</code> into separate outputs on the component.</li> </ol> <p>Info</p> <p>To run this tutorial you'll need an API key for OpenAI. Set the <code>OPENAI_API_KEY</code> environment variable to provide it to the model.</p> <p>Since <code>LLMChat</code> is based on LlamaIndex you can even try reconfiguring <code>LLMChat</code> to use a different LLM.</p>","tags":["tutorial","logging","llm","io"]},{"location":"examples/tutorials/more-components/#querying-a-weather-api","title":"Querying a weather API","text":"<p>We can now define a component to query a weather API and get temperature and wind speed for a given location. <pre><code>class WeatherAPI(Component):\n    \"\"\"Get current weather for a location.\"\"\"\n\n    io = IO(inputs=[\"latitude\", \"longitude\"], outputs=[\"temperature\", \"wind_speed\"])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._client = httpx.AsyncClient()\n\n    async def step(self) -&gt; None:\n        response = await self._client.get(\n            \"https://api.open-meteo.com/v1/forecast\",\n            params={\n                \"latitude\": self.latitude,\n                \"longitude\": self.longitude,\n                \"current\": \"temperature_2m,wind_speed_10m\",\n            },\n        )\n        try:\n            response.raise_for_status()\n        except httpx.HTTPStatusError:\n            self._logger.error(\n                \"Error querying weather API\",\n                code=response.status_code,\n                message=response.text,\n            )\n            return\n        data = response.json()\n        self.temperature = data[\"current\"][\"temperature_2m\"]\n        self.wind_speed = data[\"current\"][\"wind_speed_10m\"]\n\nweather = WeatherAPI(name=\"weather\")\n</code></pre></p> <p>Info</p> <p>See how we used <code>self._logger</code> to record log messages. All Plugboard <code>Component</code> objects have a structlog logger on the <code>_logger</code> attribute. See configuration for more information on configuring the logging.</p>","tags":["tutorial","logging","llm","io"]},{"location":"examples/tutorials/more-components/#putting-it-all-together","title":"Putting it all together","text":"<p>As usual, we can link all our components together in a <code>LocalProcess</code> and run them as follows: <pre><code>connect = lambda in_, out_: AsyncioConnector(\n    spec=ConnectorSpec(source=in_, target=out_)\n)\nprocess = LocalProcess(\n    components=[load_text, llm, weather, save_output],\n    connectors=[\n        connect(\"load-text.text\", \"llm.prompt\"),\n        connect(\"llm.latitude\", \"weather.latitude\"),\n        connect(\"llm.longitude\", \"weather.longitude\"),\n        connect(\"llm.location\", \"save-results.location\"),\n        connect(\"weather.temperature\", \"save-results.temperature\"),\n        connect(\"weather.wind_speed\", \"save-results.wind_speed\"),\n    ],\n)\nasync with process:\n    await process.run()\n</code></pre></p> <p>Check out the <code>output.csv</code> file to see all of the collected model output.</p>","tags":["tutorial","logging","llm","io"]},{"location":"examples/tutorials/running-in-parallel/","title":"Running in parallel","text":"<p>Up until now we have running all our models in a single computational process. This is perfectly sufficient for simple models, or when your components can make use of Python's asyncio to avoid blocking.</p> <p>As your models get larger and more computationally intensive you may benefit from running parts of the model in parallel. Plugboard integrates with the Ray framework, allowing you to split your computation across multiple CPU cores, or even across nodes in a Ray cluster.</p> <p>Tip</p> <p>Keep in mind that parallelising a model has a cost associated with it: the communication between the different components will be slower on Ray than it is locally.</p> <p>For small models, or when a single component is the computational bottleneck then this overhead may not be worth it. However, when you have multiple computationally-intensive components in different branches of your <code>Process</code> then moving to Ray can give you a performance boost.</p> <p>Before running this tutorial be sure to install Ray with pip, or install plugboard with its optional <code>ray</code> extra.</p>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#parallelising-a-model","title":"Parallelising a model","text":"<p>For demonstration purposes we're going to use a model with two branches that containing <code>Sleep</code> components to simulate computationally intensive activity. In real scenarios these might instead be calls to simulation software or machine-learning model inference.</p> <pre><code>flowchart LR\n    input@{ shape: rounded, label: Iterator&lt;br&gt;**input** } --&gt; slow-sleep@{ shape: rounded, label: Sleep&lt;br&gt;**slow-sleep** }\n    input@{ shape: rounded, label: Iterator&lt;br&gt;**input** } --&gt; very-slow-sleep@{ shape: rounded, label: Sleep&lt;br&gt;**very-slow-sleep** }\n    slow-sleep@{ shape: rounded, label: Sleep&lt;br&gt;**slow-sleep** } --&gt; timestamper@{ shape: rounded, label: Timestamper&lt;br&gt;**timestamper** }\n    timestamper@{ shape: rounded, label: Timestamper&lt;br&gt;**timestamper** } --&gt; save-results@{ shape: rounded, label: FileWriter&lt;br&gt;**save-results** }\n    very-slow-sleep@{ shape: rounded, label: Sleep&lt;br&gt;**very-slow-sleep** } --&gt; timestamper@{ shape: rounded, label: Timestamper&lt;br&gt;**timestamper** }</code></pre>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#defining-the-components","title":"Defining the components","text":"<p>Let's define the various components that we need. The <code>Timestamper</code> component simply emits the current time in ISO format so that our output file will contain a record of how long each step of the model took. We can again use <code>FileWriter</code> to save the output to CSV. <pre><code>class Iterator(Component):\n    \"\"\"Creates a sequence of numbers.\"\"\"\n\n    io = IO(outputs=[\"x\"])\n\n    def __init__(self, iters: int, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._iters = iters\n\n    async def init(self) -&gt; None:\n        self._seq = iter(range(self._iters))\n\n    async def step(self) -&gt; None:\n        try:\n            self.out_1 = next(self._seq)\n        except StopIteration:\n            await self.io.close()\n\n\nclass Sleep(Component):\n    \"\"\"Passes through input to output after a delay.\"\"\"\n\n    io = IO(inputs=[\"x\"], outputs=[\"y\"])\n\n    def __init__(self, sleep_seconds: float, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._duration = sleep_seconds\n\n    async def step(self) -&gt; None:\n        time.sleep(self._duration)  # (1)!\n        self.y = self.x\n\n\nclass Timestamper(Component):\n    \"\"\"Emits the current time when all inputs are ready.\"\"\"\n\n    io = IO(inputs=[\"x\", \"y\"], outputs=[\"timestamp\"])\n\n    async def step(self) -&gt; None:\n        self.timestamp = datetime.datetime.now().isoformat()\n</code></pre></p> <ol> <li>We're using <code>time.sleep</code> here and not <code>asyncio.sleep</code> because we're deliberately blocking execution to simulate a computationally intensive component.</li> </ol>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#running-normally-in-a-localprocess","title":"Running normally in a <code>LocalProcess</code>","text":"<p>First we can setup the <code>LocalProcess</code> and run it as we have in previous tutorials. <pre><code>process = LocalProcess(\n    components=[\n        Iterator(name=\"input\", iters=20),\n        Sleep(name=\"slow-sleep\", sleep_seconds=0.5),\n        Sleep(name=\"very-slow-sleep\", sleep_seconds=1),\n        Timestamper(name=\"timestamper\"),\n        FileWriter(name=\"save-results\", path=\"ray.csv\", field_names=[\"timestamp\"]),\n    ],\n    connectors=[\n        AsyncioConnector(spec=ConnectorSpec(source=\"input.x\", target=\"slow-sleep.x\")),\n        AsyncioConnector(spec=ConnectorSpec(source=\"input.x\", target=\"very-slow-sleep.x\")),\n        AsyncioConnector(spec=ConnectorSpec(source=\"slow-sleep.y\", target=\"timestamper.x\")),\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"very-slow-sleep.y\", target=\"timestamper.y\")\n        ),\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"timestamper.timestamp\", target=\"save-results.timestamp\")\n        ),\n    ],\n)\nasync with process:\n    await process.run()\n</code></pre></p> <p>Running 20 iterations takes around 30 seconds, because each step of the model contains 1.5s of computation.</p>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#running-in-parallel-using-rayprocess","title":"Running in parallel using <code>RayProcess</code>","text":"<p>With some small changes we can make the same model run in parallel on Ray. First we change the <code>Process</code> class to <code>RayProcess</code>. Then when creating the <code>Connector</code> objects we need to change the channel type to <code>RayChannel</code>.</p> <p>Info</p> <p><code>Channel</code> objects are used by Plugboard to handle the communication between components. So far we have used <code>AsyncioChannel</code>, which is the best option for simple models that don't require parallelisation.</p> <p>Plugboard provides different channel classes for use in parallel environments: <code>RayChannel</code> is suitable for single and multi-host Ray environments. <code>ZMQChannel</code> is faster, but currently only works on a single host.</p> <pre><code>process = RayProcess(\n    components=[\n        Iterator(name=\"input\", iters=20),\n        Sleep(name=\"slow-sleep\", sleep_seconds=0.5),\n        Sleep(name=\"very-slow-sleep\", sleep_seconds=1),\n        Timestamper(name=\"timestamper\"),\n        FileWriter(name=\"save-results\", path=\"ray.csv\", field_names=[\"timestamp\"]),\n    ],\n    connectors=[\n        RayConnector(spec=ConnectorSpec(source=\"input.x\", target=\"slow-sleep.x\")),\n        RayConnector(spec=ConnectorSpec(source=\"input.x\", target=\"very-slow-sleep.x\")),\n        RayConnector(spec=ConnectorSpec(source=\"slow-sleep.y\", target=\"timestamper.x\")),\n        RayConnector(spec=ConnectorSpec(source=\"very-slow-sleep.y\", target=\"timestamper.y\")),\n        RayConnector(\n            spec=ConnectorSpec(source=\"timestamper.timestamp\", target=\"save-results.timestamp\")\n        ),\n    ],\n)\nasync with process:\n    await process.run()\n</code></pre> <p>Now the 20 iteration model takes around 23s, because the two different <code>Sleep</code> components are being executed in parallel (20s compute time plus a little overhead).</p>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#using-yaml-config","title":"Using YAML config","text":"<p>Defining your model as a YAML config file is particularly useful when you want to use more computational resources: the config file is portable and lets you easily move the model to different compute environments.</p> <p>Specifying the process type and channel builder type in the YAML is the only change needed to get the example above to run on Ray. <pre><code>plugboard:\n  process:\n    type: \"plugboard.process.RayProcess\"  # (1)!\n    connector_builder:\n      type: \"plugboard.connector.RayConnector\"  # (2)!\n    args:\n      components:\n      - type: hello_ray.Iterator\n        args:\n          name: \"input\"\n          iters: 10\n      - type: hello_ray.Sleep\n        args:\n          name: \"slow-sleep\"\n          sleep_seconds: 0.5\n      - type: hello_ray.Sleep\n        args:\n          name: \"very-slow-sleep\"\n          sleep_seconds: 1\n      - type: hello_ray.Timestamper\n        args:\n          name: \"timestamper\"\n      - type: plugboard.library.file_io.FileWriter\n        args:\n          name: \"save-results\"\n          path: \"ray.csv\"\n          field_names:\n          - timestamp\n      connectors:\n      - source: \"input.x\"\n        target: \"slow-sleep.x\"\n      - source: \"input.x\"\n        target: \"very-slow-sleep.x\"\n      - source: \"slow-sleep.y\"\n        target: \"timestamper.x\"\n      - source: \"very-slow-sleep.y\"\n        target: \"timestamper.y\"\n      - source: \"timestamper.timestamp\"\n        target: \"save-results.timestamp\"\n</code></pre></p> <ol> <li>Tell Plugboard to use a <code>RayProcess</code> instead of the default <code>LocalProcess</code>.</li> <li>Also change the connector builder to <code>RayConnector</code>, which will build <code>RayChannel</code> objects when creating the <code>Process</code>.</li> </ol>","tags":["tutorial","ray"]},{"location":"examples/tutorials/tuning-a-process/","title":"Tuning a process","text":"<p>Once you have built a model of your process, a common problem you might face is tuning its parameters. Plugboard includes a built-in optimisation utility based on Ray Tune and Optuna. Using this tool you can do things like:</p> <ul> <li>Calibrate the parameters of a process model to match observed results; and</li> <li>Optimise a process model to maximise or minimise its output.</li> </ul> <p>These capabilities are particularly useful when working with digital twins: for example given a model of a production line, you could use the tuner to work out how to maximise its output.</p> <p>Tip</p> <p>By using Ray Tune, Plugboard allows you to run optimisations in parallel within a Ray cluster, allowing you to explore the parameter space quickly even when working with long simulations.</p>","tags":["tutorial","optimisation"]},{"location":"examples/tutorials/tuning-a-process/#define-a-model-to-optimise","title":"Define a model to optimise","text":"<p>As a simple example, we'll create a simple 3-component model to calculate the maximum height of a projectile launched at a given angle and velocity. <pre><code> flowchart LR\n   horizontal@{ shape: rounded, label: Iterator&lt;br&gt;**horizontal** } --&gt; trajectory@{ shape: rounded, label: Trajectory&lt;br&gt;**trajectory** }\n   trajectory@{ shape: rounded, label: Trajectory&lt;br&gt;**trajectory** } --&gt; max-height@{ shape: rounded, label: MaxHeight&lt;br&gt;**max-height** }</code></pre></p> <p>Running the model with different values of the angle and velocity parameters configured on the <code>Trajectory</code> component will result in different heights being found on the <code>MaxHeight</code> component at the end of the simulation. We will use the <code>Tuner</code> class to explore this parameter space and maximise the projectile height.</p>","tags":["tutorial","optimisation"]},{"location":"examples/tutorials/tuning-a-process/#setting-up-the-components","title":"Setting up the components","text":"<p>We'll need the following components to implement the model above: <pre><code>class Iterator(Component):\n    \"\"\"Creates a sequence of x values.\"\"\"\n\n    io = IO(outputs=[\"x\"])\n\n    def __init__(self, iters: int, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._iters = iters\n\n    async def init(self) -&gt; None:\n        self._seq = iter(range(self._iters))\n\n    async def step(self) -&gt; None:\n        try:\n            self.x = next(self._seq)\n        except StopIteration:\n            await self.io.close()\n\n\nclass Trajectory(Component):\n    \"\"\"Computes the height of a projectile.\"\"\"\n\n    io = IO(inputs=[\"x\"], outputs=[\"y\"])\n\n    def __init__(\n        self, angle: float = 30, velocity: float = 20, **kwargs: _t.Unpack[ComponentArgsDict]\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self._angle_radians = math.radians(angle)\n        self._v0 = velocity\n\n    async def step(self) -&gt; None:\n        self._logger.info(\"Calculating trajectory\", x=self.x)\n        self.y = self.x * math.tan(self._angle_radians) - (9.81 * self.x**2) / (\n            2 * self._v0**2 * math.cos(self._angle_radians) ** 2\n        )\n\n\nclass MaxHeight(Component):\n    \"\"\"Record the maximum height achieved.\"\"\"\n\n    io = IO(inputs=[\"y\"], outputs=[\"max_y\"])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self.max_y: float = 0\n\n    async def step(self) -&gt; None:\n        self.max_y = max(self.y, self.max_y)\n</code></pre></p> <p>Instead of building a <code>Process</code> as we would normally do to run the model directly, we'll instead define the <code>ProcessSpec</code> for the model. <pre><code>process_spec = ProcessSpec(\n    args=ProcessArgsSpec(\n        components=[\n            {\"type\": \"hello_tuner.Iterator\", \"args\": {\"name\": \"horizontal\", \"iters\": 100}},\n            {\n                \"type\": \"hello_tuner.Trajectory\",\n                \"args\": {\"name\": \"trajectory\", \"angle\": 30, \"velocity\": 20},\n            },\n            {\"type\": \"hello_tuner.MaxHeight\", \"args\": {\"name\": \"max-height\"}},\n        ],\n        connectors=[\n            {\"source\": \"horizontal.x\", \"target\": \"trajectory.x\"},\n            {\"source\": \"trajectory.y\", \"target\": \"max-height.y\"},\n        ],\n    ),\n    type=\"plugboard.process.LocalProcess\",\n)\n# Check that the process spec can be built\n_ = ProcessBuilder.build(spec=process_spec)\n</code></pre></p>","tags":["tutorial","optimisation"]},{"location":"examples/tutorials/tuning-a-process/#setting-up-the-tuner","title":"Setting up the Tuner","text":"<p>Next, we set up a <code>Tuner</code> object by configuring the <code>angle</code> and <code>velocity</code> arguments as floating point parameters, along with constraints.</p> <p>Info</p> <p>Plugboard supports floating point, integer and categorical variables as tunable model parameters. See the definition of <code>ParameterSpec</code> for details.</p> <p>When building the tuner, we also specify the number of optimisation samples and how many we will allow to run in parallel on Ray. <pre><code>tuner = Tuner(\n    objective=ObjectiveSpec(  # (1)!\n        object_type=\"component\",\n        object_name=\"max-height\",\n        field_type=\"field\",\n        field_name=\"max_y\",\n    ),\n    parameters=[\n        FloatParameterSpec(  # (2)!\n            object_type=\"component\",\n            object_name=\"trajectory\",\n            field_type=\"arg\",\n            field_name=\"angle\",\n            lower=0,\n            upper=90,\n        ),\n        FloatParameterSpec(\n            object_type=\"component\",\n            object_name=\"trajectory\",\n            field_type=\"arg\",\n            field_name=\"velocity\",\n            lower=0,\n            upper=100,\n        ),\n    ],\n    num_samples=40,  # (3)!\n    max_concurrent=4,  # (4)!\n    mode=\"max\",  # (5)!\n)\nresult = tuner.run(spec=process_spec)\nprint(\n    f\"Best parameters: angle={result.config['trajectory.angle']}, velocity={result.config['trajectory.velocity']}\"\n)\nprint(f\"Best max height: {result.metrics['max-height.max_y']}\")\n</code></pre></p> <ol> <li>Set the objective, i.e. what we want our optimisation to target. In this case it is a field  on the <code>max-height</code> component. This can be a list of objectives if you need to do multi-objective optimisation.</li> <li>List the tunable parameters here. The <code>field_type</code> can be <code>\"arg\"</code> or <code>\"initial_value\"</code>. This is also where you can specify constraints on the parameters.</li> <li>Set the number of trials to run. More trials will take longer, but may get closer to finding the true optimum.</li> <li>The level of concurrency to use in Ray.</li> <li>Whether to minimise or maximise the objective. This must be set as a list for multi-objective optimisation.</li> </ol> <p>Running this code will execute an optimisation job and print out information on each trial, along with the final optimisation result.</p> <p>Tip</p> <p>Since Optuna is used under the hood, you can configure the optional <code>algorithm</code> argument on the <code>Tuner</code> with additional configuration defined in <code>OptunaSpec</code>. For example, the <code>storage</code> argument allows you to save the optimisation results to a database or SQLite file. You can then use a tool like Optuna Dashboard to study the optimisation output in more detail.</p> <p>Tip</p> <p>You can impose arbitary constraints on variables within a <code>Process</code>. In your <code>step</code> method you can raise a <code>ConstraintError</code> to indicate to the <code>Tuner</code> that a constraint has been breached. This will cause the trial to be stopped, and the optimisation will continue trying to find parameters that don't cause the constraint violation.</p>","tags":["tutorial","optimisation"]},{"location":"examples/tutorials/tuning-a-process/#using-yaml-config","title":"Using YAML config","text":"<p>Plugboard's YAML config supports an optional <code>tune</code> section, allowing you to define optimisation jobs alongside your model configuration: <pre><code>plugboard:\n  process:  # (1)!\n    args:\n      components:\n      - type: hello_tuner.Iterator\n        args:\n          name: horizontal\n          iters: 100\n      - type: hello_tuner.Trajectory\n        args:\n          name: trajectory\n          angle: 25\n          velocity: 20\n      - type: hello_tuner.MaxHeight\n        args:\n          name: max-height\n      connectors:\n      - source: horizontal.x\n        target: trajectory.x\n      - source: trajectory.y\n        target: max-height.y\n  tune:  # (2)!\n    args:\n      objective:\n        object_name: max-height\n        field_type: field\n        field_name: max_y\n      parameters:\n      - type: ray.tune.uniform  # (3)!\n        object_type: component\n        object_name: trajectory\n        field_type: arg\n        field_name: angle\n        lower: 0\n        upper: 90\n      - type: ray.tune.uniform\n        object_type: component\n        object_name: trajectory\n        field_type: arg\n        field_name: velocity\n        lower: 0\n        upper: 100\n      num_samples: 40\n      mode: max\n      max_concurrent: 4\n</code></pre></p> <ol> <li>As usual, this section defines the <code>Process</code>. It can also be replaced by a path to another YAML file.</li> <li>This section is optional, and configures the <code>Tuner</code>.</li> <li>Parameters need to reference a type, so that Plugboard knows the type of parameter to build.</li> </ol> <p>Now run <code>plugboard process tune model-with-tuner.yaml</code> to execute the optimisation job from the CLI.</p>","tags":["tutorial","optimisation"]},{"location":"usage/configuration/","title":"Configuration","text":""},{"location":"usage/configuration/#main-configuration-options","title":"Main configuration options","text":"<p>Plugboard can either be configured via shell environment variables or using a <code>.env</code> file. Full details on the settings and feature flags can be found in <code>plugboard.utils.settings.Settings</code>.</p>"},{"location":"usage/configuration/#logging","title":"Logging","text":"<p>Logging can be configured via the following environment variables:</p> Option Name Description Default Value <code>PLUGBOARD_LOG_LEVEL</code> Sets the logging level (e.g., <code>DEBUG</code>, <code>INFO</code>, <code>ERROR</code>) <code>WARNING</code> <code>PLUGBOARD_LOG_STRUCTURED</code> Enables logging in JSON format. <p>Plugboard uses structlog as its logging library. For basic changes you can adjust the options above, but for more advanced configuration you may need to call <code>structlog.configure()</code> and set the options yourself.</p>"},{"location":"usage/configuration/#message-brokers","title":"Message brokers","text":"<p>Plugboard can make use of a message broker for data exchange between components in a distributed setting such as a Ray cluster. To allow components to connect to a broker, a connection string containing the broker url (and credentials if required) should be set in the the environment. Below are the recognised environment variables for the supported message brokers. In general, only one broker would be used per plugboard run.</p> Option Name Description Default Value <code>RABBITMQ_URL</code> URL for RabbitMQ AMQP message broker (must include credentials if required)"},{"location":"usage/configuration/#job-id","title":"Job ID","text":"<p>Each plugboard run has a unique job ID associated with it. This is used to: track state for each run; and separate data messages between runs when using a message broker. Typically, a run would be started without explicitly setting the job ID, in which case a unique job ID will be created automatically. However, there are instances when it may be desirable to specify the job ID, such as stopping a run and resuming the same run later with the existing persisted state. In these scenarios the job ID can be set with the below environment variable which will then be used by any <code>StateBackend</code>, <code>Process</code> and <code>Component</code> while the value is set.</p> Option Name Description Default Value <code>PLUGBOARD_JOB_ID</code> Unique job ID for plugboard runs to track state and message broker topics"},{"location":"usage/key-concepts/","title":"Key Concepts","text":"<p>If you enjoy learning by following examples, we recommend diving straight into the tutorials section. All of the tutorials and demos can be found in our Github repo.</p> <p>This section introduces some of the key concepts in Plugboard and how to apply them when building your own models.</p>"},{"location":"usage/key-concepts/#terminology","title":"Terminology","text":""},{"location":"usage/key-concepts/#components","title":"Components","text":"<p>The basic building blocks of Plugboard models are <code>Component</code> objects. Typical uses of components are:</p> <ul> <li>Loading data into and saving data out of models;</li> <li>Preparing data and/or running calculations;</li> <li>Modelling a particular physical entity, e.g. within a model of a factory production line, you might define separate components representing the conveyor belts, sensors and workstations;</li> <li>Making calls to external systems, e.g. fetching data from the internet, calling an LLM, spinning up a subprocess to run some third-party simulation software.</li> </ul> <p>When implementing your own components, you will need to:</p> <ul> <li>Subclass the base <code>Component</code>;</li> <li>Specify its inputs and ouputs using an <code>IOController</code>;</li> <li>Define a <code>step()</code> method the executes the main logic of your component for a single step; and</li> <li>Optionally define an <code>init()</code> method to do any required preparatory steps before the model in run.</li> <li>In the case of event based models, define custom <code>Event</code> subclasses and corresponding event handler methods decorated with <code>Event.handler</code>.</li> </ul>"},{"location":"usage/key-concepts/#connectors","title":"Connectors","text":"<p>Data flows between components via Connectors. You will need to use these to tell Plugboard how data should flow between your components. Your overall model might be very simple, for example:</p> <pre><code>graph LR;\n    A(Load input data)--&gt;B(Process data)--&gt;C(Save output data);</code></pre> <p>However Plugboard supports much more complex model structures, including looping and branching:</p> <pre><code>graph LR;\n    A(Load data)--&gt;B(Simulate process);\n    B(Simulate process)--&gt;C(Process controller);\n    C(Process controller)--&gt;B(Simulate process);\n    B(Simulate process)--&gt;D(Record output);\n    C(Process controller)--&gt;D(Record output);\n    A(Load data)--&gt;D(Record output);</code></pre> <p>For models with explicitly declared input and output fields, connectors for each input-output pair must be defined explicitly using one of the <code>Connector</code> implementations. Connectors required for any events used in the model will be created for you automatically. </p>"},{"location":"usage/key-concepts/#processes","title":"Processes","text":"<p>Components and connectors are collected together under a Process. This top-level class takes care of starting the model and running it until completion. Model execution is broken down into discrete steps. Running a model means executing all steps for each component until all of the available data has flowed through the model. The <code>step()</code> method advances the model forward by a single step. The <code>run()</code> method will repeatedly call <code>step()</code> until completion.</p> <p>Plugboard supports both bounded and unbounded data streams. That is to say, you can either run a model with a fixed size input data set until completion, or run a model indefinitely which will continuously process new inputs as they arrive until a shutdown signal is received.</p> <p>Plugboard uses Python's asynchronous concurrency to schedule execution of each of the components. Don't worry if asynchronous Python is unfamiliar to you: Plugboard takes care of all the details, so that you can focus on the logic of your model.</p> <p>These Process classes are currently available which can be extended with custom implementations:</p> <ul> <li><code>LocalProcess</code> runs models in a single Python process on your computer. This is useful for initial development, and is often sufficient for models are not computationally demanding.</li> <li><code>RayProcess</code> allows you to execute components on different Python processes using the Ray Framework. This supports parallel computation on a single machine and scales out to large-scale compute clusters.</li> </ul>"},{"location":"usage/key-concepts/#running-models","title":"Running models","text":"<p>Most models start out life in a Jupyter notebook or Python script. Later on in development you may choose to convert the Plugboard process definition to a YAML file. This allows you to:</p> <ul> <li>Separate your model code from its configuration;</li> <li>Run the model via Plugboard's CLI - see <code>plugboard process run --help</code> for details;</li> <li>Transfer your model to a cluster to take advantage of larger-scale computational resources.</li> </ul>"},{"location":"usage/topics/","title":"Topic index","text":"<p>To find information on a specific topic, you can look for pages under one of the tags below.</p>"},{"location":"usage/topics/#tag:io","title":"io","text":"<ul> <li>            More components          </li> <li>            Streaming data: processing a websocket feed          </li> </ul>"},{"location":"usage/topics/#tag:llm","title":"llm","text":"<ul> <li>            LLM for data filtering          </li> <li>            More components          </li> <li>            Streaming data: processing a websocket feed          </li> </ul>"},{"location":"usage/topics/#tag:logging","title":"logging","text":"<ul> <li>            More components          </li> </ul>"},{"location":"usage/topics/#tag:optimisation","title":"optimisation","text":"<ul> <li>            Tuning a process          </li> </ul>"},{"location":"usage/topics/#tag:physics-models","title":"physics-models","text":"<ul> <li>            Hot water tank model          </li> </ul>"},{"location":"usage/topics/#tag:ray","title":"ray","text":"<ul> <li>            Running in parallel          </li> </ul>"},{"location":"usage/topics/#tag:streaming","title":"streaming","text":"<ul> <li>            Streaming data: processing a websocket feed          </li> </ul>"},{"location":"usage/topics/#tag:tutorial","title":"tutorial","text":"<ul> <li>            A more complex process          </li> <li>            Event-driven models          </li> <li>            Hello world          </li> <li>            More components          </li> <li>            Running in parallel          </li> <li>            Tuning a process          </li> </ul>"}]}