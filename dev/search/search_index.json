{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p>Plugboard is an event-driven modelling and orchestration framework in Python for simulating and driving complex processes with many interconnected stateful components.</p> <p>You can use it to define models in Python and connect them together easily so that data automatically moves between them. After running your model on a laptop, you can then scale out on multiple processors, or go to a compute cluster in the cloud.</p> <p>Some examples of what you can build with Plugboard include:</p> <ul> <li>Digital twin models of complex processes:<ul> <li>It can easily handle common problems in industrial process simulation like material recirculation;</li> <li>Models can be composed from different underlying components, e.g. physics-based simulations, machine-learning, AI models;</li> </ul> </li> <li>AI integrations:<ul> <li>You can feed data to/from different LLMs using Plugboard components;</li> <li>Easily reconfigure and swap model providers for optimal performance.</li> </ul> </li> </ul>"},{"location":"#key-features","title":"\ud83d\udd8b\ufe0f Key Features","text":"<ul> <li>Reusable classes containing the core framework, which you can extend to define your own model logic;</li> <li>Support for different simulation paradigms: discrete time and event based.</li> <li>YAML model specification format for saving model definitions, allowing you to run the same model locally or in cloud infrastructure;</li> <li>A command line interface for executing models;</li> <li>Built to handle the data intensive simulation requirements of industrial process applications;</li> <li>Modern implementation with Python 3.12 and above based around asyncio with complete type annotation coverage;</li> <li>Built-in integrations for loading/saving data from cloud storage and SQL databases;</li> <li>Detailed logging of component inputs, outputs and state for monitoring and process mining or surrogate modelling use-cases.</li> </ul>"},{"location":"#installation","title":"\ud83d\udd0c Installation","text":"<p>Plugboard requires Python &gt;= 3.12. Install the package with pip inside a virtual env as below. <pre><code>python -m pip install plugboard\n</code></pre></p> <p>Optional integrations for different cloud providers can be installed using <code>plugboard[aws]</code>, <code>plugboard[azure]</code> or <code>plugboard[gcp]</code>.</p> <p>Support for parallelisation can be installed using <code>plugboard[ray]</code>.</p>"},{"location":"#usage","title":"\ud83d\ude80 Usage","text":"<p>Plugboard is built to help you with two things: defining process models, and executing those models. There are two main ways to interact with plugboard: via the Python API; or, via the CLI using model definitions saved in yaml format.</p>"},{"location":"#building-models-with-the-python-api","title":"Building models with the Python API","text":"<p>A model is made up of one or more components, though Plugboard really shines when you have many! First we start by defining the <code>Component</code>s within our model. Components can have only inputs, only outputs, or both. To keep it simple we just have two components here, showing the most basic functionality. Each component has several methods which are called at different stages during model execution: <code>init</code> for optional initialisation actions; <code>step</code> to take a single step forward through time; <code>run</code> to execute all steps; and <code>destroy</code> for optional teardown actions. <pre><code>import typing as _t\nfrom plugboard.component import Component, IOController as IO\nfrom plugboard.schemas import ComponentArgsDict\n\nclass A(Component):\n    io = IO(outputs=[\"out_1\"])\n\n    def __init__(self, iters: int, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._iters = iters\n\n    async def init(self) -&gt; None:\n        self._seq = iter(range(self._iters))\n\n    async def step(self) -&gt; None:\n        try:\n            self.out_1 = next(self._seq)\n        except StopIteration:\n            await self.io.close()\n\n\nclass B(Component):\n    io = IO(inputs=[\"in_1\"])\n\n    def __init__(self, path: str, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._path = path\n\n    async def init(self) -&gt; None:\n        self._f = open(self._path, \"w\")\n\n    async def step(self) -&gt; None:\n        out = 2 * self.in_1\n        self._f.write(f\"{out}\\n\")\n\n    async def destroy(self) -&gt; None:\n        self._f.close()\n</code></pre></p> <p>There is also a <code>@component</code> decorator which simplifies creating <code>Component</code>s for small stateless transform type functions. A component instance can be created by calling the <code>.component</code> method of the object returned by the decorator. The wrapped function can be sync or async and will be called as the step method with the named inputs being passed in. Inputs must be specified matching function args. Outputs must be specified and the function must return a dictionary where the keys match the outputs. <pre><code>@component(inputs=[\"in_1\"], outputs=[\"out_1\"])\ndef pow2(in_1: int) -&gt; int:\n  return {\"out_1\": in_1 ** 2}\n\nresult = pow2(2)  # Preserves original function call -&gt; result = {\"out_1\": 4}\ncomp_pow2 = pow2.component(name=\"component-pow2\")\n</code></pre></p> <p>Now we take these components, connect them up as a <code>Process</code>, and fire off the model. Using the <code>Process</code> context handler takes care of calling <code>init</code> at the beginning and <code>destroy</code> at the end for all <code>Component</code>s. Calling <code>Process.run</code> triggers all the components to start iterating through all their inputs until a termination condition is reached. Simulations proceed in an event-driven manner: when inputs arrive, the components are triggered to step forward in time. The framework handles the details of the inter-component communication, you just need to specify the logic of your components, and the connections between them. <pre><code>from plugboard.connector import AsyncioConnector\nfrom plugboard.process import LocalProcess\nfrom plugboard.schemas import ConnectorSpec\n\nprocess = LocalProcess(\n    components=[A(name=\"component-a\", iters=5), B(name=\"component-b\", path=\"b.txt\"), comp_pow2],\n    connectors=[\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"component-a.out_1\", target=\"component-b.in_1\"),\n        ),\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"component-a.out_1\", target=f\"{comp_pow2.name}.in_1\"),\n        )\n    ],\n)\nasync with process:\n    await process.run()\n</code></pre></p> <p>Visually, we've created the model below, with Plugboard automatically handling the flow of data between the components. <pre><code>flowchart LR\n  subgraph Process\n    direction LR\n    comp_a(A&lt;br&gt;**component-a**)\n    comp_b(B&lt;br&gt;**component-b**)\n    comp_pow2(pow2&lt;br&gt;**component-pow2**)\n  end\n  comp_a -- out_1 --&gt; comp_b\n  comp_a -- out_1 --&gt; comp_pow2</code></pre></p>"},{"location":"#executing-pre-defined-models-on-the-cli","title":"Executing pre-defined models on the CLI","text":"<p>In many cases, we want to define components once, with suitable parameters, and then use them repeatedly in different simulations. Plugboard enables this workflow with model specification files in yaml format. Once the components have been defined, the simple model above can be represented as follows. Components auto-generated with the <code>@component</code> decorator can be referenced by the name of the wrapped function. <pre><code># my-model.yaml\nplugboard:\n  process:\n    args:\n      components:\n      - type: hello_world.A\n        args:\n          name: \"component-a\"\n          iters: 10\n      - type: hello_world.B\n        args:\n          name: \"component-b\"\n          path: \"./b.txt\"\n      - type: hello_world.pow2\n        args:\n          name: \"component-pow2\"\n      connectors:\n      - source: \"component-a.out_1\"\n        target: \"component-b.in_1\"\n      - source: \"component-a.out_1\"\n        target: \"component-pow2.in_1\"\n</code></pre></p> <p>We can now run this model using the plugboard CLI with the command: <pre><code>plugboard process run my-model.yaml\n</code></pre></p>"},{"location":"#documentation","title":"\ud83d\udcd6 Documentation","text":"<p>For more information including a detailed API reference and step-by-step usage examples, refer to the documentation site. We recommend diving into the tutorials for a step-by-step to getting started.</p>"},{"location":"#roadmap","title":"\ud83d\udc3e Roadmap","text":"<p>Plugboard is under active development, with new features in the works:</p> <ul> <li>Support for strongly typed data messages and validation based on pydantic.</li> <li>Support for different parallelisation patterns such as: single-threaded with coroutines, single-host multi process, or distributed with Ray in Kubernetes.</li> <li>Data exchange between components with popular messaging technologies like RabbitMQ and Google Pub/Sub.</li> <li>Support for different message exchange patterns such as: one-to-one, one-to-many, many-to-one etc via a broker; or peer-to-peer with http requests.</li> </ul>"},{"location":"#contributions","title":"\ud83d\udc4b Contributions","text":"<p>Contributions are welcomed and warmly received! For bug fixes and smaller feature requests feel free to open an issue on this repo. For any larger changes please get in touch with us to discuss first. More information for developers can be found in the contributing section of the docs.</p>"},{"location":"#licence","title":"\u2696\ufe0f Licence","text":"<p>Plugboard is offered under the Apache 2.0 Licence so it's free for personal or commercial use within those terms.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for your interest in Plugboard. Contributions are welcomed and warmly received! For bug fixes and smaller feature requests feel free to open an issue on our Github repo. For any larger changes please get in touch with us to discuss first.</p>"},{"location":"contributing/#pr-process","title":"\ud83d\ude3b PR process","text":"<p>We use Conventional Commits on our main branch, so prefix your pull request titles with a commit type: <code>feat</code>, <code>fix</code>, <code>chore</code>, etc.</p>"},{"location":"contributing/#development-setup","title":"\ud83d\udcbb Development setup","text":"<p>For small changes or to get up-and-running quickly, we recommend GitHub codespaces, which provides you with a ready-to-use development environment.</p> <p>For local development we recommend VSCode.</p>"},{"location":"contributing/#python-dependencies","title":"Python dependencies","text":"<p>Dependencies are managed using uv. Install the project using <pre><code>uv sync --all-extras\n</code></pre></p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>Tests are run in pytest, which you can run with <pre><code>uv run pytest .\n</code></pre></p>"},{"location":"contributing/#linting","title":"Linting","text":"<p>We use ruff for code formatting and style. Install the pre-commit hook by running <pre><code>uv run pre-commit install\n</code></pre></p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>The package documentation uses Material for MkDocs and can be viewed locally by running <pre><code>uv run mkdocs serve\n</code></pre></p>"},{"location":"contributing/#building-example-models","title":"Building example models","text":"<p>This repo includes a custom LLM prompt for the examples folder. If you use GitHub Copilot, this can help you build a Plugboard model from a description of the process and/or the components that you would like to implement. We recommend using Copilot in agent mode and allowing it to implement the boilerplate code from your input prompt.</p>"},{"location":"api/component/component/","title":"component","text":"<p>Component submodule providing functionality related to components and their execution.</p>"},{"location":"api/component/component/#plugboard.component.Component","title":"Component","text":"<pre><code>Component(\n    *,\n    name: str,\n    initial_values: Optional[dict[str, Iterable]] = None,\n    parameters: Optional[dict[str, Any]] = None,\n    state: Optional[StateBackend] = None,\n    constraints: Optional[dict] = None,\n    resources: Optional[Resource] = None,\n)\n</code></pre> <p>               Bases: <code>ABC</code>, <code>ExportMixin</code></p> <p><code>Component</code> base class for all components in a process model.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>The name of the component.</p> <code>io</code> <code>IOController</code> <p>The <code>IOController</code> for the component, specifying inputs, outputs, and events.</p> <code>exports</code> <code>Optional[list[str]]</code> <p>Optional; The exportable fields from the component during distributed runs in addition to input and output fields.</p> <code>resources</code> <code>Resource</code> <p>Resource requirements for the component. Can be declared as a class attribute to set default resource requirements, which can be overridden in the constructor. Defaults to <code>Resource()</code> (0.001 CPU, 0 GPU, 0 memory).</p> <p>Initialize a Component instance.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the component.</p> required <code>initial_values</code> <code>Optional[dict[str, Iterable]]</code> <p>Optional; Initial values for the component's inputs.</p> <code>None</code> <code>parameters</code> <code>Optional[dict[str, Any]]</code> <p>Optional; Parameters for the component.</p> <code>None</code> <code>state</code> <code>Optional[StateBackend]</code> <p>Optional; State backend for the component.</p> <code>None</code> <code>constraints</code> <code>Optional[dict]</code> <p>Optional; Constraints for the component.</p> <code>None</code> <code>resources</code> <code>Optional[Resource]</code> <p>Optional; Resource requirements for the component. If not provided, uses the class-level <code>resources</code> attribute as default.</p> <code>None</code>"},{"location":"api/component/component/#plugboard.component.Component.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Unique ID for <code>Component</code>.</p>"},{"location":"api/component/component/#plugboard.component.Component.parameters","title":"parameters  <code>property</code>","text":"<pre><code>parameters: dict[str, Any]\n</code></pre> <p>Gets the parameters of the component.</p>"},{"location":"api/component/component/#plugboard.component.Component.state","title":"state  <code>property</code>","text":"<pre><code>state: Optional[StateBackend]\n</code></pre> <p>State backend for the process.</p>"},{"location":"api/component/component/#plugboard.component.Component.status","title":"status  <code>property</code>","text":"<pre><code>status: Status\n</code></pre> <p>Gets the status of the component.</p>"},{"location":"api/component/component/#plugboard.component.Component.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(key: str, value: Any) -&gt; None\n</code></pre> <p>Sets attributes on the component.</p> <p>If the attribute is an input field, it is set in the field input buffer for the current step. This data is consumed by the <code>step</code> method when it is called and must be reset for subsequent steps.</p>"},{"location":"api/component/component/#plugboard.component.Component.cancel","title":"cancel  <code>async</code>","text":"<pre><code>cancel() -&gt; None\n</code></pre> <p>Called from the <code>Process</code> to set correct status.</p>"},{"location":"api/component/component/#plugboard.component.Component.connect_state","title":"connect_state  <code>async</code>","text":"<pre><code>connect_state(state: Optional[StateBackend] = None) -&gt; None\n</code></pre> <p>Connects the <code>Component</code> to the <code>StateBackend</code>.</p>"},{"location":"api/component/component/#plugboard.component.Component.destroy","title":"destroy  <code>async</code>","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Performs tear-down actions for <code>Component</code>.</p>"},{"location":"api/component/component/#plugboard.component.Component.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Performs component initialisation actions.</p>"},{"location":"api/component/component/#plugboard.component.Component.run","title":"run  <code>async</code>","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Executes component logic for all steps to completion.</p>"},{"location":"api/component/component/#plugboard.component.Component.step","title":"step  <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Executes component logic for a single step.</p>"},{"location":"api/component/component/#plugboard.component.IOController","title":"IOController","text":"<pre><code>IOController(\n    inputs: Optional[Any] = None,\n    outputs: Optional[Any] = None,\n    initial_values: Optional[dict[str, Iterable]] = None,\n    input_events: Optional[list[Type[Event]]] = None,\n    output_events: Optional[list[Type[Event]]] = None,\n    namespace: str = IO_NS_UNSET,\n    component: Optional[Component] = None,\n)\n</code></pre> <p><code>IOController</code> manages input/output to/from components.</p>"},{"location":"api/component/component/#plugboard.component.IOController.is_closed","title":"is_closed  <code>property</code>","text":"<pre><code>is_closed: bool\n</code></pre> <p>Returns <code>True</code> if the <code>IOController</code> is closed, <code>False</code> otherwise.</p>"},{"location":"api/component/component/#plugboard.component.IOController.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes all input/output channels.</p>"},{"location":"api/component/component/#plugboard.component.IOController.connect","title":"connect  <code>async</code>","text":"<pre><code>connect(connectors: list[Connector]) -&gt; None\n</code></pre> <p>Connects the input/output fields to input/output channels.</p>"},{"location":"api/component/component/#plugboard.component.IOController.queue_event","title":"queue_event","text":"<pre><code>queue_event(event: Event) -&gt; None\n</code></pre> <p>Queues an event for output.</p>"},{"location":"api/component/component/#plugboard.component.IOController.read","title":"read  <code>async</code>","text":"<pre><code>read(timeout: float | None = None) -&gt; None\n</code></pre> <p>Reads data and/or events from input channels.</p> <p>Read behaviour is dependent on the specific combination of input fields, output fields, and input events. In general, all components will have at a minimum the system defined input events, such as <code>StopEvent</code>. Logic for the various cases is as follows:</p> <ul> <li>At least one input field: the method waits until either all input fields have received   data or an input event is received, and returns after whichever occurs first.</li> <li>No input fields but at least one output field: the method waits for a short amount of   time to give chance for input events to be received before returning so that the control   flow can continue on to processing output events.</li> <li>No input fields or output fields: this is the pure event driven case where the method   waits until an input event is received, and returns after the first received event.</li> </ul>"},{"location":"api/component/component/#plugboard.component.IOController.write","title":"write  <code>async</code>","text":"<pre><code>write() -&gt; None\n</code></pre> <p>Writes data to output channels.</p>"},{"location":"api/component/component/#componentutils","title":"component.utils","text":"<p>Provides utility functions for working with Plugboard components.</p>"},{"location":"api/component/component/#plugboard.component.utils.ComponentDecoratorHelper","title":"ComponentDecoratorHelper","text":"<pre><code>ComponentDecoratorHelper(\n    func: _FuncT, component_cls: Type[Component]\n)\n</code></pre> <p>Stores wrapped function and dynamically created component class.</p>"},{"location":"api/component/component/#plugboard.component.utils.ComponentDecoratorHelper.__call__","title":"__call__","text":"<pre><code>__call__(*args: Any, **kwargs: Any) -&gt; _t.Any\n</code></pre> <p>Calls the wrapped function directly.</p>"},{"location":"api/component/component/#plugboard.component.utils.ComponentDecoratorHelper.component","title":"component","text":"<pre><code>component(\n    name: Optional[str] = None, **kwargs: Any\n) -&gt; Component\n</code></pre> <p>Creates an instance of the component class for the wrapped function.</p>"},{"location":"api/component/component/#plugboard.component.utils.component","title":"component","text":"<pre><code>component(\n    inputs: Optional[Any] = None,\n    outputs: Optional[Any] = None,\n) -&gt; _t.Callable[[_FuncT], \"ComponentDecoratorHelper\"]\n</code></pre> <p>A decorator to auto generate a Plugboard component from a function.</p> <p>The wrapped function will be added to a dynamically created component class as the step method. The returned helper class can either be called directly, retaining the original behaviour of the wrapped function; or can be used to create a component instance.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>Optional[Any]</code> <p>The input schema or schema factory for the component.</p> <code>None</code> <code>outputs</code> <code>Optional[Any]</code> <p>The output schema or schema factory for the component.</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[[_FuncT], 'ComponentDecoratorHelper']</code> <p>A helper class which can be used to both call the original function and create</p> <code>Callable[[_FuncT], 'ComponentDecoratorHelper']</code> <p>an instance of the component class.</p>"},{"location":"api/connector/connector/","title":"connector","text":"<p>Connector submodule providing functionality related to component connectors and data exchange.</p>"},{"location":"api/connector/connector/#plugboard.connector.Connector","title":"Connector","text":"<pre><code>Connector(spec: ConnectorSpec, *args: Any, **kwargs: Any)\n</code></pre> <p>               Bases: <code>ABC</code>, <code>ExportMixin</code></p> <p><code>Connector</code> provides <code>Channel</code>s for communication between a specified source and target.</p>"},{"location":"api/connector/connector/#plugboard.connector.Connector.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Unique ID for <code>Connector</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.Connector.connect_recv","title":"connect_recv  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>connect_recv() -&gt; Channel\n</code></pre> <p>Returns a <code>Channel</code> for receiving messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.Connector.connect_send","title":"connect_send  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>connect_send() -&gt; Channel\n</code></pre> <p>Returns a <code>Channel</code> for sending messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.Channel","title":"Channel","text":"<pre><code>Channel(\n    *args: Any, maxsize: int = CHAN_MAXSIZE, **kwargs: Any\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p><code>Channel</code> defines an interface for data communication.</p> <p>Initialises the <code>Channel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>maxsize</code> <code>int</code> <p>Optional; The message capacity of the <code>Channel</code>.</p> <code>CHAN_MAXSIZE</code>"},{"location":"api/connector/connector/#plugboard.connector.Channel.is_closed","title":"is_closed  <code>property</code>","text":"<pre><code>is_closed: bool\n</code></pre> <p>Returns <code>True</code> if the <code>Channel</code> is closed, <code>False</code> otherwise.</p> <p>When a <code>Channel</code> is closed, it can no longer be used to send messages, though there may still be some messages waiting to be read.</p>"},{"location":"api/connector/connector/#plugboard.connector.Channel.maxsize","title":"maxsize  <code>property</code>","text":"<pre><code>maxsize: int\n</code></pre> <p>Returns the message capacity of the <code>Channel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.Channel.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the <code>Channel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.Channel.recv","title":"recv  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>recv() -&gt; _t.Any\n</code></pre> <p>Receives an item from the <code>Channel</code> and returns it.</p>"},{"location":"api/connector/connector/#plugboard.connector.Channel.send","title":"send  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>send(msg: Any) -&gt; None\n</code></pre> <p>Sends an item through the <code>Channel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>Any</code> <p>The item to be sent through the <code>Channel</code>.</p> required"},{"location":"api/connector/connector/#plugboard.connector.AsyncioConnector","title":"AsyncioConnector","text":"<pre><code>AsyncioConnector(\n    *args: Any, maxsize: int = CHAN_MAXSIZE, **kwargs: Any\n)\n</code></pre> <p>               Bases: <code>Connector</code></p> <p><code>AsyncioConnector</code> connects components using <code>AsyncioChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.AsyncioConnector.connect_recv","title":"connect_recv  <code>async</code>","text":"<pre><code>connect_recv() -&gt; AsyncioChannel\n</code></pre> <p>Returns an <code>AsyncioChannel</code> for receiving messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.AsyncioConnector.connect_send","title":"connect_send  <code>async</code>","text":"<pre><code>connect_send() -&gt; AsyncioChannel\n</code></pre> <p>Returns an <code>AsyncioChannel</code> for sending messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.AsyncioChannel","title":"AsyncioChannel","text":"<pre><code>AsyncioChannel(\n    *args: Any,\n    maxsize: int = CHAN_MAXSIZE,\n    queue: Optional[Queue] = None,\n    subscribers: Optional[set[Queue]] = None,\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>Channel</code></p> <p><code>AsyncioChannel</code> enables async data exchange between coroutines on the same host.</p> <p>Instantiates <code>AsyncioChannel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>maxsize</code> <code>int</code> <p>Optional; Queue maximum item capacity.</p> <code>CHAN_MAXSIZE</code> <code>queue</code> <code>Optional[Queue]</code> <p>Optional; asyncio.Queue to use for data exchange.</p> <code>None</code> <code>subscribers</code> <code>Optional[set[Queue]]</code> <p>Optional; Set of output asyncio.Queues in pubsub mode.</p> <code>None</code>"},{"location":"api/connector/connector/#plugboard.connector.AsyncioChannel.recv","title":"recv  <code>async</code>","text":"<pre><code>recv() -&gt; _t.Any\n</code></pre> <p>Returns an item received from the <code>Channel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.AsyncioChannel.send","title":"send  <code>async</code>","text":"<pre><code>send(item: Any) -&gt; None\n</code></pre> <p>Sends an item through the <code>Channel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.SerdeChannel","title":"SerdeChannel","text":"<pre><code>SerdeChannel(\n    *args: Any, maxsize: int = CHAN_MAXSIZE, **kwargs: Any\n)\n</code></pre> <p>               Bases: <code>Channel</code>, <code>ABC</code></p> <p><code>SerdeChannel</code> base class for channels that use serialised messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.SerdeChannel.recv","title":"recv  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>recv() -&gt; bytes\n</code></pre> <p>Receives a serialised message from the <code>Channel</code> and returns it.</p> <p>Note: Receiving data involves an unpickling deserialisation step. There are security implications to consider when unpickling data. It is assumed that data received through a channel is trusted.</p>"},{"location":"api/connector/connector/#plugboard.connector.SerdeChannel.send","title":"send  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>send(msg: bytes) -&gt; None\n</code></pre> <p>Sends an serialised message through the <code>Channel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>bytes</code> <p>The message to be sent through the <code>Channel</code>.</p> required"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQConnector","title":"RabbitMQConnector","text":"<pre><code>RabbitMQConnector(*args: Any, **kwargs: Any)\n</code></pre> <p>               Bases: <code>Connector</code></p> <p><code>RabbitMQConnector</code> connects components via RabbitMQ AMQP broker.</p> <p>Uses exclusive queues for pub-sub mode to ensure that each subscriber receives its own copy of each message. In direct mode, uses a single queue for all subscribers, allowing them to share the same messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQConnector.connect_recv","title":"connect_recv  <code>async</code>","text":"<pre><code>connect_recv(\n    rabbitmq_conn: AbstractRobustConnection = Provide[\n        DI.rabbitmq_conn\n    ],\n) -&gt; RabbitMQChannel\n</code></pre> <p>Returns a <code>RabbitMQ</code> channel for receiving messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQConnector.connect_send","title":"connect_send  <code>async</code>","text":"<pre><code>connect_send(\n    rabbitmq_conn: AbstractRobustConnection = Provide[\n        DI.rabbitmq_conn\n    ],\n) -&gt; RabbitMQChannel\n</code></pre> <p>Returns a <code>RabbitMQ</code> channel for sending messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQChannel","title":"RabbitMQChannel","text":"<pre><code>RabbitMQChannel(\n    *args: Any,\n    send_exchange: Optional[AbstractExchange] = None,\n    recv_queue: Optional[AbstractQueue] = None,\n    topic: str = \"\",\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>SerdeChannel</code></p> <p><code>RabbitMQChannel</code> for sending and receiving messages via RabbitMQ AMQP broker.</p> <p>Instantiates a <code>RabbitMQChannel</code>.</p> <p>Uses RabbitMQ AMQP message broker to provide communication between components on different processes. Requires a RabbitMQ broker to be running with the url (and credentials if required) set in the <code>RABBITMQ_URL</code> environment variable.</p> <p>Parameters:</p> Name Type Description Default <code>send_exchange</code> <code>Optional[AbstractExchange]</code> <p>Optional; The RabbitMQ exchange for sending messages.</p> <code>None</code> <code>recv_queue</code> <code>Optional[AbstractQueue]</code> <p>Optional; The RabbitMQ queue for receiving messages.</p> <code>None</code> <code>topic</code> <code>str</code> <p>Optional; The topic for the <code>RabbitMQChannel</code>, defaults to an empty string. Only relevant in the case of pub-sub mode channels.</p> <code>''</code>"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQChannel.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the <code>RabbitMQChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQChannel.recv","title":"recv  <code>async</code>","text":"<pre><code>recv() -&gt; bytes\n</code></pre> <p>Receive a message from the RabbitMQ channel.</p>"},{"location":"api/connector/connector/#plugboard.connector.RabbitMQChannel.send","title":"send  <code>async</code>","text":"<pre><code>send(msg: bytes) -&gt; None\n</code></pre> <p>Send a message to the RabbitMQ channel.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayConnector","title":"RayConnector","text":"<pre><code>RayConnector(*args: Any, **kwargs: Any)\n</code></pre> <p>               Bases: <code>Connector</code></p> <p><code>RayConnector</code> connects components using <code>RayChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayConnector.connect_recv","title":"connect_recv  <code>async</code>","text":"<pre><code>connect_recv() -&gt; RayChannel\n</code></pre> <p>Returns a <code>RayChannel</code> for receiving messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayConnector.connect_send","title":"connect_send  <code>async</code>","text":"<pre><code>connect_send() -&gt; RayChannel\n</code></pre> <p>Returns a <code>RayChannel</code> for sending messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayChannel","title":"RayChannel","text":"<pre><code>RayChannel(\n    actor_options: Optional[dict] = None, **kwargs: Any\n)\n</code></pre> <p>               Bases: <code>Channel</code></p> <p><code>RayChannel</code> enables async data exchange between coroutines on a Ray cluster.</p> <p>Instantiates <code>RayChannel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>actor_options</code> <code>Optional[dict]</code> <p>Optional; Options to pass to the Ray actor. Defaults to {\"num_cpus\": 0}.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to the the underlying <code>Channel</code>.</p> <code>{}</code>"},{"location":"api/connector/connector/#plugboard.connector.RayChannel.is_closed","title":"is_closed  <code>property</code>","text":"<pre><code>is_closed: bool\n</code></pre> <p>Returns <code>True</code> if the <code>RayChannel</code> is closed, <code>False</code> otherwise.</p> <p>When a <code>RayChannel</code> is closed, it can no longer be used to send messages, though there may still be some messages waiting to be read.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayChannel.maxsize","title":"maxsize  <code>property</code>","text":"<pre><code>maxsize: int\n</code></pre> <p>Returns the message capacity of the <code>RayChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayChannel.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the <code>RayChannel</code> and terminates the underlying actor.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayChannel.recv","title":"recv  <code>async</code>","text":"<pre><code>recv() -&gt; _t.Any\n</code></pre> <p>Returns an item received from the <code>RayChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.RayChannel.send","title":"send  <code>async</code>","text":"<pre><code>send(item: Any) -&gt; None\n</code></pre> <p>Sends an item through the <code>RayChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQConnector","title":"ZMQConnector","text":"<pre><code>ZMQConnector(\n    *args: Any,\n    settings: Settings = Provide[DI.settings],\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>_ZMQConnector</code></p> <p><code>ZMQConnector</code> connects components using <code>ZMQChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQConnector.zmq_address","title":"zmq_address  <code>property</code>","text":"<pre><code>zmq_address: str\n</code></pre> <p>The ZMQ address used for communication.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQConnector.connect_recv","title":"connect_recv  <code>async</code>","text":"<pre><code>connect_recv() -&gt; ZMQChannel\n</code></pre> <p>Returns a <code>ZMQChannel</code> for receiving messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQConnector.connect_send","title":"connect_send  <code>async</code>","text":"<pre><code>connect_send() -&gt; ZMQChannel\n</code></pre> <p>Returns a <code>ZMQChannel</code> for sending messages.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQChannel","title":"ZMQChannel","text":"<pre><code>ZMQChannel(\n    *args: Any,\n    send_socket: Optional[Socket] = None,\n    recv_socket: Optional[Socket] = None,\n    topic: str = \"\",\n    maxsize: int = 2000,\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>SerdeChannel</code></p> <p><code>ZMQChannel</code> enables data exchange between processes using ZeroMQ.</p> <p>Instantiates <code>ZMQChannel</code>.</p> <p>Uses ZeroMQ to provide communication between components on different processes. Note that maxsize is not a hard limit because the operating system will buffer TCP messages before they reach the channel. <code>ZMQChannel</code> provides better performance than <code>RayChannel</code>, but is only suitable for use on a single host. For multi-host communication, use <code>RayChannel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>send_socket</code> <code>Optional[Socket]</code> <p>Optional; The ZeroMQ socket for sending messages.</p> <code>None</code> <code>recv_socket</code> <code>Optional[Socket]</code> <p>Optional; The ZeroMQ socket for receiving messages.</p> <code>None</code> <code>topic</code> <code>str</code> <p>Optional; The topic for the <code>ZMQChannel</code>, defaults to an empty string. Only relevant in the case of pub-sub mode channels.</p> <code>''</code> <code>maxsize</code> <code>int</code> <p>Optional; Queue maximum item capacity, defaults to 2000.</p> <code>2000</code>"},{"location":"api/connector/connector/#plugboard.connector.ZMQChannel.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the <code>ZMQChannel</code>.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQChannel.recv","title":"recv  <code>async</code>","text":"<pre><code>recv() -&gt; bytes\n</code></pre> <p>Receives a message from the <code>ZMQChannel</code> and returns it.</p>"},{"location":"api/connector/connector/#plugboard.connector.ZMQChannel.send","title":"send  <code>async</code>","text":"<pre><code>send(msg: bytes) -&gt; None\n</code></pre> <p>Sends a message through the <code>ZMQChannel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>bytes</code> <p>The message to be sent through the <code>ZMQChannel</code>.</p> required"},{"location":"api/diagram/diagram/","title":"diagram","text":"<p>Provides classes and helper functions to visualise Plugboard processes.</p>"},{"location":"api/diagram/diagram/#plugboard.diagram.Diagram","title":"Diagram","text":"<pre><code>Diagram(**kwargs: Any)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p><code>Diagram</code> base class for creating diagrams of Plugboard processes.</p> <p>Instantiates <code>Diagram</code>.</p>"},{"location":"api/diagram/diagram/#plugboard.diagram.Diagram.diagram","title":"diagram  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>diagram: str\n</code></pre> <p>Returns a string representation of the diagram.</p>"},{"location":"api/diagram/diagram/#plugboard.diagram.Diagram.from_process","title":"from_process  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>from_process(process: Process, **kwargs: Any) -&gt; Diagram\n</code></pre> <p>Create the diagram.</p> <p>Parameters:</p> Name Type Description Default <code>process</code> <code>Process</code> <p>The <code>Process</code> object to create the diagram from.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for the diagram backend.</p> <code>{}</code>"},{"location":"api/diagram/diagram/#plugboard.diagram.MermaidDiagram","title":"MermaidDiagram","text":"<pre><code>MermaidDiagram(spec: str)\n</code></pre> <p>               Bases: <code>Diagram</code></p> <p><code>MermaidDiagram</code> class for creating diagrams of Plugboard processes using Mermaid.</p> <p>Instantiates <code>MermaidDiagram</code>.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>str</code> <p>The string representation of the diagram.</p> required"},{"location":"api/diagram/diagram/#plugboard.diagram.MermaidDiagram.diagram","title":"diagram  <code>property</code>","text":"<pre><code>diagram: str\n</code></pre> <p>Returns a string representation of the diagram.</p>"},{"location":"api/diagram/diagram/#plugboard.diagram.MermaidDiagram.url","title":"url  <code>property</code>","text":"<pre><code>url: str\n</code></pre> <p>Returns a URL to the diagram on Mermaid Live Editor.</p>"},{"location":"api/diagram/diagram/#plugboard.diagram.MermaidDiagram.from_process","title":"from_process  <code>classmethod</code>","text":"<pre><code>from_process(\n    process: Process, **kwargs: Any\n) -&gt; MermaidDiagram\n</code></pre> <p>Create the diagram.</p> <p>Parameters:</p> Name Type Description Default <code>process</code> <code>Process</code> <p>The <code>Process</code> object to create the diagram from.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for the diagram backend.</p> <code>{}</code>"},{"location":"api/diagram/diagram/#plugboard.diagram.markdown_diagram","title":"markdown_diagram","text":"<pre><code>markdown_diagram(process: Process) -&gt; str\n</code></pre> <p>Returns a markdown representation of a <code>Process</code>.</p>"},{"location":"api/events/events/","title":"events","text":"<p>Provides models and utilities for handling events.</p>"},{"location":"api/events/events/#plugboard.events.Event","title":"Event","text":"<p>               Bases: <code>PlugboardBaseModel</code>, <code>ABC</code></p> <p><code>Event</code> is a base model for all events.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>Type of the <code>Event</code>.</p> <code>id</code> <code>UUID4</code> <p>UUID v4 unique identifier for the <code>Event</code>.</p> <code>timestamp</code> <code>UTCDateTime</code> <p>UTC timestamp for the <code>Event</code>.</p> <code>source</code> <code>str</code> <p>Source of the <code>Event</code>.</p> <code>version</code> <code>str</code> <p>Version of the <code>Event</code>.</p> <code>data</code> <code>dict[str, Any] | BaseModel</code> <p>Data associated with the <code>Event</code>.</p> <code>metadata</code> <code>dict[str, str]</code> <p>Metadata for the <code>Event</code>.</p>"},{"location":"api/events/events/#plugboard.events.Event.handler","title":"handler  <code>classmethod</code>","text":"<pre><code>handler(method: AsyncCallable) -&gt; AsyncCallable\n</code></pre> <p>Registers a class method as an event handler.</p>"},{"location":"api/events/events/#plugboard.events.Event.safe_type","title":"safe_type  <code>classmethod</code>","text":"<pre><code>safe_type(event_type: Optional[str] = None) -&gt; str\n</code></pre> <p>Returns a safe event type string for use in broker topic strings.</p>"},{"location":"api/events/events/#plugboard.events.SystemEvent","title":"SystemEvent","text":"<p>               Bases: <code>Event</code>, <code>ABC</code></p> <p><code>SystemEvent</code> is a base model for system events.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>Type of the <code>SystemEvent</code>.</p> <code>id</code> <code>UUID4</code> <p>UUID v4 unique identifier for the <code>SystemEvent</code>.</p> <code>timestamp</code> <code>UTCDateTime</code> <p>UTC timestamp for the <code>SystemEvent</code>.</p> <code>source</code> <code>str</code> <p>Source of the <code>SystemEvent</code>.</p> <code>version</code> <code>str</code> <p>Version of the <code>SystemEvent</code>.</p> <code>data</code> <code>dict[str, Any] | BaseModel</code> <p>Data associated with the <code>SystemEvent</code>.</p> <code>metadata</code> <code>dict[str, str]</code> <p>Metadata for the <code>SystemEvent</code>.</p>"},{"location":"api/events/events/#plugboard.events.StopEvent","title":"StopEvent","text":"<p>               Bases: <code>SystemEvent</code></p> <p><code>StopEvent</code> is a system event to stop the application.</p>"},{"location":"api/events/events/#plugboard.events.EventConnectorBuilder","title":"EventConnectorBuilder","text":"<pre><code>EventConnectorBuilder(connector_builder: ConnectorBuilder)\n</code></pre> <p><code>EventConnectorBuilder</code> constructs connectors for component event handlers.</p>"},{"location":"api/events/events/#plugboard.events.EventConnectorBuilder.build","title":"build","text":"<pre><code>build(\n    components: Iterable[Component],\n) -&gt; dict[str, Connector]\n</code></pre> <p>Returns mapping of connectors for events handled by components.</p>"},{"location":"api/events/events/#plugboard.events.EventHandlers","title":"EventHandlers","text":"<p><code>EventHandlers</code> provides a decorator for registering event handlers.</p>"},{"location":"api/events/events/#plugboard.events.EventHandlers.add","title":"add  <code>classmethod</code>","text":"<pre><code>add(\n    event: Type[Event] | Event,\n) -&gt; _t.Callable[[AsyncCallable], AsyncCallable]\n</code></pre> <p>Decorator that registers class methods as handlers for specific event types.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Type[Event] | Event</code> <p>Event class this handler processes</p> required <p>Returns:</p> Name Type Description <code>Callable</code> <code>Callable[[AsyncCallable], AsyncCallable]</code> <p>Decorated method</p>"},{"location":"api/events/events/#plugboard.events.EventHandlers.get","title":"get  <code>classmethod</code>","text":"<pre><code>get(\n    _class: Type, event: Type[Event] | Event\n) -&gt; AsyncCallable\n</code></pre> <p>Retrieve a handler for a specific class and event type.</p> <p>Parameters:</p> Name Type Description Default <code>_class</code> <code>Type</code> <p>Class to handle event for</p> required <code>event</code> <code>Type[Event] | Event</code> <p>Event class or instance to handle</p> required <p>Returns:</p> Name Type Description <code>Callable</code> <code>AsyncCallable</code> <p>The event handler method</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If no handler found for class or event type</p>"},{"location":"api/exceptions/exceptions/","title":"exceptions","text":"<p>Provides exceptions for Plugboard.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.ChannelClosedError","title":"ChannelClosedError","text":"<p>               Bases: <code>ChannelError</code></p> <p>Raised when a closed channel is accessed.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.ChannelError","title":"ChannelError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised for channel related errors.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.ChannelNotConnectedError","title":"ChannelNotConnectedError","text":"<p>               Bases: <code>ChannelError</code></p> <p>Raised when using a channel that is not connected.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.ChannelSetupError","title":"ChannelSetupError","text":"<p>               Bases: <code>ChannelError</code></p> <p>Raised when a channel is setup incorrectly.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.ConstraintError","title":"ConstraintError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a constraint is violated.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.EventError","title":"EventError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised for event related errors.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.EventStreamClosedError","title":"EventStreamClosedError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there are no more event producers running.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.IOControllerError","title":"IOControllerError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised for IO controller related errors.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.IOSetupError","title":"IOSetupError","text":"<p>               Bases: <code>IOControllerError</code></p> <p>Raised when an IO controller is setup incorrectly.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.IOStreamClosedError","title":"IOStreamClosedError","text":"<p>               Bases: <code>IOControllerError</code></p> <p><code>IOStreamClosedError</code> is raised when an IO stream is closed.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.NoMoreDataException","title":"NoMoreDataException","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is no more data to fetch.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.NotFoundError","title":"NotFoundError","text":"<p>               Bases: <code>StateBackendError</code></p> <p>Raised when a resource is not found.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.NotInitialisedError","title":"NotInitialisedError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised attempting to step or run a <code>Process</code> or <code>Component</code> that has not been initialised.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.ProcessStatusError","title":"ProcessStatusError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a <code>Process</code> is in an invalid state for the requested operation.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.RegistryError","title":"RegistryError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an unknown class is requested from the ClassRegistry.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.StateBackendError","title":"StateBackendError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised for <code>StateBackend</code> related errors.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.UnrecognisedEventError","title":"UnrecognisedEventError","text":"<p>               Bases: <code>EventError</code></p> <p>Raised when an unrecognised event is encountered.</p>"},{"location":"api/exceptions/exceptions/#plugboard.exceptions.ValidationError","title":"ValidationError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when an invalid <code>Process</code> or <code>Component</code> is encountered.</p>"},{"location":"api/library/library/","title":"library","text":"<p>Provides implementations of Plugboard objects for use in user models.</p>"},{"location":"api/library/library/#plugboard.library.DataReader","title":"DataReader","text":"<pre><code>DataReader(\n    field_names: list[str],\n    chunk_size: Optional[int] = None,\n    **kwargs: Unpack[ComponentArgsDict],\n)\n</code></pre> <p>               Bases: <code>Component</code>, <code>ABC</code></p> <p>Abstract base class for reading data.</p> <p>Instantiates the <code>DataReader</code>.</p> <p>Parameters:</p> Name Type Description Default <code>field_names</code> <code>list[str]</code> <p>The names of the fields to read from the data source.</p> required <code>chunk_size</code> <code>Optional[int]</code> <p>The size of the data chunk to read from the data source.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[ComponentArgsDict]</code> <p>Additional keyword arguments for <code>Component</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.DataReader.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Initialises the <code>DataReader</code>.</p>"},{"location":"api/library/library/#plugboard.library.DataReader.step","title":"step  <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Reads data from the source and updates outputs.</p>"},{"location":"api/library/library/#plugboard.library.DataWriter","title":"DataWriter","text":"<pre><code>DataWriter(\n    field_names: list[str],\n    chunk_size: Optional[int] = None,\n    **kwargs: Unpack[ComponentArgsDict],\n)\n</code></pre> <p>               Bases: <code>Component</code>, <code>ABC</code></p> <p>Abstract base class for writing data.</p> <p>Instantiates the <code>DataWriter</code>.</p> <p>Parameters:</p> Name Type Description Default <code>field_names</code> <code>list[str]</code> <p>The names of the fields to write to the data source.</p> required <code>chunk_size</code> <code>Optional[int]</code> <p>The size of the data chunk to read from the DataFrame.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[ComponentArgsDict]</code> <p>Additional keyword arguments for <code>Component</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.DataWriter.run","title":"run  <code>async</code>","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Runs the <code>DataWriter</code>.</p>"},{"location":"api/library/library/#plugboard.library.DataWriter.step","title":"step  <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Trigger save when buffer is at target size.</p>"},{"location":"api/library/library/#plugboard.library.FileReader","title":"FileReader","text":"<pre><code>FileReader(\n    path: str | Path,\n    storage_options: Optional[dict[str, Any]] = None,\n    **kwargs: Unpack[DataReaderArgsSpec],\n)\n</code></pre> <p>               Bases: <code>DataReader</code></p> <p>Reads data from a file.</p> <p>Supported formats: CSV, GZIP-compressed CSV, Parquet. The file can be stored locally or on an fsspec-compatible cloud storage service.</p> <p>Instantiates the <code>FileReader</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>The path to the file to read.</p> required <code>storage_options</code> <code>Optional[dict[str, Any]]</code> <p>Optional; Additional options for the fsspec-compatible filesystem.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[DataReaderArgsSpec]</code> <p>Additional keyword arguments for <code>DataReader</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.FileWriter","title":"FileWriter","text":"<pre><code>FileWriter(\n    path: str | Path,\n    storage_options: Optional[dict[str, Any]] = None,\n    **kwargs: Unpack[DataWriterArgsSpec],\n)\n</code></pre> <p>               Bases: <code>DataWriter</code></p> <p>Writes data to a file. If the file already exists, it will be overwritten.</p> <p>Supported formats: CSV, GZIP-compressed CSV, Parquet. The file can be stored locally or on an fsspec-compatible cloud storage service.</p> <p>Instantiates the <code>FileWriter</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>The path to the file to write.</p> required <code>storage_options</code> <code>Optional[dict[str, Any]]</code> <p>Optional; Additional options for the fsspec-compatible filesystem.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[DataWriterArgsSpec]</code> <p>Additional keyword arguments for <code>DataWriter</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.LLMChat","title":"LLMChat","text":"<pre><code>LLMChat(\n    llm: str = \"llama_index.llms.openai.OpenAI\",\n    system_prompt: Optional[str] = None,\n    context_window: int = 0,\n    response_model: Optional[Type[BaseModel] | str] = None,\n    expand_response: bool = False,\n    llm_kwargs: Optional[dict[str, Any]] = None,\n    **kwargs: Unpack[ComponentArgsDict],\n)\n</code></pre> <p>               Bases: <code>_LLMBase</code></p> <p><code>LLMChat</code> is a component for interacting with large language models (LLMs).</p> <p>Requires the optional <code>plugboard[llm]</code> installation. The default LLM is OpenAI, and requires the <code>OPENAI_API_KEY</code> environment variable to be set. Other LLMs supported by llama-index can be used: see here for available models. Additional llama-index dependencies may be required for specific models.</p> <p>Structured output is supported by providing a Pydantic model as the <code>response_model</code> argument. This can optionally be unpacked into individual output fields by setting <code>expand_response=True</code>, otherwise the LLM response will be stored in the <code>response</code> output field.</p> <p>Instantiates <code>LLMChat</code>.</p> <p>Parameters:</p> Name Type Description Default <code>llm</code> <code>str</code> <p>The LLM class to use from llama-index.</p> <code>'llama_index.llms.openai.OpenAI'</code> <code>system_prompt</code> <code>Optional[str]</code> <p>Optional; System prompt to prepend to the context window.</p> <code>None</code> <code>context_window</code> <code>int</code> <p>The number of previous messages to include in the context window.</p> <code>0</code> <code>response_model</code> <code>Optional[Type[BaseModel] | str]</code> <p>Optional; A Pydantic model to structure the response. Can be specified as a string identifying the namespaced class to use.</p> <code>None</code> <code>expand_response</code> <code>bool</code> <p>Setting this to <code>True</code> when using a structured response model will cause the individual attributes of the response model to be added as output fields.</p> <code>False</code> <code>llm_kwargs</code> <code>Optional[dict[str, Any]]</code> <p>Additional keyword arguments for the LLM.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[ComponentArgsDict]</code> <p>Additional keyword arguments for <code>Component</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.LLMImageProcessor","title":"LLMImageProcessor","text":"<pre><code>LLMImageProcessor(\n    llm: str = \"llama_index.llms.openai.OpenAI\",\n    prompt: str | None = None,\n    response_model: Optional[Type[BaseModel] | str] = None,\n    expand_response: bool = False,\n    llm_kwargs: Optional[dict[str, Any]] = None,\n    **kwargs: Unpack[ComponentArgsDict],\n)\n</code></pre> <p>               Bases: <code>_LLMBase</code></p> <p><code>LLMImageProcessor</code> processes an image with a vision-capable LLM.</p> <p>Sends a (optional) textual prompt plus an image to a llama-index LLM. The image may be provided either as a URL string (http/https or data URI) or as raw bytes. Structured output is supported via a Pydantic <code>response_model</code>.</p> Inputs <p>image: Union[str, bytes]; if <code>str</code> treated as URL, if <code>bytes</code> passed directly via     <code>ImageBlock(image=...)</code>.</p> Outputs <p>response: Raw string response unless <code>expand_response=True</code> with a structured model. (If structured + expanded: individual model fields become outputs.)</p> <p>Instantiate <code>LLMImageProcessor</code>.</p> <p>Parameters:</p> Name Type Description Default <code>llm</code> <code>str</code> <p>The vision-capable LLM class path for llama-index.</p> <code>'llama_index.llms.openai.OpenAI'</code> <code>prompt</code> <code>str | None</code> <p>Optional; A base prompt applied to each request (can include instructions about desired output format, etc.).</p> <code>None</code> <code>response_model</code> <code>Optional[Type[BaseModel] | str]</code> <p>Optional; Pydantic model (or namespaced string) describing structured output expected from the LLM.</p> <code>None</code> <code>expand_response</code> <code>bool</code> <p>When using a structured response model, expands fields into outputs.</p> <code>False</code> <code>llm_kwargs</code> <code>Optional[dict[str, Any]]</code> <p>Extra kwargs passed to the LLM constructor (e.g. {\"model\": \"gpt-4o\"}).</p> <code>None</code> <code>**kwargs</code> <code>Unpack[ComponentArgsDict]</code> <p>Standard Component args.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.SQLReader","title":"SQLReader","text":"<pre><code>SQLReader(\n    connection_string: str,\n    query: str,\n    params: Optional[dict[str, Any]] = None,\n    connect_args: Optional[dict[str, Any]] = None,\n    **kwargs: Unpack[DataReaderArgsSpec],\n)\n</code></pre> <p>               Bases: <code>DataReader</code></p> <p>Reads data from an SQL database using a supplied query and optional parameters.</p> <p>The underlying database connection is managed by SQLAlchemy: both synchronous and asynchronous drivers are supported.</p> <p>Instantiates the <code>SQLReader</code>.</p> <p>Parameters:</p> Name Type Description Default <code>connection_string</code> <code>str</code> <p>The connection string for the database.</p> required <code>query</code> <code>str</code> <p>The SQL query to run on the database.</p> required <code>params</code> <code>Optional[dict[str, Any]]</code> <p>Optional; Parameters to pass to the query.</p> <code>None</code> <code>connect_args</code> <code>Optional[dict[str, Any]]</code> <p>Optional; Additional options for the database connection.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[DataReaderArgsSpec]</code> <p>Additional keyword arguments for <code>DataReader</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.SQLWriter","title":"SQLWriter","text":"<pre><code>SQLWriter(\n    connection_string: str,\n    table: str,\n    connect_args: Optional[dict[str, Any]] = None,\n    **kwargs: Unpack[DataWriterArgsSpec],\n)\n</code></pre> <p>               Bases: <code>DataWriter</code></p> <p>Writes data to an SQL database. The specified table must already exist.</p> <p>The underlying database connection is managed by SQLAlchemy: both synchronous and asynchronous drivers are supported.</p> <p>Instantiates the <code>SQLWriter</code>.</p> <p>Parameters:</p> Name Type Description Default <code>connection_string</code> <code>str</code> <p>The connection string for the database.</p> required <code>table</code> <code>str</code> <p>The name of the table to write to, which must already exist.</p> required <code>connect_args</code> <code>Optional[dict[str, Any]]</code> <p>Optional; Additional options for the database connection.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[DataWriterArgsSpec]</code> <p>Additional keyword arguments for <code>DataWriter</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.WebsocketBase","title":"WebsocketBase","text":"<pre><code>WebsocketBase(\n    uri: str,\n    connect_args: dict[str, Any] | None = None,\n    **kwargs: Unpack[ComponentArgsDict],\n)\n</code></pre> <p>               Bases: <code>Component</code>, <code>ABC</code></p> <p>Base <code>Component</code> for websocket connections.</p> <p>See websockets for more info on the underlying websocket library.</p> <p>Instantiates the <code>Component</code>.</p> <p>Parameters:</p> Name Type Description Default <code>uri</code> <code>str</code> <p>The URI of the WebSocket server.</p> required <code>connect_args</code> <code>dict[str, Any] | None</code> <p>Optional; Additional arguments to pass to the WebSocket connection.</p> <code>None</code> <code>**kwargs</code> <code>Unpack[ComponentArgsDict]</code> <p>Additional keyword arguments for <code>Component</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.WebsocketBase.destroy","title":"destroy  <code>async</code>","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Closes the websocket connection.</p>"},{"location":"api/library/library/#plugboard.library.WebsocketBase.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Initializes the websocket connection.</p>"},{"location":"api/library/library/#plugboard.library.WebsocketReader","title":"WebsocketReader","text":"<pre><code>WebsocketReader(\n    initial_message: Any | None = None,\n    skip_messages: int = 0,\n    parse_json: bool = False,\n    **kwargs: Unpack[WebsocketArgsDict],\n)\n</code></pre> <p>               Bases: <code>WebsocketBase</code></p> <p>Reads data from a websocket connection.</p> <p>Instantiates the <code>WebsocketReader</code>.</p> <p>See here for possible connection arguments that can be passed using <code>connect_args</code>. This <code>WebsocketReader</code> will run until interrupted, and automatically reconnect if the server connection is lost.</p> <p>Parameters:</p> Name Type Description Default <code>initial_message</code> <code>Any | None</code> <p>Optional; The initial message to send to the WebSocket server on connection. Can be used to subscribe to a specific topic.</p> <code>None</code> <code>skip_messages</code> <code>int</code> <p>The number of messages to ignore before starting to read messages.</p> <code>0</code> <code>parse_json</code> <code>bool</code> <p>Whether to parse the received data as JSON.</p> <code>False</code> <code>**kwargs</code> <code>Unpack[WebsocketArgsDict]</code> <p>Additional keyword arguments for <code>WebsocketBase</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.WebsocketReader.step","title":"step  <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Reads a message from the websocket connection.</p>"},{"location":"api/library/library/#plugboard.library.WebsocketWriter","title":"WebsocketWriter","text":"<pre><code>WebsocketWriter(\n    parse_json: bool = False,\n    **kwargs: Unpack[WebsocketArgsDict],\n)\n</code></pre> <p>               Bases: <code>WebsocketBase</code></p> <p>Writes data to a websocket connection.</p> <p>Instantiates the <code>WebsocketWriter</code>.</p> <p>See here for possible connection arguments that can be passed using <code>connect_args</code>.</p> <p>Parameters:</p> Name Type Description Default <code>parse_json</code> <code>bool</code> <p>Whether to convert the data to JSON before sending.</p> <code>False</code> <code>**kwargs</code> <code>Unpack[WebsocketArgsDict]</code> <p>Additional keyword arguments for <code>WebsocketBase</code>.</p> <code>{}</code>"},{"location":"api/library/library/#plugboard.library.WebsocketWriter.step","title":"step  <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Writes a message to the websocket connection.</p>"},{"location":"api/process/process/","title":"process","text":"<p>Process submodule providing functionality related to processes and their execution.</p>"},{"location":"api/process/process/#plugboard.process.Process","title":"Process","text":"<pre><code>Process(\n    components: Iterable[Component],\n    connectors: Iterable[Connector],\n    name: Optional[str] = None,\n    parameters: Optional[dict[str, Any]] = None,\n    state: Optional[StateBackend] = None,\n)\n</code></pre> <p>               Bases: <code>ExportMixin</code>, <code>ABC</code></p> <p><code>Process</code> is a base class for managing components in a model.</p> <p>Instantiates a <code>Process</code>.</p> <p>Parameters:</p> Name Type Description Default <code>components</code> <code>Iterable[Component]</code> <p>The components in the <code>Process</code>.</p> required <code>connectors</code> <code>Iterable[Connector]</code> <p>The connectors between the components.</p> required <code>name</code> <code>Optional[str]</code> <p>Optional; Name for this <code>Process</code>.</p> <code>None</code> <code>parameters</code> <code>Optional[dict[str, Any]]</code> <p>Optional; Parameters for the <code>Process</code>. These will be shared across all <code>Component</code> objects within the <code>Process</code>.</p> <code>None</code> <code>state</code> <code>Optional[StateBackend]</code> <p>Optional; <code>StateBackend</code> for the <code>Process</code>.</p> <code>None</code>"},{"location":"api/process/process/#plugboard.process.Process.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Unique ID for <code>Process</code>.</p>"},{"location":"api/process/process/#plugboard.process.Process.is_initialised","title":"is_initialised  <code>property</code>","text":"<pre><code>is_initialised: bool\n</code></pre> <p>Returns whether the <code>Process</code> is initialised.</p>"},{"location":"api/process/process/#plugboard.process.Process.state","title":"state  <code>property</code>","text":"<pre><code>state: StateBackend\n</code></pre> <p>State backend for the process.</p>"},{"location":"api/process/process/#plugboard.process.Process.status","title":"status  <code>property</code>","text":"<pre><code>status: Status\n</code></pre> <p>Returns the current status of the <code>Process</code>.</p>"},{"location":"api/process/process/#plugboard.process.Process.__aenter__","title":"__aenter__  <code>async</code>","text":"<pre><code>__aenter__() -&gt; Process\n</code></pre> <p>Enters the context manager.</p>"},{"location":"api/process/process/#plugboard.process.Process.__aexit__","title":"__aexit__  <code>async</code>","text":"<pre><code>__aexit__(\n    exc_type: Optional[Type[BaseException]],\n    exc_value: Optional[BaseException],\n    traceback: Optional[TracebackType],\n) -&gt; None\n</code></pre> <p>Exits the context manager.</p>"},{"location":"api/process/process/#plugboard.process.Process.cancel","title":"cancel  <code>abstractmethod</code>","text":"<pre><code>cancel() -&gt; None\n</code></pre> <p>Cancels the process run.</p>"},{"location":"api/process/process/#plugboard.process.Process.connect_state","title":"connect_state  <code>async</code>","text":"<pre><code>connect_state(state: Optional[StateBackend] = None) -&gt; None\n</code></pre> <p>Connects the <code>Process</code> to the <code>StateBackend</code>.</p>"},{"location":"api/process/process/#plugboard.process.Process.destroy","title":"destroy  <code>async</code>","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Performs tear-down actions for the <code>Process</code> and its <code>Component</code>s.</p>"},{"location":"api/process/process/#plugboard.process.Process.dump","title":"dump","text":"<pre><code>dump(path: Path | str) -&gt; None\n</code></pre> <p>Saves to <code>Process</code> configuration to a YAML file for use with the CLI.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>The path to the YAML file. Will be overwritten if it exists.</p> required"},{"location":"api/process/process/#plugboard.process.Process.init","title":"init  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Performs component initialisation actions.</p>"},{"location":"api/process/process/#plugboard.process.Process.run","title":"run  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Runs the process to completion.</p>"},{"location":"api/process/process/#plugboard.process.Process.step","title":"step  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Executes a single step for the process.</p>"},{"location":"api/process/process/#plugboard.process.LocalProcess","title":"LocalProcess","text":"<pre><code>LocalProcess(\n    components: Iterable[Component],\n    connectors: Iterable[Connector],\n    name: Optional[str] = None,\n    parameters: Optional[dict[str, Any]] = None,\n    state: Optional[StateBackend] = None,\n)\n</code></pre> <p>               Bases: <code>Process</code></p> <p><code>LocalProcess</code> manages components in a process model on a single processor.</p> <p>Instantiates a <code>LocalProcess</code>.</p> <p>Parameters:</p> Name Type Description Default <code>components</code> <code>Iterable[Component]</code> <p>The components in the <code>Process</code>.</p> required <code>connectors</code> <code>Iterable[Connector]</code> <p>The connectors between the components.</p> required <code>name</code> <code>Optional[str]</code> <p>Optional; Name for this <code>Process</code>.</p> <code>None</code> <code>parameters</code> <code>Optional[dict[str, Any]]</code> <p>Optional; Parameters for the <code>Process</code>.</p> <code>None</code> <code>state</code> <code>Optional[StateBackend]</code> <p>Optional; <code>StateBackend</code> for the <code>Process</code>.</p> <code>None</code>"},{"location":"api/process/process/#plugboard.process.LocalProcess.cancel","title":"cancel","text":"<pre><code>cancel() -&gt; None\n</code></pre> <p>Cancels the process run.</p>"},{"location":"api/process/process/#plugboard.process.LocalProcess.destroy","title":"destroy  <code>async</code>","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Performs tear-down actions for the <code>LocalProcess</code> and its <code>Component</code>s.</p>"},{"location":"api/process/process/#plugboard.process.LocalProcess.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Performs component initialisation actions.</p>"},{"location":"api/process/process/#plugboard.process.LocalProcess.run","title":"run  <code>async</code>","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Runs the process to completion.</p>"},{"location":"api/process/process/#plugboard.process.LocalProcess.step","title":"step  <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Executes a single step for the process.</p>"},{"location":"api/process/process/#plugboard.process.RayProcess","title":"RayProcess","text":"<pre><code>RayProcess(\n    components: Iterable[Component],\n    connectors: Iterable[Connector],\n    name: Optional[str] = None,\n    parameters: Optional[dict] = None,\n    state: Optional[StateBackend] = None,\n)\n</code></pre> <p>               Bases: <code>Process</code></p> <p><code>RayProcess</code> manages components in a process model on a multiple Ray actors.</p> <p>Instantiates a <code>RayProcess</code>.</p> <p>Parameters:</p> Name Type Description Default <code>components</code> <code>Iterable[Component]</code> <p>The components in the <code>Process</code>.</p> required <code>connectors</code> <code>Iterable[Connector]</code> <p>The connectors between the components.</p> required <code>name</code> <code>Optional[str]</code> <p>Optional; Name for this <code>Process</code>.</p> <code>None</code> <code>parameters</code> <code>Optional[dict]</code> <p>Optional; Parameters for the <code>Process</code>.</p> <code>None</code> <code>state</code> <code>Optional[StateBackend]</code> <p>Optional; <code>StateBackend</code> for the <code>Process</code>.</p> <code>None</code>"},{"location":"api/process/process/#plugboard.process.RayProcess.cancel","title":"cancel","text":"<pre><code>cancel() -&gt; None\n</code></pre> <p>Cancels the process run.</p>"},{"location":"api/process/process/#plugboard.process.RayProcess.destroy","title":"destroy  <code>async</code>","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Performs tear-down actions for the <code>RayProcess</code> and its <code>Component</code>s.</p>"},{"location":"api/process/process/#plugboard.process.RayProcess.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Performs component initialisation actions.</p>"},{"location":"api/process/process/#plugboard.process.RayProcess.run","title":"run  <code>async</code>","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Runs the process to completion.</p>"},{"location":"api/process/process/#plugboard.process.RayProcess.step","title":"step  <code>async</code>","text":"<pre><code>step() -&gt; None\n</code></pre> <p>Executes a single step for the process.</p>"},{"location":"api/schemas/schemas/","title":"schemas","text":"<p>Provides schemas used in Plugboard.</p> <p>This includes:</p> <ul> <li>Pydantic models for specifying Plugboard objects;</li> <li><code>TypeDict</code> definitions for constructor <code>**kwargs</code>.</li> </ul>"},{"location":"api/schemas/schemas/#plugboard_schemas.Direction","title":"Direction  <code>module-attribute</code>","text":"<pre><code>Direction = Literal['min', 'max']\n</code></pre> <p>A type for the direction of optimisation.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ParameterSpec","title":"ParameterSpec  <code>module-attribute</code>","text":"<pre><code>ParameterSpec = Union[\n    FloatParameterSpec,\n    IntParameterSpec,\n    CategoricalParameterSpec,\n]\n</code></pre> <p>A union type for all parameter specifications.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.CategoricalParameterSpec","title":"CategoricalParameterSpec","text":"<p>               Bases: <code>BaseFieldSpec</code></p> <p>Specification for a categorical parameter.</p> <p>See: https://docs.ray.io/en/latest/tune/api/search_space.html.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['ray.tune.choice']</code> <p>The type of the parameter.</p> <code>categories</code> <code>list[Any]</code> <p>The categories of the parameter.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ComponentArgsDict","title":"ComponentArgsDict","text":"<p>               Bases: <code>TypedDict</code></p> <p><code>TypedDict</code> of the <code>Component</code> constructor arguments.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ComponentArgsSpec","title":"ComponentArgsSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of the <code>Component</code> constructor arguments.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the <code>Component</code>.</p> <code>initial_values</code> <code>dict[str, Any]</code> <p>Initial values for the <code>Component</code>.</p> <code>parameters</code> <code>dict[str, Any]</code> <p>Parameters for the <code>Component</code>.</p> <code>constraints</code> <code>dict[str, Any]</code> <p>Constraints for the <code>Component</code>.</p> <code>resources</code> <code>Resource | None</code> <p>Resource requirements for the <code>Component</code>.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ComponentSpec","title":"ComponentSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of a <code>Component</code>.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>The type of the <code>Component</code>.</p> <code>args</code> <code>ComponentArgsSpec</code> <p>The arguments for the <code>Component</code>.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ConfigSpec","title":"ConfigSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Configuration for a Plugboard simulation.</p> <p>Attributes:</p> Name Type Description <code>plugboard</code> <code>ProcessConfigSpec</code> <p>A <code>ProcessConfig</code> that specifies the Plugboard <code>Process</code>.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ConnectorBuilderArgsDict","title":"ConnectorBuilderArgsDict","text":"<p>               Bases: <code>TypedDict</code></p> <p><code>TypedDict</code> of the <code>Connector</code> constructor arguments.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ConnectorBuilderArgsSpec","title":"ConnectorBuilderArgsSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of the <code>Connector</code> constructor arguments.</p> <p>Attributes:</p> Name Type Description <code>parameters</code> <code>dict[str, Any]</code> <p>Parameters for the <code>Connector</code>.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ConnectorBuilderSpec","title":"ConnectorBuilderSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of a <code>ConnectorBuilder</code>.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>The type of the <code>ConnectorBuilder</code>.</p> <code>args</code> <code>ConnectorBuilderArgsSpec</code> <p>Optional; The arguments for the <code>ConnectorBuilder</code>.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ConnectorMode","title":"ConnectorMode","text":"<p>               Bases: <code>StrEnum</code></p> <p>Defines the mode of a connector.</p> <p>Attributes:</p> Name Type Description <code>PIPELINE</code> <p>one-in-one-out task queue.</p> <code>PUBSUB</code> <p>one-to-many event distribution.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ConnectorSocket","title":"ConnectorSocket","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p><code>ConnectorSocket</code> defines a source or target connection point on a <code>Connector</code>.</p> <p>There are two typical types of connections in use: those between attributes of components; and those connecting components with events which they either emit or consume. When connecting two component attributes together, the <code>entity</code> is the name of the component, and the <code>descriptor</code> is the name of the attribute. When connecting components with events, the <code>entity</code> is the name of the event, and the <code>descriptor</code> is either \"publishers\" or \"subscribers\" as appropriate.</p> <p>Attributes:</p> Name Type Description <code>entity</code> <code>str</code> <p>The name of the entity.</p> <code>descriptor</code> <code>str</code> <p>The name of the descriptor on the entity.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ConnectorSocket.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Unique ID for <code>ConnectorSocket</code>.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ConnectorSocket.connects_to","title":"connects_to","text":"<pre><code>connects_to(entities: Container[str]) -&gt; bool\n</code></pre> <p>Returns <code>True</code> if the <code>ConnectorSocket</code> connects to any of the named entities.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ConnectorSocket.from_ref","title":"from_ref  <code>classmethod</code>","text":"<pre><code>from_ref(ref: str) -&gt; _t.Self\n</code></pre> <p>Creates a <code>ConnectorSocket</code> from a reference string.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ConnectorSpec","title":"ConnectorSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p><code>ConnectorSpec</code> defines a connection between two entities.</p> <p>Attributes:</p> Name Type Description <code>source</code> <code>ConnectorSocket</code> <p>The source endpoint.</p> <code>target</code> <code>ConnectorSocket</code> <p>The target endpoint.</p> <code>mode</code> <code>ConnectorMode</code> <p>The mode of the connector.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ConnectorSpec.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Unique ID for <code>ConnectorSpec</code>.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.Entity","title":"Entity","text":"<p>               Bases: <code>StrEnum</code></p> <p>Entity names.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.Entity.id_prefix","title":"id_prefix  <code>property</code>","text":"<pre><code>id_prefix: str\n</code></pre> <p>Returns prefix for generating unique entity ids.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.Entity.id_regex","title":"id_regex  <code>property</code>","text":"<pre><code>id_regex: str\n</code></pre> <p>Returns regex for validating entity ids.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.FloatParameterSpec","title":"FloatParameterSpec","text":"<p>               Bases: <code>BaseFieldSpec</code></p> <p>Specification for a uniform float parameter.</p> <p>See: https://docs.ray.io/en/latest/tune/api/search_space.html.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['ray.tune.uniform']</code> <p>The type of the parameter.</p> <code>lower</code> <code>float</code> <p>The lower bound of the parameter.</p> <code>upper</code> <code>float</code> <p>The upper bound of the parameter.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.IODirection","title":"IODirection","text":"<p>               Bases: <code>StrEnum</code></p> <p><code>IODirection</code> defines the type of IO operation.</p> <p>Attributes:</p> Name Type Description <code>INPUT</code> <p>Specifies an input to a <code>Component</code>.</p> <code>OUTPUT</code> <p>Specifies an output to a <code>Component</code>.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.IntParameterSpec","title":"IntParameterSpec","text":"<p>               Bases: <code>BaseFieldSpec</code></p> <p>Specification for a uniform integer parameter.</p> <p>See: https://docs.ray.io/en/latest/tune/api/search_space.html.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['ray.tune.randint']</code> <p>The type of the parameter.</p> <code>lower</code> <code>int</code> <p>The lower bound of the parameter.</p> <code>upper</code> <code>int</code> <p>The upper bound of the parameter.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ObjectiveSpec","title":"ObjectiveSpec","text":"<p>               Bases: <code>BaseFieldSpec</code></p> <p>Specification for an objective field.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.OptunaSpec","title":"OptunaSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification for the Optuna configuration.</p> <p>See: https://docs.ray.io/en/latest/tune/api/doc/ray.tune.search.optuna.OptunaSearch.html and https://optuna.readthedocs.io/en/stable/reference/index.html for more information on the Optuna configuration.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['ray.tune.search.optuna.OptunaSearch']</code> <p>The algorithm type to load.</p> <code>space</code> <code>str | None</code> <p>Optional; A function defining the search space. Use this to define more complex search spaces that cannot be represented using the built-in parameter types.</p> <code>study_name</code> <code>str | None</code> <p>Optional; The name of the study.</p> <code>storage</code> <code>str | None</code> <p>Optional; The storage URI to save the optimisation results to.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.PlugboardBaseModel","title":"PlugboardBaseModel","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Custom base model for Plugboard schemas.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ProcessArgsDict","title":"ProcessArgsDict","text":"<p>               Bases: <code>TypedDict</code></p> <p><code>TypedDict</code> of the <code>Process</code> constructor arguments.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ProcessArgsSpec","title":"ProcessArgsSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of the <code>Process</code> constructor arguments.</p> <p>Attributes:</p> Name Type Description <code>components</code> <code>Annotated[list[ComponentSpec], Len(min_length=1)]</code> <p>Specifies each <code>Component</code> in the <code>Process</code>.</p> <code>connectors</code> <code>list[ConnectorSpec]</code> <p>Specifies the connections between each <code>Component</code>.</p> <code>name</code> <code>Optional[str]</code> <p>Unique identifier for <code>Process</code>.</p> <code>parameters</code> <code>dict[str, Any]</code> <p>Parameters for the <code>Process</code>. These will be shared across all <code>Component</code> objects within the <code>Process</code>.</p> <code>state</code> <code>StateBackendSpec</code> <p>Optional; Specifies the <code>StateBackend</code> used for the <code>Process</code>.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ProcessConfigSpec","title":"ProcessConfigSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>A <code>ProcessSpec</code> within a Plugboard configuration.</p> <p>Attributes:</p> Name Type Description <code>process</code> <code>ProcessSpec</code> <p>A <code>ProcessSpec</code> that specifies the process, or a path to a YAML file containing the process specification.</p> <code>tune</code> <code>TuneSpec | None</code> <p>Optional; A <code>TuneSpec</code> that specifies an optimisation configuration.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.ProcessSpec","title":"ProcessSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of a Plugboard <code>Process</code>.</p> <p>Attributes:</p> Name Type Description <code>args</code> <code>ProcessArgsSpec</code> <p>The arguments for the <code>Process</code>.</p> <code>type</code> <code>Literal['plugboard.process.LocalProcess', 'plugboard.process.RayProcess']</code> <p>The type of <code>Process</code> to build.</p> <code>connector_builder</code> <code>ConnectorBuilderSpec</code> <p>The <code>ConnectorBuilder</code> to use for the <code>Process</code>.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.Resource","title":"Resource","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Resource requirements for a component.</p> <p>Supports specification of CPU, GPU, memory, and custom resources. Values can be specified as numbers or strings with units (e.g., \"250m\" for 0.25, \"10Mi\" for 10 * 1024 * 1024).</p> <p>Attributes:</p> Name Type Description <code>cpu</code> <code>float</code> <p>CPU requirement (default: 0.001).</p> <code>gpu</code> <code>float</code> <p>GPU requirement (default: 0).</p> <code>memory</code> <code>int</code> <p>Memory requirement in bytes as an integer (default: 0).</p> <code>resources</code> <code>dict[str, float]</code> <p>Custom resource requirements as a dictionary.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.Resource.to_ray_options","title":"to_ray_options","text":"<pre><code>to_ray_options(\n    style: Literal[\"actor\", \"placement_group\"] = \"actor\",\n) -&gt; dict[str, _t.Any]\n</code></pre> <p>Convert resource requirements to Ray actor options.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary of Ray actor options.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.StateBackendArgsDict","title":"StateBackendArgsDict","text":"<p>               Bases: <code>TypedDict</code></p> <p><code>TypedDict</code> of the <code>StateBackend</code> constructor arguments.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.StateBackendArgsSpec","title":"StateBackendArgsSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of the <code>StateBackend</code> constructor arguments.</p> <p>Attributes:</p> Name Type Description <code>job_id</code> <code>Optional[str]</code> <p>The unique id for the job.</p> <code>metadata</code> <code>dict[str, Any]</code> <p>Metadata for a run.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.StateBackendSpec","title":"StateBackendSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of a Plugboard <code>StateBackend</code>.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>The type of the <code>StateBackend</code>.</p> <code>args</code> <code>StateBackendArgsSpec</code> <p>The arguments for the <code>StateBackend</code>.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.Status","title":"Status","text":"<p>               Bases: <code>StrEnum</code></p> <p><code>Status</code> describes the status of either a <code>Component</code> or a <code>Process</code>.</p> <p>Attributes:</p> Name Type Description <code>CREATED</code> <p>The <code>Component</code> or <code>Process</code> has been created but not yet started.</p> <code>INIT</code> <p>The <code>Component</code> or <code>Process</code> has been initialised but has not started running.</p> <code>RUNNING</code> <p>The <code>Component</code> or <code>Process</code> is currently running.</p> <code>WAITING</code> <p>The <code>Component</code> or <code>Process</code> is waiting for input.</p> <code>COMPLETED</code> <p>The <code>Component</code> or <code>Process</code> has completed successfully.</p> <code>FAILED</code> <p>The <code>Component</code> or <code>Process</code> has failed.</p> <code>STOPPED</code> <p>The <code>Component</code> or <code>Process</code> has been cancelled or stopped.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.Status.is_terminal","title":"is_terminal  <code>property</code>","text":"<pre><code>is_terminal: bool\n</code></pre> <p>Returns whether the status is terminal.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.TuneArgsDict","title":"TuneArgsDict","text":"<p>               Bases: <code>TypedDict</code></p> <p><code>TypedDict</code> of the <code>Tuner</code> constructor arguments.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.TuneArgsSpec","title":"TuneArgsSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Specification of the arguments for the <code>Tune</code> class.</p> <p>Attributes:</p> Name Type Description <code>objective</code> <code>ObjectiveSpec | list[ObjectiveSpec]</code> <p>The location of the objective(s) to optimise for in the <code>Process</code>.</p> <code>parameters</code> <code>list[ParameterSpec]</code> <p>The parameters to optimise over.</p> <code>num_samples</code> <code>PositiveInt</code> <p>The number of samples to draw during the optimisation.</p> <code>mode</code> <code>Direction | list[Direction]</code> <p>The mode of optimisation. For multi-objective optimisation, this should be a list containing a direction for each objective.</p> <code>max_concurrent</code> <code>PositiveInt | None</code> <p>The maximum number of concurrent trials.</p> <code>algorithm</code> <code>Union[OptunaSpec]</code> <p>The algorithm to use for the optimisation.</p>"},{"location":"api/schemas/schemas/#plugboard_schemas.TuneSpec","title":"TuneSpec","text":"<p>               Bases: <code>PlugboardBaseModel</code></p> <p>Configuration for an optimisation job.</p> <p>Attributes:</p> Name Type Description <code>args</code> <code>TuneArgsSpec</code> <p>The arguments for the <code>Tune</code> job.</p>"},{"location":"api/state/state/","title":"state","text":"<p>State submodule providing functionality related to persisting process or component state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend","title":"StateBackend","text":"<pre><code>StateBackend(\n    job_id: Optional[str] = None,\n    metadata: Optional[dict] = None,\n    **kwargs: Any,\n)\n</code></pre> <p>               Bases: <code>ABC</code>, <code>ExportMixin</code></p> <p><code>StateBackend</code> defines an interface for managing process state.</p> <p>Instantiates <code>StateBackend</code>.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>Optional[str]</code> <p>The unique id for the job.</p> <code>None</code> <code>metadata</code> <code>Optional[dict]</code> <p>Metadata key value pairs.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code>"},{"location":"api/state/state/#plugboard.state.StateBackend.created_at","title":"created_at  <code>property</code>","text":"<pre><code>created_at: str\n</code></pre> <p>Returns date and time of job creation.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.job_id","title":"job_id  <code>property</code>","text":"<pre><code>job_id: str\n</code></pre> <p>Returns the job id for the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.metadata","title":"metadata  <code>property</code>","text":"<pre><code>metadata: dict\n</code></pre> <p>Returns metadata attached to the job.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.__aenter__","title":"__aenter__  <code>async</code>","text":"<pre><code>__aenter__() -&gt; StateBackend\n</code></pre> <p>Enters the context manager.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.__aexit__","title":"__aexit__  <code>async</code>","text":"<pre><code>__aexit__(\n    exc_type: Optional[Type[BaseException]],\n    exc_value: Optional[BaseException],\n    traceback: Optional[TracebackType],\n) -&gt; None\n</code></pre> <p>Exits the context manager.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.destroy","title":"destroy  <code>async</code>","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Destroys the <code>StateBackend</code>.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.get_component","title":"get_component  <code>async</code>","text":"<pre><code>get_component(component_id: str) -&gt; dict\n</code></pre> <p>Returns a component from the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.get_connector","title":"get_connector  <code>async</code>","text":"<pre><code>get_connector(connector_id: str) -&gt; dict\n</code></pre> <p>Returns a connector from the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.get_process","title":"get_process  <code>async</code>","text":"<pre><code>get_process(process_id: str) -&gt; dict\n</code></pre> <p>Returns a process from the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.get_process_for_component","title":"get_process_for_component  <code>async</code>","text":"<pre><code>get_process_for_component(component_id: str) -&gt; dict\n</code></pre> <p>Gets the process that a component belongs to.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.get_process_status","title":"get_process_status  <code>async</code>","text":"<pre><code>get_process_status(process_id: str) -&gt; Status\n</code></pre> <p>Gets the status of a process from the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.get_process_status_for_component","title":"get_process_status_for_component  <code>async</code>","text":"<pre><code>get_process_status_for_component(\n    component_id: str,\n) -&gt; Status\n</code></pre> <p>Gets the status of the process that a component belongs to.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Initialises the <code>StateBackend</code>.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.update_process_status","title":"update_process_status  <code>async</code>","text":"<pre><code>update_process_status(\n    process_id: str, status: Status\n) -&gt; None\n</code></pre> <p>Updates the status of a process in the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.upsert_component","title":"upsert_component  <code>async</code>","text":"<pre><code>upsert_component(component: Component) -&gt; None\n</code></pre> <p>Upserts a component into the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.upsert_connector","title":"upsert_connector  <code>async</code>","text":"<pre><code>upsert_connector(connector: Connector) -&gt; None\n</code></pre> <p>Upserts a connector into the state.</p>"},{"location":"api/state/state/#plugboard.state.StateBackend.upsert_process","title":"upsert_process  <code>async</code>","text":"<pre><code>upsert_process(\n    process: Process, with_components: bool = False\n) -&gt; None\n</code></pre> <p>Upserts a process into the state.</p>"},{"location":"api/state/state/#plugboard.state.DictStateBackend","title":"DictStateBackend","text":"<pre><code>DictStateBackend(*args: Any, **kwargs: Any)\n</code></pre> <p>               Bases: <code>StateBackend</code></p> <p><code>DictStateBackend</code> provides state persistence for single process runs.</p> <p>Instantiates <code>DictStateBackend</code>.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend","title":"SqliteStateBackend","text":"<pre><code>SqliteStateBackend(\n    db_path: str = \"plugboard.db\", *args: Any, **kwargs: Any\n)\n</code></pre> <p>               Bases: <code>StateBackend</code></p> <p><code>SqliteStateBackend</code> handles single host persistent state.</p> <p>Initializes <code>SqliteStateBackend</code> with <code>db_path</code>.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.destroy","title":"destroy  <code>async</code>","text":"<pre><code>destroy() -&gt; None\n</code></pre> <p>Destroys the <code>SqliteStateBackend</code>.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.get_component","title":"get_component  <code>async</code>","text":"<pre><code>get_component(component_id: str) -&gt; dict\n</code></pre> <p>Returns a component from the state.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.get_connector","title":"get_connector  <code>async</code>","text":"<pre><code>get_connector(connector_id: str) -&gt; dict\n</code></pre> <p>Returns a connector from the state.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.get_process","title":"get_process  <code>async</code>","text":"<pre><code>get_process(process_id: str) -&gt; dict\n</code></pre> <p>Returns a process from the state.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.get_process_for_component","title":"get_process_for_component  <code>async</code>","text":"<pre><code>get_process_for_component(component_id: str) -&gt; dict\n</code></pre> <p>Gets the process that a component belongs to.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.get_process_status","title":"get_process_status  <code>async</code>","text":"<pre><code>get_process_status(process_id: str) -&gt; Status\n</code></pre> <p>Gets the status of a process from the state.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.get_process_status_for_component","title":"get_process_status_for_component  <code>async</code>","text":"<pre><code>get_process_status_for_component(\n    component_id: str,\n) -&gt; Status\n</code></pre> <p>Gets the status of the process that a component belongs to.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.init","title":"init  <code>async</code>","text":"<pre><code>init() -&gt; None\n</code></pre> <p>Initializes the <code>SqliteStateBackend</code>.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.update_process_status","title":"update_process_status  <code>async</code>","text":"<pre><code>update_process_status(\n    process_id: str, status: Status\n) -&gt; None\n</code></pre> <p>Updates the status of a process in the state.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.upsert_component","title":"upsert_component  <code>async</code>","text":"<pre><code>upsert_component(component: Component) -&gt; None\n</code></pre> <p>Upserts a component into the state.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.upsert_connector","title":"upsert_connector  <code>async</code>","text":"<pre><code>upsert_connector(connector: Connector) -&gt; None\n</code></pre> <p>Upserts a connector into the state.</p>"},{"location":"api/state/state/#plugboard.state.SqliteStateBackend.upsert_process","title":"upsert_process  <code>async</code>","text":"<pre><code>upsert_process(\n    process: Process, with_components: bool = False\n) -&gt; None\n</code></pre> <p>Upserts a process into the state.</p>"},{"location":"api/tune/tune/","title":"tune","text":"<p>Tune submodule for configuring optimisation jobs.</p>"},{"location":"api/tune/tune/#plugboard.tune.Tuner","title":"Tuner","text":"<pre><code>Tuner(\n    *,\n    objective: ObjectiveSpec | list[ObjectiveSpec],\n    parameters: list[ParameterSpec],\n    num_samples: int,\n    mode: Direction | list[Direction] = \"max\",\n    max_concurrent: Optional[int] = None,\n    algorithm: Optional[OptunaSpec] = None,\n)\n</code></pre> <p>A class for running optimisation on Plugboard processes.</p> <p>Instantiates the <code>Tuner</code> class.</p> <p>Parameters:</p> Name Type Description Default <code>objective</code> <code>ObjectiveSpec | list[ObjectiveSpec]</code> <p>The objective(s) to optimise for in the <code>Process</code>.</p> required <code>parameters</code> <code>list[ParameterSpec]</code> <p>The parameters to optimise over.</p> required <code>num_samples</code> <code>int</code> <p>The number of trial samples to use for the optimisation.</p> required <code>mode</code> <code>Direction | list[Direction]</code> <p>The direction of the optimisation.</p> <code>'max'</code> <code>max_concurrent</code> <code>Optional[int]</code> <p>The maximum number of concurrent trials. Defaults to None, which means that Ray will use its default concurrency of 1 trial per CPU core.</p> <code>None</code> <code>algorithm</code> <code>Optional[OptunaSpec]</code> <p>Configuration for the underlying Optuna algorithm used for optimisation.</p> <code>None</code>"},{"location":"api/tune/tune/#plugboard.tune.Tuner.is_multi_objective","title":"is_multi_objective  <code>property</code>","text":"<pre><code>is_multi_objective: bool\n</code></pre> <p>Returns <code>True</code> if the optimisation is multi-objective.</p>"},{"location":"api/tune/tune/#plugboard.tune.Tuner.result_grid","title":"result_grid  <code>property</code>","text":"<pre><code>result_grid: ResultGrid\n</code></pre> <p>Returns a <code>ResultGrid</code> summarising the optimisation results.</p>"},{"location":"api/tune/tune/#plugboard.tune.Tuner.run","title":"run","text":"<pre><code>run(\n    spec: ProcessSpec,\n) -&gt; ray.tune.Result | list[ray.tune.Result]\n</code></pre> <p>Run the optimisation job on Ray.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>ProcessSpec</code> <p>The <code>ProcessSpec</code> to optimise.</p> required <p>Returns:</p> Type Description <code>Result | list[Result]</code> <p>Either one or a list of <code>Result</code> objects containing the best trial result. Use the <code>result_grid</code> property to get full trial results.</p>"},{"location":"api/utils/","title":"utils","text":"<p>Provides utility functions for use throughout the code.</p>"},{"location":"api/utils/#plugboard.utils.ClassRegistry","title":"ClassRegistry","text":"<p>               Bases: <code>ABC</code>, <code>Generic[T]</code></p> <p>A registry of Plugboard classes.</p>"},{"location":"api/utils/#plugboard.utils.ClassRegistry.add","title":"add  <code>classmethod</code>","text":"<pre><code>add(\n    plugboard_class: type[T], key: Optional[Hashable] = None\n) -&gt; None\n</code></pre> <p>Add a class to the registry.</p> <p>Parameters:</p> Name Type Description Default <code>plugboard_class</code> <code>type[T]</code> <p>The class to register.</p> required <code>key</code> <code>Optional[Hashable]</code> <p>Optional; The key to register the class under.</p> <code>None</code>"},{"location":"api/utils/#plugboard.utils.ClassRegistry.build","title":"build  <code>classmethod</code>","text":"<pre><code>build(\n    plugboard_class: Hashable, *args: Any, **kwargs: Any\n) -&gt; T\n</code></pre> <p>Builds a Plugboard object.</p> <p>Parameters:</p> Name Type Description Default <code>plugboard_class</code> <code>Hashable</code> <p>The key corresponding to the required class.</p> required <code>*args</code> <code>Any</code> <p>Positional arguments to pass to the class constructor.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments to pass to the class constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>T</code> <p>An object of the required class.</p>"},{"location":"api/utils/#plugboard.utils.ClassRegistry.get","title":"get  <code>classmethod</code>","text":"<pre><code>get(plugboard_class: Hashable) -&gt; type[T]\n</code></pre> <p>Returns a class from the registry.</p> <p>Parameters:</p> Name Type Description Default <code>plugboard_class</code> <code>Hashable</code> <p>The key corresponding to the required class.</p> required <p>Returns:</p> Type Description <code>type[T]</code> <p>The class.</p>"},{"location":"api/utils/#plugboard.utils.DI","title":"DI","text":"<p>               Bases: <code>BaseContainer</code></p> <p><code>DI</code> is a dependency injection container for plugboard.</p>"},{"location":"api/utils/#plugboard.utils.EntityIdGen","title":"EntityIdGen","text":"<p>EntityIdGen generates entity ids.</p>"},{"location":"api/utils/#plugboard.utils.EntityIdGen.id","title":"id  <code>classmethod</code>","text":"<pre><code>id(entity: Entity) -&gt; str\n</code></pre> <p>Returns a unique entity id.</p> <p>Parameters:</p> Name Type Description Default <code>entity</code> <code>Entity</code> <p>The entity to generate an id for.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The generated id.</p>"},{"location":"api/utils/#plugboard.utils.EntityIdGen.is_job_id","title":"is_job_id  <code>classmethod</code>","text":"<pre><code>is_job_id(id: str) -&gt; bool\n</code></pre> <p>Checks if an id is a job id.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The id to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the id is a job id.</p>"},{"location":"api/utils/#plugboard.utils.EntityIdGen.job_id","title":"job_id  <code>classmethod</code>","text":"<pre><code>job_id() -&gt; str\n</code></pre> <p>Returns a unique job id.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The generated job id.</p>"},{"location":"api/utils/#plugboard.utils.EntityIdGen.parse","title":"parse  <code>classmethod</code>","text":"<pre><code>parse(id: str) -&gt; tuple[Entity, str]\n</code></pre> <p>Parses an entity id.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The entity id to parse.</p> required <p>Returns:</p> Type Description <code>tuple[Entity, str]</code> <p>tuple[Entity, str]: The parsed entity and id.</p>"},{"location":"api/utils/#plugboard.utils.ExportMixin","title":"ExportMixin","text":"<p><code>AsDictMixin</code> provides functionality for converting objects to dict.</p>"},{"location":"api/utils/#plugboard.utils.ExportMixin._convert_exportable_objs","title":"_convert_exportable_objs  <code>staticmethod</code>","text":"<pre><code>_convert_exportable_objs(obj: Any) -&gt; _t.Any\n</code></pre> <p>Recursively converts <code>Exportable</code> objects to their <code>export</code> representation.</p>"},{"location":"api/utils/#plugboard.utils.ExportMixin.dict","title":"dict","text":"<pre><code>dict() -&gt; dict\n</code></pre> <p>Returns dict representation of object.</p>"},{"location":"api/utils/#plugboard.utils.ExportMixin.export","title":"export","text":"<pre><code>export() -&gt; dict\n</code></pre> <p>Returns dict representation of object for later reconstruction.</p>"},{"location":"api/utils/#plugboard.utils.ExportMixin.json","title":"json","text":"<pre><code>json() -&gt; bytes\n</code></pre> <p>Returns JSON representation of object as bytes.</p>"},{"location":"api/utils/#plugboard.utils.Exportable","title":"Exportable","text":"<p>               Bases: <code>Protocol</code></p> <p><code>Exportable</code> protocol for objects that can be exported.</p>"},{"location":"api/utils/#plugboard.utils.Exportable.export","title":"export","text":"<pre><code>export() -&gt; dict\n</code></pre> <p>Returns dict representation of object for later reconstruction.</p>"},{"location":"api/utils/#plugboard.utils.add_sys_path","title":"add_sys_path","text":"<pre><code>add_sys_path(path: str | PathLike) -&gt; Iterator\n</code></pre> <p>Temporarily add <code>path</code> to <code>sys.path</code>.</p>"},{"location":"api/utils/#plugboard.utils.build_actor_wrapper","title":"build_actor_wrapper","text":"<pre><code>build_actor_wrapper(cls: type[T]) -&gt; type[_ActorWrapper[T]]\n</code></pre> <p>Builds an actor wrapper around a class.</p> <p>This is useful for handling classes that are modified at runtime, e.g. via wrapped methods, and therefore not supported by the <code>ray.remote</code> decorator.</p> <p>The wrapper methods will have the same name as the original methods, but where nested in class attributes the method names will be prefixed accordingly. The wrapper also provides a <code>getattr</code> and <code>setattr</code> method to access the wrapped object's properties.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>type[T]</code> <p>The class to wrap.</p> required <p>Returns:</p> Type Description <code>type[_ActorWrapper[T]]</code> <p>A new class that wraps the original class and can be used as a Ray actor.</p>"},{"location":"api/utils/#plugboard.utils.depends_on_optional","title":"depends_on_optional","text":"<pre><code>depends_on_optional(\n    module_name: str, extra: Optional[str] = None\n) -&gt; _t.Callable\n</code></pre> <p>Decorator to check for optional dependencies.</p> <p>Parameters:</p> Name Type Description Default <code>module_name</code> <code>str</code> <p>The name of the module to check for.</p> required <code>extra</code> <code>Optional[str]</code> <p>Optional; The name of the extra that the module is associated with. Defaults to the module name.</p> <code>None</code>"},{"location":"api/utils/#plugboard.utils.gather_except","title":"gather_except  <code>async</code>","text":"<pre><code>gather_except(*coros: Coroutine) -&gt; list[_t.Any]\n</code></pre> <p>Attempts to gather the given coroutines, raising any exceptions.</p>"},{"location":"api/utils/#plugboard.utils.gen_rand_str","title":"gen_rand_str","text":"<pre><code>gen_rand_str(chars: int = RANDOM_CHAR_COUNT) -&gt; str\n</code></pre> <p>Generates a random string of a fixed length and character set.</p> <p>With 16 chars in [a-zA-Z0-9], at 1000 ids/second it would take ~1000 years or 30T ids for &gt;= 1% chance of at least one collision. See here for details: https://zelark.github.io/nano-id-cc/</p> <p>Note: This function is not suitable for cryptographic purposes; it is intended to generate random strings for unique identifiers only.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Random fixed length string.</p>"},{"location":"api/utils/#plugboard.utils.is_on_ray_worker","title":"is_on_ray_worker","text":"<pre><code>is_on_ray_worker() -&gt; bool\n</code></pre> <p>Returns <code>True</code> if called from a Ray worker.</p>"},{"location":"api/utils/#plugboard.utils.run_coro_sync","title":"run_coro_sync","text":"<pre><code>run_coro_sync(\n    coro: Coroutine, timeout: Optional[float] = None\n) -&gt; _t.Any\n</code></pre> <p>Runs a coroutine synchronously, returning the result.</p> <p>This is useful for async code run from synchronous CLI entrypoints. In the test environment, it will run the coroutine in the current event loop, if present, otherwise it will create a new event loop for the coroutine.</p>"},{"location":"api/utils/settings/settings/","title":"settings","text":"<p>Provides Plugboard's settings.</p>"},{"location":"api/utils/settings/settings/#plugboard.utils.settings.Settings","title":"Settings","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Settings for Plugboard.</p> <p>Attributes:</p> Name Type Description <code>flags</code> <code>_FeatureFlags</code> <p>Feature flags for Plugboard.</p> <code>log_level</code> <code>LogLevel</code> <p>The log level to use.</p> <code>log_structured</code> <code>bool</code> <p>Whether to render logs to JSON. Defaults to JSON if not running in a terminal session.</p> <code>io_read_timeout</code> <code>float</code> <p>Timeout for reading from IO streams in seconds between periodic status checks.</p>"},{"location":"api/utils/settings/settings/#plugboard.utils.settings._FeatureFlags","title":"_FeatureFlags","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Feature flags for Plugboard.</p> <p>Attributes:</p> Name Type Description <code>zmq_pubsub_proxy</code> <code>bool</code> <p>If set to true, runs a ZMQ proxy in a separate process for pubsub.</p> <code>multiprocessing_fork</code> <code>bool</code> <p>If set to true, uses fork mode for multiprocessing.</p>"},{"location":"examples/demos/finance/001_momentum_signal/momentum-signal/","title":"Momentum trading","text":"In\u00a0[\u00a0]: Copied! <pre># Install plugboard and dependencies for Google Colab\n!pip install -q plugboard yfinance plotly\n</pre> # Install plugboard and dependencies for Google Colab !pip install -q plugboard yfinance plotly <p>Here's a diagram to illustrate the whole process:</p> <p></p> In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport datetime as dt\nimport typing as _t\n\nfrom plugboard.connector import AsyncioConnector, ConnectorBuilder\nfrom plugboard.events import EventConnectorBuilder\nfrom plugboard.process import LocalProcess\nfrom plugboard.schemas import ConnectorSpec\n\nimport pandas as pd\nimport plotly.graph_objects as go\n\nimport yfinance as yf\nfrom pydantic import BaseModel\nfrom plugboard.events import Event\n\nfrom plugboard.component import Component, IOController as IO\nfrom plugboard.schemas import ComponentArgsDict\n\n# Helper to create field connectors\nconnect = lambda src, tgt: AsyncioConnector(spec=ConnectorSpec(source=src, target=tgt))\n</pre> import pandas as pd import datetime as dt import typing as _t  from plugboard.connector import AsyncioConnector, ConnectorBuilder from plugboard.events import EventConnectorBuilder from plugboard.process import LocalProcess from plugboard.schemas import ConnectorSpec  import pandas as pd import plotly.graph_objects as go  import yfinance as yf from pydantic import BaseModel from plugboard.events import Event  from plugboard.component import Component, IOController as IO from plugboard.schemas import ComponentArgsDict  # Helper to create field connectors connect = lambda src, tgt: AsyncioConnector(spec=ConnectorSpec(source=src, target=tgt)) In\u00a0[\u00a0]: Copied! <pre>def _ensure_dt(val: _t.Any) -&gt; dt.datetime:\n    if isinstance(val, dt.datetime):\n        return val\n    if isinstance(val, dt.date):\n        return dt.datetime.combine(val, dt.time())\n    return pd.to_datetime(val).to_pydatetime()\n\n\nclass YahooPriceLoader(Component):\n    \"\"\"Loads historical prices for a symbol from Yahoo Finance and streams them row by row.\n\n    Outputs per step:\n        price: float - adjusted close price (or close if adj not present)\n        timestamp: datetime\n    \"\"\"\n\n    io = IO(outputs=[\"price\", \"timestamp\"])  # stream out prices\n\n    def __init__(\n        self,\n        symbol: str = \"^GSPC\",\n        period: str | None = None,\n        start: str | dt.date | None = None,\n        end: str | dt.date | None = None,\n        interval: str = \"1d\",\n        limit: int | None = None,\n        **kwargs: _t.Unpack[ComponentArgsDict],\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self.symbol = symbol\n        self.period = period\n        self.start = start\n        self.end = end\n        self.interval = interval\n        self.limit = limit\n        self._data: pd.DataFrame | None = None\n        self._iter = 0\n\n    async def _ensure_data(self) -&gt; None:\n        if self._data is not None:\n            return\n        if yf is None:  # pragma: no cover - runtime safeguard\n            raise RuntimeError(\"yfinance not installed. Please 'pip install yfinance'.\")\n        df = yf.download(\n            self.symbol,\n            period=self.period,\n            start=self.start,\n            end=self.end,\n            interval=self.interval,\n            progress=False,\n        )\n        if df.empty:\n            raise RuntimeError(f\"No data returned for symbol {self.symbol}\")\n        # Prefer Adj Close if exists\n        if \"Adj Close\" in df.columns:\n            df.rename(columns={\"Adj Close\": \"AdjClose\"}, inplace=True)\n            price_col = \"AdjClose\"\n        elif \"Close\" in df.columns:\n            price_col = \"Close\"\n        else:\n            price_col = df.columns[0]\n        df = df[[price_col]].rename(columns={price_col: \"price\"})\n        df.index.name = \"timestamp\"\n        df.reset_index(inplace=True)\n        if self.limit is not None:\n            df = df.head(self.limit)\n        # Remove column multi-index if present\n        self._data = df.droplevel(1, axis=\"columns\")\n\n    @property\n    def df(self) -&gt; pd.DataFrame:\n        \"\"\"The full DataFrame of loaded price data.\"\"\"\n        if self._data is None:\n            raise RuntimeError(\"Data not yet loaded. Call step() first.\")\n        return self._data\n\n    async def step(self) -&gt; None:  # noqa: D401\n        await self._ensure_data()\n        if self._iter &gt;= len(self._data):\n            await self.io.close()\n            return\n        row = self._data.iloc[self._iter]\n        self.price = float(row[\"price\"])\n        ts = row[\"timestamp\"]\n        self.timestamp = _ensure_dt(ts)\n        self._iter += 1\n</pre> def _ensure_dt(val: _t.Any) -&gt; dt.datetime:     if isinstance(val, dt.datetime):         return val     if isinstance(val, dt.date):         return dt.datetime.combine(val, dt.time())     return pd.to_datetime(val).to_pydatetime()   class YahooPriceLoader(Component):     \"\"\"Loads historical prices for a symbol from Yahoo Finance and streams them row by row.      Outputs per step:         price: float - adjusted close price (or close if adj not present)         timestamp: datetime     \"\"\"      io = IO(outputs=[\"price\", \"timestamp\"])  # stream out prices      def __init__(         self,         symbol: str = \"^GSPC\",         period: str | None = None,         start: str | dt.date | None = None,         end: str | dt.date | None = None,         interval: str = \"1d\",         limit: int | None = None,         **kwargs: _t.Unpack[ComponentArgsDict],     ) -&gt; None:         super().__init__(**kwargs)         self.symbol = symbol         self.period = period         self.start = start         self.end = end         self.interval = interval         self.limit = limit         self._data: pd.DataFrame | None = None         self._iter = 0      async def _ensure_data(self) -&gt; None:         if self._data is not None:             return         if yf is None:  # pragma: no cover - runtime safeguard             raise RuntimeError(\"yfinance not installed. Please 'pip install yfinance'.\")         df = yf.download(             self.symbol,             period=self.period,             start=self.start,             end=self.end,             interval=self.interval,             progress=False,         )         if df.empty:             raise RuntimeError(f\"No data returned for symbol {self.symbol}\")         # Prefer Adj Close if exists         if \"Adj Close\" in df.columns:             df.rename(columns={\"Adj Close\": \"AdjClose\"}, inplace=True)             price_col = \"AdjClose\"         elif \"Close\" in df.columns:             price_col = \"Close\"         else:             price_col = df.columns[0]         df = df[[price_col]].rename(columns={price_col: \"price\"})         df.index.name = \"timestamp\"         df.reset_index(inplace=True)         if self.limit is not None:             df = df.head(self.limit)         # Remove column multi-index if present         self._data = df.droplevel(1, axis=\"columns\")      @property     def df(self) -&gt; pd.DataFrame:         \"\"\"The full DataFrame of loaded price data.\"\"\"         if self._data is None:             raise RuntimeError(\"Data not yet loaded. Call step() first.\")         return self._data      async def step(self) -&gt; None:  # noqa: D401         await self._ensure_data()         if self._iter &gt;= len(self._data):             await self.io.close()             return         row = self._data.iloc[self._iter]         self.price = float(row[\"price\"])         ts = row[\"timestamp\"]         self.timestamp = _ensure_dt(ts)         self._iter += 1 In\u00a0[\u00a0]: Copied! <pre>class EMA(Component):\n    \"\"\"Computes an exponential moving average of an input price stream.\n\n    Inputs:\n        price: float\n    Outputs:\n        ema: float\n    \"\"\"\n\n    io = IO(inputs=[\"price\"], outputs=[\"ema\"])\n\n    def __init__(\n        self,\n        alpha: float | None = None,\n        span: int | None = None,\n        **kwargs: _t.Unpack[ComponentArgsDict],\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        if alpha is None and span is None:\n            raise ValueError(\"Provide either alpha or span\")\n        if alpha is not None and not (0 &lt; alpha &lt;= 1):\n            raise ValueError(\"alpha must be (0,1]\")\n        self.alpha = alpha if alpha is not None else 2 / (span + 1)\n        self._ema: float | None = None\n\n    async def step(self) -&gt; None:\n        price = float(self.price)\n        if self._ema is None:\n            self._ema = price\n        else:\n            self._ema = self.alpha * price + (1 - self.alpha) * self._ema\n        self.ema = self._ema\n</pre> class EMA(Component):     \"\"\"Computes an exponential moving average of an input price stream.      Inputs:         price: float     Outputs:         ema: float     \"\"\"      io = IO(inputs=[\"price\"], outputs=[\"ema\"])      def __init__(         self,         alpha: float | None = None,         span: int | None = None,         **kwargs: _t.Unpack[ComponentArgsDict],     ) -&gt; None:         super().__init__(**kwargs)         if alpha is None and span is None:             raise ValueError(\"Provide either alpha or span\")         if alpha is not None and not (0 &lt; alpha &lt;= 1):             raise ValueError(\"alpha must be (0,1]\")         self.alpha = alpha if alpha is not None else 2 / (span + 1)         self._ema: float | None = None      async def step(self) -&gt; None:         price = float(self.price)         if self._ema is None:             self._ema = price         else:             self._ema = self.alpha * price + (1 - self.alpha) * self._ema         self.ema = self._ema In\u00a0[\u00a0]: Copied! <pre>class CrossoverSignal(Component):\n    \"\"\"Generates buy/sell/hold signal from two moving averages.\n\n    Inputs:\n        fast: float\n        slow: float\n    Outputs:\n        signal: int (1=buy, -1=sell)\n    \"\"\"\n\n    io = IO(inputs=[\"fast\", \"slow\"], outputs=[\"signal\"])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n\n    async def step(self) -&gt; None:\n        fast = float(self.fast)\n        slow = float(self.slow)\n        self.signal = 1 if fast &gt;= slow else -1\n</pre> class CrossoverSignal(Component):     \"\"\"Generates buy/sell/hold signal from two moving averages.      Inputs:         fast: float         slow: float     Outputs:         signal: int (1=buy, -1=sell)     \"\"\"      io = IO(inputs=[\"fast\", \"slow\"], outputs=[\"signal\"])      def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)      async def step(self) -&gt; None:         fast = float(self.fast)         slow = float(self.slow)         self.signal = 1 if fast &gt;= slow else -1 In\u00a0[\u00a0]: Copied! <pre>class TradeData(BaseModel):\n    \"\"\"Data for a trade decision.\n\n    side: \"buy\" or \"sell\"\n    size: number of units\n    price: execution price\n    timestamp: event time\n    strength: \"strong\" | \"weak\"\n    count_buy: number of buy signals\n    count_sell: number of sell signals\n    \"\"\"\n\n    side: _t.Literal[\"buy\", \"sell\"]\n    size: int\n    price: float\n    timestamp: dt.datetime\n    strength: _t.Literal[\"strong\", \"weak\"]\n    count_buy: int\n    count_sell: int\n\n\nclass TradeEvent(Event):\n    \"\"\"Event emitted when strategy decides to trade.\"\"\"\n\n    type: _t.ClassVar[str] = \"trade_event\"\n    data: TradeData\n\n\nclass TradeSignalAggregator(Component):\n    \"\"\"Aggregates three crossover signals into trade events.\n\n    Inputs:\n        s1, s2, s3 (int signals: 1 buy, -1 sell, 0 hold)\n        price (float)\n        timestamp (datetime)\n    Output events:\n        TradeEvent\n    Logic:\n        strong buy  = 3 buys -&gt; size 2\n        weak buy    = 2 buys 1 sell -&gt; size 1\n        strong sell = 3 sells -&gt; size 2\n        weak sell   = 2 sells 1 buy -&gt; size 1\n    \"\"\"\n\n    io = IO(\n        inputs=[\"s1\", \"s2\", \"s3\", \"price\", \"timestamp\"],\n        output_events=[TradeEvent],\n    )\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._previous_signal: int | None = None\n\n    async def step(self) -&gt; None:\n        signals = [int(self.s1), int(self.s2), int(self.s3)]\n        count_buy = sum(1 for s in signals if s == 1)\n        count_sell = sum(1 for s in signals if s == -1)\n        net_signal = count_buy - count_sell\n        if net_signal &gt;= 2:\n            decision, strength, size = \"buy\", \"strong\", 2\n        elif net_signal == 1:\n            decision, strength, size = \"buy\", \"weak\", 1\n        elif net_signal &lt;= -2:\n            decision, strength, size = \"sell\", \"strong\", 2\n        elif net_signal == -1:\n            decision, strength, size = \"sell\", \"weak\", 1\n\n        if net_signal != self._previous_signal:\n            self._logger.info(\n                f\"Emitting trade decision\", decision=decision, size=size, strength=strength\n            )\n            trade = TradeEvent(\n                source=self.name,\n                data=TradeData(\n                    side=decision,\n                    size=size,\n                    price=float(self.price),\n                    timestamp=_ensure_dt(self.timestamp),\n                    strength=strength,\n                    count_buy=count_buy,\n                    count_sell=count_sell,\n                ),\n            )\n            self.io.queue_event(trade)\n            self._previous_signal = net_signal\n</pre> class TradeData(BaseModel):     \"\"\"Data for a trade decision.      side: \"buy\" or \"sell\"     size: number of units     price: execution price     timestamp: event time     strength: \"strong\" | \"weak\"     count_buy: number of buy signals     count_sell: number of sell signals     \"\"\"      side: _t.Literal[\"buy\", \"sell\"]     size: int     price: float     timestamp: dt.datetime     strength: _t.Literal[\"strong\", \"weak\"]     count_buy: int     count_sell: int   class TradeEvent(Event):     \"\"\"Event emitted when strategy decides to trade.\"\"\"      type: _t.ClassVar[str] = \"trade_event\"     data: TradeData   class TradeSignalAggregator(Component):     \"\"\"Aggregates three crossover signals into trade events.      Inputs:         s1, s2, s3 (int signals: 1 buy, -1 sell, 0 hold)         price (float)         timestamp (datetime)     Output events:         TradeEvent     Logic:         strong buy  = 3 buys -&gt; size 2         weak buy    = 2 buys 1 sell -&gt; size 1         strong sell = 3 sells -&gt; size 2         weak sell   = 2 sells 1 buy -&gt; size 1     \"\"\"      io = IO(         inputs=[\"s1\", \"s2\", \"s3\", \"price\", \"timestamp\"],         output_events=[TradeEvent],     )      def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._previous_signal: int | None = None      async def step(self) -&gt; None:         signals = [int(self.s1), int(self.s2), int(self.s3)]         count_buy = sum(1 for s in signals if s == 1)         count_sell = sum(1 for s in signals if s == -1)         net_signal = count_buy - count_sell         if net_signal &gt;= 2:             decision, strength, size = \"buy\", \"strong\", 2         elif net_signal == 1:             decision, strength, size = \"buy\", \"weak\", 1         elif net_signal &lt;= -2:             decision, strength, size = \"sell\", \"strong\", 2         elif net_signal == -1:             decision, strength, size = \"sell\", \"weak\", 1          if net_signal != self._previous_signal:             self._logger.info(                 f\"Emitting trade decision\", decision=decision, size=size, strength=strength             )             trade = TradeEvent(                 source=self.name,                 data=TradeData(                     side=decision,                     size=size,                     price=float(self.price),                     timestamp=_ensure_dt(self.timestamp),                     strength=strength,                     count_buy=count_buy,                     count_sell=count_sell,                 ),             )             self.io.queue_event(trade)             self._previous_signal = net_signal In\u00a0[\u00a0]: Copied! <pre>class TradeEventFileWriter(Component):\n    \"\"\"Consumes trade events and writes them to a CSV file (append mode).\"\"\"\n\n    io = IO(input_events=[TradeEvent])\n\n    def __init__(self, path: str = \"trades.csv\", **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self.path = path\n        # Write header\n        with open(self.path, \"w\", encoding=\"utf-8\") as f:\n            f.write(\"timestamp,side,size,price,strength,count_buy,count_sell,source\\n\")\n\n    @TradeEvent.handler\n    async def handle_trade(self, event: TradeEvent) -&gt; None:  # noqa: D401\n        d = event.data\n        with open(self.path, \"a\", encoding=\"utf-8\") as f:\n            f.write(\n                f\"{d.timestamp.isoformat()},{d.side},{d.size},{d.price:.4f},{d.strength},{d.count_buy},{d.count_sell},{event.source}\\n\"\n            )\n</pre> class TradeEventFileWriter(Component):     \"\"\"Consumes trade events and writes them to a CSV file (append mode).\"\"\"      io = IO(input_events=[TradeEvent])      def __init__(self, path: str = \"trades.csv\", **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self.path = path         # Write header         with open(self.path, \"w\", encoding=\"utf-8\") as f:             f.write(\"timestamp,side,size,price,strength,count_buy,count_sell,source\\n\")      @TradeEvent.handler     async def handle_trade(self, event: TradeEvent) -&gt; None:  # noqa: D401         d = event.data         with open(self.path, \"a\", encoding=\"utf-8\") as f:             f.write(                 f\"{d.timestamp.isoformat()},{d.side},{d.size},{d.price:.4f},{d.strength},{d.count_buy},{d.count_sell},{event.source}\\n\"             ) In\u00a0[\u00a0]: Copied! <pre># Build components\nprice_loader = YahooPriceLoader(name=\"loader\", period=\"10y\", interval=\"1d\")\n\n# Three EMAs with different speeds (adjust spans as desired)\nema_fast_1 = EMA(name=\"ema-fast-1\", span=8)\nema_fast_2 = EMA(name=\"ema-fast-2\", span=15)\nema_medium_1 = EMA(name=\"ema-medium-1\", span=30)\nema_medium_2 = EMA(name=\"ema-medium-2\", span=50)\nema_slow_1 = EMA(name=\"ema-slow-1\", span=80)\nema_slow_2 = EMA(name=\"ema-slow-2\", span=150)\n\n# Signals from different pairings\nsig_fast = CrossoverSignal(name=\"sig-fast\")\nsig_medium = CrossoverSignal(name=\"sig-medium\")\nsig_slow = CrossoverSignal(name=\"sig-slow\")\n\n# Aggregator producing trade events\naggregator = TradeSignalAggregator(name=\"trade-aggregator\")\ntrade_writer = TradeEventFileWriter(name=\"trade-writer\", path=\"trades.csv\")\n\ncomponents = [\n    price_loader,\n    ema_fast_1,\n    ema_fast_2,\n    ema_medium_1,\n    ema_medium_2,\n    ema_slow_1,\n    ema_slow_2,\n    sig_fast,\n    sig_medium,\n    sig_slow,\n    aggregator,\n    trade_writer,\n]\n\n# Field connectors\nconnectors = [\n    # Price to EMAs\n    connect(\"loader.price\", \"ema-fast-1.price\"),\n    connect(\"loader.price\", \"ema-fast-2.price\"),\n    connect(\"loader.price\", \"ema-medium-1.price\"),\n    connect(\"loader.price\", \"ema-medium-2.price\"),\n    connect(\"loader.price\", \"ema-slow-1.price\"),\n    connect(\"loader.price\", \"ema-slow-2.price\"),\n    # Convert the three pairs of EMAs into signals\n    connect(\"ema-fast-1.ema\", \"sig-fast.fast\"),\n    connect(\"ema-fast-2.ema\", \"sig-fast.slow\"),\n    connect(\"ema-medium-1.ema\", \"sig-medium.fast\"),\n    connect(\"ema-medium-2.ema\", \"sig-medium.slow\"),\n    connect(\"ema-slow-1.ema\", \"sig-slow.fast\"),\n    connect(\"ema-slow-2.ema\", \"sig-slow.slow\"),\n    # Signals + price + timestamp into aggregator\n    connect(\"sig-fast.signal\", \"trade-aggregator.s1\"),\n    connect(\"sig-medium.signal\", \"trade-aggregator.s2\"),\n    connect(\"sig-slow.signal\", \"trade-aggregator.s3\"),\n    connect(\"loader.price\", \"trade-aggregator.price\"),\n    connect(\"loader.timestamp\", \"trade-aggregator.timestamp\"),\n]\n\n# Event connectors\nbuilder = ConnectorBuilder(connector_cls=AsyncioConnector)\nevent_builder = EventConnectorBuilder(connector_builder=builder)\nevent_connectors = list(event_builder.build(components).values())\n\nprocess = LocalProcess(components=components, connectors=connectors + event_connectors)\n</pre> # Build components price_loader = YahooPriceLoader(name=\"loader\", period=\"10y\", interval=\"1d\")  # Three EMAs with different speeds (adjust spans as desired) ema_fast_1 = EMA(name=\"ema-fast-1\", span=8) ema_fast_2 = EMA(name=\"ema-fast-2\", span=15) ema_medium_1 = EMA(name=\"ema-medium-1\", span=30) ema_medium_2 = EMA(name=\"ema-medium-2\", span=50) ema_slow_1 = EMA(name=\"ema-slow-1\", span=80) ema_slow_2 = EMA(name=\"ema-slow-2\", span=150)  # Signals from different pairings sig_fast = CrossoverSignal(name=\"sig-fast\") sig_medium = CrossoverSignal(name=\"sig-medium\") sig_slow = CrossoverSignal(name=\"sig-slow\")  # Aggregator producing trade events aggregator = TradeSignalAggregator(name=\"trade-aggregator\") trade_writer = TradeEventFileWriter(name=\"trade-writer\", path=\"trades.csv\")  components = [     price_loader,     ema_fast_1,     ema_fast_2,     ema_medium_1,     ema_medium_2,     ema_slow_1,     ema_slow_2,     sig_fast,     sig_medium,     sig_slow,     aggregator,     trade_writer, ]  # Field connectors connectors = [     # Price to EMAs     connect(\"loader.price\", \"ema-fast-1.price\"),     connect(\"loader.price\", \"ema-fast-2.price\"),     connect(\"loader.price\", \"ema-medium-1.price\"),     connect(\"loader.price\", \"ema-medium-2.price\"),     connect(\"loader.price\", \"ema-slow-1.price\"),     connect(\"loader.price\", \"ema-slow-2.price\"),     # Convert the three pairs of EMAs into signals     connect(\"ema-fast-1.ema\", \"sig-fast.fast\"),     connect(\"ema-fast-2.ema\", \"sig-fast.slow\"),     connect(\"ema-medium-1.ema\", \"sig-medium.fast\"),     connect(\"ema-medium-2.ema\", \"sig-medium.slow\"),     connect(\"ema-slow-1.ema\", \"sig-slow.fast\"),     connect(\"ema-slow-2.ema\", \"sig-slow.slow\"),     # Signals + price + timestamp into aggregator     connect(\"sig-fast.signal\", \"trade-aggregator.s1\"),     connect(\"sig-medium.signal\", \"trade-aggregator.s2\"),     connect(\"sig-slow.signal\", \"trade-aggregator.s3\"),     connect(\"loader.price\", \"trade-aggregator.price\"),     connect(\"loader.timestamp\", \"trade-aggregator.timestamp\"), ]  # Event connectors builder = ConnectorBuilder(connector_cls=AsyncioConnector) event_builder = EventConnectorBuilder(connector_builder=builder) event_connectors = list(event_builder.build(components).values())  process = LocalProcess(components=components, connectors=connectors + event_connectors) In\u00a0[\u00a0]: Copied! <pre>async with process:\n    await process.run()\n</pre> async with process:     await process.run() In\u00a0[\u00a0]: Copied! <pre>df_prices = price_loader.df\ndf_trades = pd.read_csv(\"trades.csv\", parse_dates=[\"timestamp\"])\n\ntraces = [\n    go.Scatter(x=df_prices[\"timestamp\"], y=df_prices[\"price\"], mode=\"lines\", name=\"Price\"),\n    go.Scatter(\n        x=df_trades[df_trades[\"side\"] == \"buy\"][\"timestamp\"],\n        y=df_trades[df_trades[\"side\"] == \"buy\"][\"price\"],\n        mode=\"markers\",\n        name=\"Buy\",\n        marker=dict(\n            color=\"green\",\n            symbol=\"triangle-up\",\n            size=df_trades[df_trades[\"side\"] == \"buy\"][\"strength\"].map(\n                lambda x: 18 if x == \"strong\" else 12\n            ),\n        ),\n    ),\n    go.Scatter(\n        x=df_trades[df_trades[\"side\"] == \"sell\"][\"timestamp\"],\n        y=df_trades[df_trades[\"side\"] == \"sell\"][\"price\"],\n        mode=\"markers\",\n        name=\"Sell\",\n        marker=dict(\n            color=\"red\",\n            symbol=\"triangle-down\",\n            size=df_trades[df_trades[\"side\"] == \"sell\"][\"strength\"].map(\n                lambda x: 18 if x == \"strong\" else 12\n            ),\n        ),\n    ),\n]\nfig = go.Figure(data=traces)\nfig\n</pre> df_prices = price_loader.df df_trades = pd.read_csv(\"trades.csv\", parse_dates=[\"timestamp\"])  traces = [     go.Scatter(x=df_prices[\"timestamp\"], y=df_prices[\"price\"], mode=\"lines\", name=\"Price\"),     go.Scatter(         x=df_trades[df_trades[\"side\"] == \"buy\"][\"timestamp\"],         y=df_trades[df_trades[\"side\"] == \"buy\"][\"price\"],         mode=\"markers\",         name=\"Buy\",         marker=dict(             color=\"green\",             symbol=\"triangle-up\",             size=df_trades[df_trades[\"side\"] == \"buy\"][\"strength\"].map(                 lambda x: 18 if x == \"strong\" else 12             ),         ),     ),     go.Scatter(         x=df_trades[df_trades[\"side\"] == \"sell\"][\"timestamp\"],         y=df_trades[df_trades[\"side\"] == \"sell\"][\"price\"],         mode=\"markers\",         name=\"Sell\",         marker=dict(             color=\"red\",             symbol=\"triangle-down\",             size=df_trades[df_trades[\"side\"] == \"sell\"][\"strength\"].map(                 lambda x: 18 if x == \"strong\" else 12             ),         ),     ), ] fig = go.Figure(data=traces) fig In\u00a0[\u00a0]: Copied! <pre># Visualise the process\nfrom plugboard.diagram import MermaidDiagram\n\ndiagram_md = MermaidDiagram.from_process(process)\ndiagram_md.url\n</pre> # Visualise the process from plugboard.diagram import MermaidDiagram  diagram_md = MermaidDiagram.from_process(process) diagram_md.url","tags":["finance","events"]},{"location":"examples/demos/finance/001_momentum_signal/momentum-signal/#momentum-trading","title":"Momentum trading\u00b6","text":"<p>This notebook implements a simple momentum strategy on the S&amp;P 500 using Plugboard\u2019s event-driven components:</p> <ul> <li>Data source: streams S&amp;P 500 prices from Yahoo! Finance;</li> <li>Indicators: three pairs of exponential moving averages (fast/medium/slow);</li> <li>Signals: compare EMAs to create buy/sell signals;</li> <li>Events: combine three signals into a TradeEvent (weak/strong buy/sell);</li> <li>Sink: write trades to a CSV file for inspection.</li> </ul> <p>You can run the process, then visualize trades on a price chart.</p>","tags":["finance","events"]},{"location":"examples/demos/finance/001_momentum_signal/momentum-signal/#imports-and-helpers","title":"Imports and helpers\u00b6","text":"<p>We import Plugboard\u2019s core building blocks and define a small helper to create connectors:</p> <ul> <li>Components expose named inputs/outputs and can emit/receive events.</li> <li>Connectors move values between component fields.</li> <li>Event connectors route declared events between publishers and subscribers automatically.</li> </ul>","tags":["finance","events"]},{"location":"examples/demos/finance/001_momentum_signal/momentum-signal/#components-data-and-indicators","title":"Components: data and indicators\u00b6","text":"<ul> <li>YahooPriceLoader streams price and timestamp row-by-row from Yahoo Finance for ^GSPC.</li> <li>EMA consumes <code>price</code> and emits an exponentially weighted moving average as <code>ema</code>.</li> </ul> <p>Components declare their I/O via <code>IOController</code>, giving Plugboard enough metadata to wire processes.</p>","tags":["finance","events"]},{"location":"examples/demos/finance/001_momentum_signal/momentum-signal/#components-signals-and-events","title":"Components: signals and events\u00b6","text":"<ul> <li>CrossoverSignal reads two EMAs (<code>fast</code>, <code>slow</code>) and emits a directional <code>signal</code>.</li> <li>TradeSignalAggregator takes three signals plus the current <code>price</code> and <code>timestamp</code>, and emits a <code>TradeEvent</code> with direction/size/strength.</li> <li>TradeEventFileWriter subscribes to <code>TradeEvent</code> and appends a CSV row per event.</li> </ul>","tags":["finance","events"]},{"location":"examples/demos/finance/001_momentum_signal/momentum-signal/#wire-the-process","title":"Wire the process\u00b6","text":"<p>Here we:</p> <ul> <li>Instantiate the source, indicator, signal, aggregator, and writer components.</li> <li>Connect fields with <code>AsyncioConnector</code> (price\u2192EMAs, EMAs\u2192signals, signals\u2192aggregator).</li> <li>Build event connectors so <code>TradeEvent</code> flows from the aggregator to the file writer.</li> <li>Create a <code>LocalProcess</code> to run everything in-process.</li> </ul>","tags":["finance","events"]},{"location":"examples/demos/finance/001_momentum_signal/momentum-signal/#run-the-process","title":"Run the process\u00b6","text":"<p>Running the process iterates over the price history, updates indicators, produces signals, emits trade events, and writes them to <code>trades.csv</code>.</p>","tags":["finance","events"]},{"location":"examples/demos/finance/001_momentum_signal/momentum-signal/#visualize-trades-from-csv","title":"Visualize trades from CSV\u00b6","text":"<p>After the run, <code>trades.csv</code> contains one row per <code>TradeEvent</code>. We overlay buy/sell markers on the price series to see where the strategy acted.</p>","tags":["finance","events"]},{"location":"examples/demos/finance/001_momentum_signal/momentum-signal/#visualize-the-process-diagram","title":"Visualize the process diagram\u00b6","text":"<p>We can render a Mermaid diagram of the Plugboard process, showing components, fields, and event flows. This helps debug and document the model wiring.</p>","tags":["finance","events"]},{"location":"examples/demos/finance/001_momentum_signal/momentum-signal/#next-steps","title":"Next steps\u00b6","text":"<p>Potential enhancements to this example could include:</p> <ul> <li>Adding a component to track PnL from the trades;</li> <li>Using <code>plugboard.tune</code> to choose the moving averages to optimise PnL.</li> </ul>","tags":["finance","events"]},{"location":"examples/demos/fundamentals/001_simple_model/simple-model/","title":"Simple 3-node model","text":"In\u00a0[\u00a0]: Copied! <pre># Install plugboard and dependencies for Google Colab\n!pip install -q plugboard\n</pre> # Install plugboard and dependencies for Google Colab !pip install -q plugboard In\u00a0[\u00a0]: Copied! <pre>import typing as _t\n\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.component import Component\nfrom plugboard.component import IOController as IO\nfrom plugboard.schemas import ComponentArgsDict, ConnectorSpec\nfrom plugboard.process import LocalProcess\nfrom plugboard.library import FileReader, FileWriter\n</pre> import typing as _t  from plugboard.connector import AsyncioConnector from plugboard.component import Component from plugboard.component import IOController as IO from plugboard.schemas import ComponentArgsDict, ConnectorSpec from plugboard.process import LocalProcess from plugboard.library import FileReader, FileWriter <p>The <code>FileReader</code> component is provided by Plugboard. It takes the content of a CSV and emits the values row-by-row. Our CSV contains a single <code>value</code> column, so we configure the <code>field_names</code> argument to expect that.</p> In\u00a0[\u00a0]: Copied! <pre>input_data = FileReader(name=\"input_data\", path=\"input.csv\", field_names=[\"value\"])\n</pre> input_data = FileReader(name=\"input_data\", path=\"input.csv\", field_names=[\"value\"]) <p>Next, we implement a component to compute a running total using its internal state.</p> In\u00a0[\u00a0]: Copied! <pre>class RunningTotal(Component):\n    # Define the inputs and outputs of the component\n    io = IO(inputs=[\"value\"], outputs=[\"total_value\"])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        # Set the initial running total to 0\n        self._running_total = 0\n\n    async def step(self) -&gt; None:\n        # The main logic of the component\n        self._running_total += self.value\n        self.total_value = self._running_total\n</pre> class RunningTotal(Component):     # Define the inputs and outputs of the component     io = IO(inputs=[\"value\"], outputs=[\"total_value\"])      def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         # Set the initial running total to 0         self._running_total = 0      async def step(self) -&gt; None:         # The main logic of the component         self._running_total += self.value         self.total_value = self._running_total In\u00a0[\u00a0]: Copied! <pre>total = RunningTotal(name=\"total\")\n</pre> total = RunningTotal(name=\"total\") <p>At this point, it is possible to test the component in the notebook by initialising it, setting its input value, then calling <code>step()</code>.</p> In\u00a0[\u00a0]: Copied! <pre>await total.init()\ntotal.value = 10  # Set the value input to 10\nawait total.step()  # Run the component\nprint(total.total_value)  # Print the total value output\ntotal.value = 20  # Set the value input to 20\nawait total.step()  # Run the component\nprint(total.total_value)  # Print the total value output\n</pre> await total.init() total.value = 10  # Set the value input to 10 await total.step()  # Run the component print(total.total_value)  # Print the total value output total.value = 20  # Set the value input to 20 await total.step()  # Run the component print(total.total_value)  # Print the total value output <p>Now re-instantiate <code>total</code> to reset its state.</p> In\u00a0[\u00a0]: Copied! <pre>total = RunningTotal(name=\"total\")\n</pre> total = RunningTotal(name=\"total\") <p>For the output we can use the built-in <code>FileWriter</code> component, configured to expect an input called <code>value_to_save</code>.</p> In\u00a0[\u00a0]: Copied! <pre>output_data = FileWriter(name=\"output_data\", path=\"output.csv\", field_names=[\"value_to_save\"])\n</pre> output_data = FileWriter(name=\"output_data\", path=\"output.csv\", field_names=[\"value_to_save\"]) <p>Now connect the components together in a <code>LocalProcess</code>.</p> In\u00a0[\u00a0]: Copied! <pre>process = LocalProcess(\n    components=[input_data, total, output_data],\n    connectors=[\n        # Connect input_data to total\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"input_data.value\", target=\"total.value\"),\n        ),\n        # Connect total to output_data\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"total.total_value\", target=\"output_data.value_to_save\"),\n        ),\n    ],\n)\n</pre> process = LocalProcess(     components=[input_data, total, output_data],     connectors=[         # Connect input_data to total         AsyncioConnector(             spec=ConnectorSpec(source=\"input_data.value\", target=\"total.value\"),         ),         # Connect total to output_data         AsyncioConnector(             spec=ConnectorSpec(source=\"total.total_value\", target=\"output_data.value_to_save\"),         ),     ], ) <p>Now we can initialise and run the simulation.</p> In\u00a0[\u00a0]: Copied! <pre>async with process:\n    await process.run()\n</pre> async with process:     await process.run() <p>Finally check we have the output data saved in <code>output.csv</code>.</p> In\u00a0[\u00a0]: Copied! <pre>!cat output.csv\n</pre> !cat output.csv"},{"location":"examples/demos/fundamentals/001_simple_model/simple-model/#simple-3-node-model","title":"Simple 3-node model\u00b6","text":"<p>This model demonstrates how to create different types of component and link them together. We use a built-in plugboard component to load timeseries data from a CSV file. A second node computes a rolling sum of these values. Finally another built-in component saves the output to a different CSV.</p>"},{"location":"examples/demos/fundamentals/002_production_line_optimisation/production-line/","title":"Production process optimisation","text":"In\u00a0[\u00a0]: Copied! <pre># Install plugboard and dependencies for Google Colab\n!pip install -q plugboard[ray]\n</pre> # Install plugboard and dependencies for Google Colab !pip install -q plugboard[ray] In\u00a0[\u00a0]: Copied! <pre>import typing as _t\n\nfrom plugboard.component import Component, IOController as IO\nfrom plugboard.schemas import ComponentArgsDict\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.process import LocalProcess\nfrom plugboard.schemas import ConnectorSpec\n</pre> import typing as _t  from plugboard.component import Component, IOController as IO from plugboard.schemas import ComponentArgsDict from plugboard.connector import AsyncioConnector from plugboard.process import LocalProcess from plugboard.schemas import ConnectorSpec <p>Define the components for the model.</p> In\u00a0[\u00a0]: Copied! <pre>class Input(Component):\n    \"\"\"Provides a fixed number of input items per step.\"\"\"\n\n    io = IO(outputs=[\"items\"])\n\n    def __init__(\n        self,\n        items_per_step: int = 10,\n        total_steps: int = 1000,\n        **kwargs: _t.Unpack[ComponentArgsDict],\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self._items_per_step = items_per_step\n        self._total_steps = total_steps\n\n    async def step(self) -&gt; None:\n        self.items = self._items_per_step\n        if self._total_steps &gt; 0:\n            self._total_steps -= 1\n        else:\n            self.items = 0\n            await self.io.close()\n\n\nclass InputStockpile(Component):\n    \"\"\"Tracks input stockpile, decrements based on machine operations, and calculates storage costs.\"\"\"\n\n    io = IO(\n        inputs=[\"incoming_items\", \"machine1_running\", \"machine2_running\"],\n        outputs=[\"size\", \"storage_cost\"],\n    )\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._size = 0\n\n    async def step(self) -&gt; None:\n        # Add incoming items\n        self._size += self.incoming_items\n\n        # Remove items processed by machines\n        if self.machine1_running:\n            self._size = max(0, self._size - 5)  # Machine 1 processes 5 items\n        if self.machine2_running:\n            self._size = max(0, self._size - 8)  # Machine 2 processes 8 items\n\n        # Calculate storage cost: $10 per item above 50\n        storage_cost = max(0, self._size - 50) * 10\n\n        self.size = self._size\n        self.storage_cost = storage_cost\n\n\nclass Controller(Component):\n    \"\"\"Controls machine operation based on stockpile size.\"\"\"\n\n    io = IO(inputs=[\"stockpile_size\"], outputs=[\"should_run\"])\n\n    def __init__(self, threshold: int = 30, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._threshold = threshold\n\n    async def step(self) -&gt; None:\n        self.should_run = self.stockpile_size &gt;= self._threshold\n\n\nclass MachineCost(Component):\n    \"\"\"Calculates machine running costs.\"\"\"\n\n    io = IO(inputs=[\"is_running\"], outputs=[\"cost\"])\n\n    def __init__(\n        self, cost_per_step: float = 100.0, **kwargs: _t.Unpack[ComponentArgsDict]\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self._cost_per_step = cost_per_step\n\n    async def step(self) -&gt; None:\n        self.cost = self._cost_per_step if self.is_running else 0.0\n\n\nclass OutputStock(Component):\n    \"\"\"Tracks total items processed by both machines.\"\"\"\n\n    io = IO(inputs=[\"machine1_running\", \"machine2_running\"], outputs=[\"total_output\"])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._total = 0\n\n    async def step(self) -&gt; None:\n        if self.machine1_running:\n            self._total += 5\n        if self.machine2_running:\n            self._total += 8\n        self.total_output = self._total\n\n\nclass TotalCost(Component):\n    \"\"\"Keeps running total of all costs.\"\"\"\n\n    io = IO(inputs=[\"storage_cost\", \"machine1_cost\", \"machine2_cost\"], outputs=[\"total_cost\"])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._total = 0.0\n\n    async def step(self) -&gt; None:\n        step_cost = self.storage_cost + self.machine1_cost + self.machine2_cost\n        self._total += step_cost\n        self.total_cost = self._total\n\n\nclass CostPerUnit(Component):\n    \"\"\"Calculates cost per unit produced.\"\"\"\n\n    io = IO(inputs=[\"total_cost\", \"total_output\"], outputs=[\"cost_per_unit\"])\n\n    async def step(self) -&gt; None:\n        if self.total_output &gt; 0:\n            self.cost_per_unit = self.total_cost / self.total_output\n        else:\n            self.cost_per_unit = 0.0\n</pre> class Input(Component):     \"\"\"Provides a fixed number of input items per step.\"\"\"      io = IO(outputs=[\"items\"])      def __init__(         self,         items_per_step: int = 10,         total_steps: int = 1000,         **kwargs: _t.Unpack[ComponentArgsDict],     ) -&gt; None:         super().__init__(**kwargs)         self._items_per_step = items_per_step         self._total_steps = total_steps      async def step(self) -&gt; None:         self.items = self._items_per_step         if self._total_steps &gt; 0:             self._total_steps -= 1         else:             self.items = 0             await self.io.close()   class InputStockpile(Component):     \"\"\"Tracks input stockpile, decrements based on machine operations, and calculates storage costs.\"\"\"      io = IO(         inputs=[\"incoming_items\", \"machine1_running\", \"machine2_running\"],         outputs=[\"size\", \"storage_cost\"],     )      def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._size = 0      async def step(self) -&gt; None:         # Add incoming items         self._size += self.incoming_items          # Remove items processed by machines         if self.machine1_running:             self._size = max(0, self._size - 5)  # Machine 1 processes 5 items         if self.machine2_running:             self._size = max(0, self._size - 8)  # Machine 2 processes 8 items          # Calculate storage cost: $10 per item above 50         storage_cost = max(0, self._size - 50) * 10          self.size = self._size         self.storage_cost = storage_cost   class Controller(Component):     \"\"\"Controls machine operation based on stockpile size.\"\"\"      io = IO(inputs=[\"stockpile_size\"], outputs=[\"should_run\"])      def __init__(self, threshold: int = 30, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._threshold = threshold      async def step(self) -&gt; None:         self.should_run = self.stockpile_size &gt;= self._threshold   class MachineCost(Component):     \"\"\"Calculates machine running costs.\"\"\"      io = IO(inputs=[\"is_running\"], outputs=[\"cost\"])      def __init__(         self, cost_per_step: float = 100.0, **kwargs: _t.Unpack[ComponentArgsDict]     ) -&gt; None:         super().__init__(**kwargs)         self._cost_per_step = cost_per_step      async def step(self) -&gt; None:         self.cost = self._cost_per_step if self.is_running else 0.0   class OutputStock(Component):     \"\"\"Tracks total items processed by both machines.\"\"\"      io = IO(inputs=[\"machine1_running\", \"machine2_running\"], outputs=[\"total_output\"])      def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._total = 0      async def step(self) -&gt; None:         if self.machine1_running:             self._total += 5         if self.machine2_running:             self._total += 8         self.total_output = self._total   class TotalCost(Component):     \"\"\"Keeps running total of all costs.\"\"\"      io = IO(inputs=[\"storage_cost\", \"machine1_cost\", \"machine2_cost\"], outputs=[\"total_cost\"])      def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._total = 0.0      async def step(self) -&gt; None:         step_cost = self.storage_cost + self.machine1_cost + self.machine2_cost         self._total += step_cost         self.total_cost = self._total   class CostPerUnit(Component):     \"\"\"Calculates cost per unit produced.\"\"\"      io = IO(inputs=[\"total_cost\", \"total_output\"], outputs=[\"cost_per_unit\"])      async def step(self) -&gt; None:         if self.total_output &gt; 0:             self.cost_per_unit = self.total_cost / self.total_output         else:             self.cost_per_unit = 0.0 <p>Now assemble into a <code>Process</code> and make connections between the components.</p> In\u00a0[\u00a0]: Copied! <pre>connect = lambda in_, out_: AsyncioConnector(spec=ConnectorSpec(source=in_, target=out_))\n\nprocess = LocalProcess(\n    components=[\n        # Input component provides items\n        Input(name=\"input\", items_per_step=10),\n        # Stockpile manages inventory and storage costs\n        # We need to include initial values here to resolve a circular graph\n        InputStockpile(\n            name=\"stockpile\",\n            initial_values={\"machine1_running\": [False], \"machine2_running\": [False]},\n        ),\n        # Controllers decide when machines should run\n        Controller(name=\"controller1\", threshold=30),  # Machine 1 threshold\n        Controller(name=\"controller2\", threshold=50),  # Machine 2 threshold\n        # Machine cost components\n        MachineCost(name=\"machine1_cost\", cost_per_step=100.0),\n        MachineCost(name=\"machine2_cost\", cost_per_step=200.0),\n        # Output tracking\n        OutputStock(name=\"output_stock\"),\n        # Cost tracking and calculation\n        TotalCost(name=\"total_cost\"),\n        CostPerUnit(name=\"cost_per_unit\"),\n    ],\n    connectors=[\n        # Input flow\n        connect(\"input.items\", \"stockpile.incoming_items\"),\n        # Stockpile to controllers\n        connect(\"stockpile.size\", \"controller1.stockpile_size\"),\n        connect(\"stockpile.size\", \"controller2.stockpile_size\"),\n        # Controllers to machine costs\n        connect(\"controller1.should_run\", \"machine1_cost.is_running\"),\n        connect(\"controller2.should_run\", \"machine2_cost.is_running\"),\n        # Controllers to stockpile (for processing)\n        connect(\"controller1.should_run\", \"stockpile.machine1_running\"),\n        connect(\"controller2.should_run\", \"stockpile.machine2_running\"),\n        # Controllers to output stock\n        connect(\"controller1.should_run\", \"output_stock.machine1_running\"),\n        connect(\"controller2.should_run\", \"output_stock.machine2_running\"),\n        # All costs to total cost\n        connect(\"stockpile.storage_cost\", \"total_cost.storage_cost\"),\n        connect(\"machine1_cost.cost\", \"total_cost.machine1_cost\"),\n        connect(\"machine2_cost.cost\", \"total_cost.machine2_cost\"),\n        # Total cost and output to cost per unit\n        connect(\"total_cost.total_cost\", \"cost_per_unit.total_cost\"),\n        connect(\"output_stock.total_output\", \"cost_per_unit.total_output\"),\n    ],\n)\n\nprint(\"Production line process created successfully!\")\nprint(f\"Process has {len(process.components)} components and {len(process.connectors)} connectors\")\n</pre> connect = lambda in_, out_: AsyncioConnector(spec=ConnectorSpec(source=in_, target=out_))  process = LocalProcess(     components=[         # Input component provides items         Input(name=\"input\", items_per_step=10),         # Stockpile manages inventory and storage costs         # We need to include initial values here to resolve a circular graph         InputStockpile(             name=\"stockpile\",             initial_values={\"machine1_running\": [False], \"machine2_running\": [False]},         ),         # Controllers decide when machines should run         Controller(name=\"controller1\", threshold=30),  # Machine 1 threshold         Controller(name=\"controller2\", threshold=50),  # Machine 2 threshold         # Machine cost components         MachineCost(name=\"machine1_cost\", cost_per_step=100.0),         MachineCost(name=\"machine2_cost\", cost_per_step=200.0),         # Output tracking         OutputStock(name=\"output_stock\"),         # Cost tracking and calculation         TotalCost(name=\"total_cost\"),         CostPerUnit(name=\"cost_per_unit\"),     ],     connectors=[         # Input flow         connect(\"input.items\", \"stockpile.incoming_items\"),         # Stockpile to controllers         connect(\"stockpile.size\", \"controller1.stockpile_size\"),         connect(\"stockpile.size\", \"controller2.stockpile_size\"),         # Controllers to machine costs         connect(\"controller1.should_run\", \"machine1_cost.is_running\"),         connect(\"controller2.should_run\", \"machine2_cost.is_running\"),         # Controllers to stockpile (for processing)         connect(\"controller1.should_run\", \"stockpile.machine1_running\"),         connect(\"controller2.should_run\", \"stockpile.machine2_running\"),         # Controllers to output stock         connect(\"controller1.should_run\", \"output_stock.machine1_running\"),         connect(\"controller2.should_run\", \"output_stock.machine2_running\"),         # All costs to total cost         connect(\"stockpile.storage_cost\", \"total_cost.storage_cost\"),         connect(\"machine1_cost.cost\", \"total_cost.machine1_cost\"),         connect(\"machine2_cost.cost\", \"total_cost.machine2_cost\"),         # Total cost and output to cost per unit         connect(\"total_cost.total_cost\", \"cost_per_unit.total_cost\"),         connect(\"output_stock.total_output\", \"cost_per_unit.total_output\"),     ], )  print(\"Production line process created successfully!\") print(f\"Process has {len(process.components)} components and {len(process.connectors)} connectors\") <p>We can create a diagram of the process to make a visual check.</p> <p></p> In\u00a0[\u00a0]: Copied! <pre># Visualize the process flow\nfrom plugboard.diagram import MermaidDiagram\n\ndiagram_url = MermaidDiagram.from_process(process).url\nprint(diagram_url)\n</pre> # Visualize the process flow from plugboard.diagram import MermaidDiagram  diagram_url = MermaidDiagram.from_process(process).url print(diagram_url) In\u00a0[\u00a0]: Copied! <pre># Run the simulation\nasync with process:\n    await process.run()\n</pre> # Run the simulation async with process:     await process.run() <p>At the end of the simulation, the final cost per unit is available on the <code>CostPerUnit</code> component output.</p> In\u00a0[\u00a0]: Copied! <pre>final_cost = process.components[\"cost_per_unit\"].cost_per_unit\nprint(f\"Final cost per unit: ${final_cost:.2f}\")\n</pre> final_cost = process.components[\"cost_per_unit\"].cost_per_unit print(f\"Final cost per unit: ${final_cost:.2f}\") <p>Now suppose we want to build an optimisation to find the best values of the threshold settings on <code>controller1</code> and <code>controller2</code>. Specifically we want to minimise <code>cost_per_unit</code> by choosing the settings on the two controllers. The easiest way to do this is to convert our model to Python code with an associated YAML config file. See:</p> <ul> <li><code>production_line.py</code>; and</li> <li><code>production-line.yaml</code>.</li> </ul> <p>The easiest way to launch an optimisation job is via the CLI by running:</p> <pre>plugboard process tune production-line.yaml\n</pre> <p>This will use Optuna to explore the parameter space and report the controller thresholds that minimise cost per unit at the end of the run, for example:</p> <pre><code>Best parameters found:\nConfig: {'component.controller1.arg.threshold': 10, 'component.controller2.arg.threshold': 38} - Metrics: {'component.cost_per_unit.field.cost_per_unit': 22.491974317817014, 'timestamp': 1763499370, \n'checkpoint_dir_name': None, 'done': True, 'training_iteration': 1, 'trial_id': '480ac050', 'date': '2025-11-18_20-56-10', 'time_this_iter_s': 2.0268948078155518, 'time_total_s': 2.0268948078155518, 'pid': 35181,\n'hostname': 'Tobys-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'component.controller1.arg.threshold': 10, 'component.controller2.arg.threshold': 38}, 'time_since_restore': 2.0268948078155518, \n'iterations_since_restore': 1, 'experiment_tag': '23_component_controller1_arg_threshold=10,component_controller2_arg_threshold=38'}\n</code></pre>","tags":["optimisation"]},{"location":"examples/demos/fundamentals/002_production_line_optimisation/production-line/#production-process-optimisation","title":"Production process optimisation\u00b6","text":"<p>This production line simulation models the unit cost of a small manufacturing operation with the following components:</p>","tags":["optimisation"]},{"location":"examples/demos/fundamentals/002_production_line_optimisation/production-line/#components","title":"Components:\u00b6","text":"<ol> <li>Input: Provides a fixed number of input items (10) per simulation step</li> <li>InputStockpile:<ul> <li>Tracks inventory levels</li> <li>Decrements based on machine operations (Machine 1: 5 items/step, Machine 2: 8 items/step)</li> <li>Calculates storage costs ($10 per item above 50)</li> </ul> </li> <li>Controller (2 instances):<ul> <li>Controller 1: Activates Machine 1 when stockpile &gt;= 30 items</li> <li>Controller 2: Activates Machine 2 when stockpile &gt;= 50 items</li> </ul> </li> <li>MachineCost (2 instances):<ul> <li>Machine 1: $100 per step when running</li> <li>Machine 2: $200 per step when running</li> </ul> </li> <li>OutputStock: Tracks total items processed by both machines</li> <li>TotalCost: Maintains running total of all costs (storage + machine operations)</li> <li>CostPerUnit: Calculates the cost per unit produced (total cost \u00f7 total output)</li> </ol>","tags":["optimisation"]},{"location":"examples/demos/fundamentals/002_production_line_optimisation/production-line/#key-metrics","title":"Key Metrics:\u00b6","text":"<ul> <li>Production Efficiency: Percentage of input items successfully processed</li> <li>Cost Per Unit: Total operational cost divided by units produced</li> <li>Storage Utilization: How well the system manages inventory levels</li> </ul> <p>The simulation runs for 1000 steps to provide stable long-term cost metrics. We can then use the model to find optimal values for the threshold levels on the two controllers.</p>","tags":["optimisation"]},{"location":"examples/demos/fundamentals/002_production_line_optimisation/production_line/","title":"Production line","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Defines components used in the production line example.\"\"\"\n</pre> \"\"\"Defines components used in the production line example.\"\"\" In\u00a0[\u00a0]: Copied! <pre>import typing as _t\n</pre> import typing as _t In\u00a0[\u00a0]: Copied! <pre>from plugboard.component import Component, IOController as IO\nfrom plugboard.schemas import ComponentArgsDict\n</pre> from plugboard.component import Component, IOController as IO from plugboard.schemas import ComponentArgsDict In\u00a0[\u00a0]: Copied! <pre>class Input(Component):\n    \"\"\"Provides a fixed number of input items per step.\"\"\"\n\n    io = IO(outputs=[\"items\"])\n\n    def __init__(\n        self,\n        items_per_step: int = 10,\n        total_steps: int = 1000,\n        **kwargs: _t.Unpack[ComponentArgsDict],\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self._items_per_step = items_per_step\n        self._total_steps = total_steps\n\n    async def step(self) -&gt; None:\n        self.items = self._items_per_step\n        if self._total_steps &gt; 0:\n            self._total_steps -= 1\n        else:\n            self.items = 0\n            await self.io.close()\n</pre> class Input(Component):     \"\"\"Provides a fixed number of input items per step.\"\"\"      io = IO(outputs=[\"items\"])      def __init__(         self,         items_per_step: int = 10,         total_steps: int = 1000,         **kwargs: _t.Unpack[ComponentArgsDict],     ) -&gt; None:         super().__init__(**kwargs)         self._items_per_step = items_per_step         self._total_steps = total_steps      async def step(self) -&gt; None:         self.items = self._items_per_step         if self._total_steps &gt; 0:             self._total_steps -= 1         else:             self.items = 0             await self.io.close() In\u00a0[\u00a0]: Copied! <pre>class InputStockpile(Component):\n    \"\"\"Tracks input stockpile, decrements based on machine operations, and calculates storage costs.\"\"\"\n\n    io = IO(\n        inputs=[\"incoming_items\", \"machine1_running\", \"machine2_running\"],\n        outputs=[\"size\", \"storage_cost\"],\n    )\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._size = 0\n\n    async def step(self) -&gt; None:\n        # Add incoming items\n        self._size += self.incoming_items\n\n        # Remove items processed by machines\n        if self.machine1_running:\n            self._size = max(0, self._size - 5)  # Machine 1 processes 5 items\n        if self.machine2_running:\n            self._size = max(0, self._size - 8)  # Machine 2 processes 8 items\n\n        # Calculate storage cost: $10 per item above 50\n        storage_cost = max(0, self._size - 50) * 10\n\n        self.size = self._size\n        self.storage_cost = storage_cost\n</pre> class InputStockpile(Component):     \"\"\"Tracks input stockpile, decrements based on machine operations, and calculates storage costs.\"\"\"      io = IO(         inputs=[\"incoming_items\", \"machine1_running\", \"machine2_running\"],         outputs=[\"size\", \"storage_cost\"],     )      def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._size = 0      async def step(self) -&gt; None:         # Add incoming items         self._size += self.incoming_items          # Remove items processed by machines         if self.machine1_running:             self._size = max(0, self._size - 5)  # Machine 1 processes 5 items         if self.machine2_running:             self._size = max(0, self._size - 8)  # Machine 2 processes 8 items          # Calculate storage cost: $10 per item above 50         storage_cost = max(0, self._size - 50) * 10          self.size = self._size         self.storage_cost = storage_cost In\u00a0[\u00a0]: Copied! <pre>class Controller(Component):\n    \"\"\"Controls machine operation based on stockpile size.\"\"\"\n\n    io = IO(inputs=[\"stockpile_size\"], outputs=[\"should_run\"])\n\n    def __init__(self, threshold: int = 30, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._threshold = threshold\n\n    async def step(self) -&gt; None:\n        self.should_run = self.stockpile_size &gt;= self._threshold\n</pre> class Controller(Component):     \"\"\"Controls machine operation based on stockpile size.\"\"\"      io = IO(inputs=[\"stockpile_size\"], outputs=[\"should_run\"])      def __init__(self, threshold: int = 30, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._threshold = threshold      async def step(self) -&gt; None:         self.should_run = self.stockpile_size &gt;= self._threshold In\u00a0[\u00a0]: Copied! <pre>class MachineCost(Component):\n    \"\"\"Calculates machine running costs.\"\"\"\n\n    io = IO(inputs=[\"is_running\"], outputs=[\"cost\"])\n\n    def __init__(\n        self, cost_per_step: float = 100.0, **kwargs: _t.Unpack[ComponentArgsDict]\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self._cost_per_step = cost_per_step\n\n    async def step(self) -&gt; None:\n        self.cost = self._cost_per_step if self.is_running else 0.0\n</pre> class MachineCost(Component):     \"\"\"Calculates machine running costs.\"\"\"      io = IO(inputs=[\"is_running\"], outputs=[\"cost\"])      def __init__(         self, cost_per_step: float = 100.0, **kwargs: _t.Unpack[ComponentArgsDict]     ) -&gt; None:         super().__init__(**kwargs)         self._cost_per_step = cost_per_step      async def step(self) -&gt; None:         self.cost = self._cost_per_step if self.is_running else 0.0 In\u00a0[\u00a0]: Copied! <pre>class OutputStock(Component):\n    \"\"\"Tracks total items processed by both machines.\"\"\"\n\n    io = IO(inputs=[\"machine1_running\", \"machine2_running\"], outputs=[\"total_output\"])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._total = 0\n\n    async def step(self) -&gt; None:\n        if self.machine1_running:\n            self._total += 5\n        if self.machine2_running:\n            self._total += 8\n        self.total_output = self._total\n</pre> class OutputStock(Component):     \"\"\"Tracks total items processed by both machines.\"\"\"      io = IO(inputs=[\"machine1_running\", \"machine2_running\"], outputs=[\"total_output\"])      def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._total = 0      async def step(self) -&gt; None:         if self.machine1_running:             self._total += 5         if self.machine2_running:             self._total += 8         self.total_output = self._total In\u00a0[\u00a0]: Copied! <pre>class TotalCost(Component):\n    \"\"\"Keeps running total of all costs.\"\"\"\n\n    io = IO(inputs=[\"storage_cost\", \"machine1_cost\", \"machine2_cost\"], outputs=[\"total_cost\"])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._total = 0.0\n\n    async def step(self) -&gt; None:\n        step_cost = self.storage_cost + self.machine1_cost + self.machine2_cost\n        self._total += step_cost\n        self.total_cost = self._total\n</pre> class TotalCost(Component):     \"\"\"Keeps running total of all costs.\"\"\"      io = IO(inputs=[\"storage_cost\", \"machine1_cost\", \"machine2_cost\"], outputs=[\"total_cost\"])      def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._total = 0.0      async def step(self) -&gt; None:         step_cost = self.storage_cost + self.machine1_cost + self.machine2_cost         self._total += step_cost         self.total_cost = self._total In\u00a0[\u00a0]: Copied! <pre>class CostPerUnit(Component):\n    \"\"\"Calculates cost per unit produced.\"\"\"\n\n    io = IO(inputs=[\"total_cost\", \"total_output\"], outputs=[\"cost_per_unit\"])\n\n    async def step(self) -&gt; None:\n        if self.total_output &gt; 0:\n            self.cost_per_unit = self.total_cost / self.total_output\n        else:\n            self.cost_per_unit = 0.0\n</pre> class CostPerUnit(Component):     \"\"\"Calculates cost per unit produced.\"\"\"      io = IO(inputs=[\"total_cost\", \"total_output\"], outputs=[\"cost_per_unit\"])      async def step(self) -&gt; None:         if self.total_output &gt; 0:             self.cost_per_unit = self.total_cost / self.total_output         else:             self.cost_per_unit = 0.0","tags":["optimisation"]},{"location":"examples/demos/llm/001_data_filter/llm-filtering/","title":"LLM for data filtering","text":"In\u00a0[\u00a0]: Copied! <pre># Install plugboard and dependencies for Google Colab\n!pip install -q plugboard[llm]\n</pre> # Install plugboard and dependencies for Google Colab !pip install -q plugboard[llm] In\u00a0[\u00a0]: Copied! <pre>import os\nfrom getpass import getpass\n\nimport pandas as pd\nfrom pydantic import BaseModel\n\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.schemas import ConnectorSpec\nfrom plugboard.process import LocalProcess\nfrom plugboard.library import FileReader, FileWriter, LLMChat\n</pre> import os from getpass import getpass  import pandas as pd from pydantic import BaseModel  from plugboard.connector import AsyncioConnector from plugboard.schemas import ConnectorSpec from plugboard.process import LocalProcess from plugboard.library import FileReader, FileWriter, LLMChat In\u00a0[\u00a0]: Copied! <pre>if \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n</pre> if \"OPENAI_API_KEY\" not in os.environ:     os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \") <p>The <code>FileReader</code> and <code>FileWriter</code> components are provided by plugboard: set the up to load the input CSV file and save the model result to <code>output.csv</code>.</p> In\u00a0[\u00a0]: Copied! <pre>input_data = FileReader(name=\"input_data\", path=\"input.csv\", field_names=[\"temperature\"])\noutput_data = FileWriter(\n    name=\"output_data\",\n    path=\"output.csv\",\n    field_names=[\"raw_temperature\", \"corrected_temperature\", \"was_corrected\"],\n)\n</pre> input_data = FileReader(name=\"input_data\", path=\"input.csv\", field_names=[\"temperature\"]) output_data = FileWriter(     name=\"output_data\",     path=\"output.csv\",     field_names=[\"raw_temperature\", \"corrected_temperature\", \"was_corrected\"], ) <p>For the noise filter, we need to set up an <code>LLMChat</code> component to correct the temperature readings. To do this we need:</p> <ol> <li>A Pydantic response model to specify the format we would like the output in;</li> <li>A system prompt that provides instructions to the LLM about how we would like the data corrected;</li> <li>Configuration on <code>LLMChat</code> to keep context in the chat history, so that the model knows about previous values of the temperature that it has seen.</li> </ol> In\u00a0[\u00a0]: Copied! <pre>class CleanTemperature(BaseModel):\n    temperature: float\n    was_corrected: bool\n\n\nsystem_prompt = \"\"\"\nYou are going to receive temperature values read from a sensor. These frequently contain errors that need to be corrected.\nExample errors are: missing decimal point, missing digit, decimal point in the wrong place, etc.\nYou need to correct the temperature values and indicate whether they were corrected or not.\nFor context, the temperature values are in Celsius and are not expected to change more than 2 degrees between readings.\nIf you cannot tell what the correct value should be you should output the last known correct value.\n\"\"\"\n\nllm = LLMChat(\n    name=\"llm\",\n    system_prompt=system_prompt,\n    # This needs GPT-4o or similar to work well\n    llm_kwargs={\"model\": \"gpt-4o\"},\n    response_model=CleanTemperature,\n    # Expand the response into separate fields: llm.temperature and llm.was_corrected\n    expand_response=True,\n    # Include context so that the model can use the last known correct value\n    context_window=5,\n)\n</pre> class CleanTemperature(BaseModel):     temperature: float     was_corrected: bool   system_prompt = \"\"\" You are going to receive temperature values read from a sensor. These frequently contain errors that need to be corrected. Example errors are: missing decimal point, missing digit, decimal point in the wrong place, etc. You need to correct the temperature values and indicate whether they were corrected or not. For context, the temperature values are in Celsius and are not expected to change more than 2 degrees between readings. If you cannot tell what the correct value should be you should output the last known correct value. \"\"\"  llm = LLMChat(     name=\"llm\",     system_prompt=system_prompt,     # This needs GPT-4o or similar to work well     llm_kwargs={\"model\": \"gpt-4o\"},     response_model=CleanTemperature,     # Expand the response into separate fields: llm.temperature and llm.was_corrected     expand_response=True,     # Include context so that the model can use the last known correct value     context_window=5, ) <p>Now connect the components together in a <code>LocalProcess</code>.</p> In\u00a0[\u00a0]: Copied! <pre>process = LocalProcess(\n    components=[input_data, llm, output_data],\n    connectors=[\n        # Connect input_data to LLM\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"input_data.temperature\", target=\"llm.prompt\"),\n        ),\n        # Connect both the raw input and LLM output to the output_data\n        AsyncioConnector(\n            spec=ConnectorSpec(\n                source=\"input_data.temperature\", target=\"output_data.raw_temperature\"\n            )\n        ),\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"llm.temperature\", target=\"output_data.corrected_temperature\")\n        ),\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"llm.was_corrected\", target=\"output_data.was_corrected\")\n        ),\n    ],\n)\n</pre> process = LocalProcess(     components=[input_data, llm, output_data],     connectors=[         # Connect input_data to LLM         AsyncioConnector(             spec=ConnectorSpec(source=\"input_data.temperature\", target=\"llm.prompt\"),         ),         # Connect both the raw input and LLM output to the output_data         AsyncioConnector(             spec=ConnectorSpec(                 source=\"input_data.temperature\", target=\"output_data.raw_temperature\"             )         ),         AsyncioConnector(             spec=ConnectorSpec(source=\"llm.temperature\", target=\"output_data.corrected_temperature\")         ),         AsyncioConnector(             spec=ConnectorSpec(source=\"llm.was_corrected\", target=\"output_data.was_corrected\")         ),     ], ) <p>Now we can initialise and run the simulation.</p> In\u00a0[\u00a0]: Copied! <pre>async with process:\n    await process.run()\n</pre> async with process:     await process.run() <p>Now take a look at the data in <code>output.csv</code> and see how the model did.</p> In\u00a0[\u00a0]: Copied! <pre>pd.read_csv(\"output.csv\")\n</pre> pd.read_csv(\"output.csv\")","tags":["llm"]},{"location":"examples/demos/llm/001_data_filter/llm-filtering/#llm-for-data-filtering","title":"LLM for data filtering\u00b6","text":"<p>This model is a simple demonstration of how to use an LLM in a Plugboard model. In this case, we're going to use it to filter noisy data. The <code>input.csv</code> contains a sample of some temperature data that has been corrupted by various errors. We use the LLM to make corrections to the data where necessary.</p> <p>To run this model you will need to set the <code>OPENAI_API_KEY</code> environment variable.</p>","tags":["llm"]},{"location":"examples/demos/llm/002_bluesky_websocket/bluesky-websocket/","title":"Streaming data: processing a websocket feed","text":"In\u00a0[\u00a0]: Copied! <pre># Install plugboard and dependencies for Google Colab\n!pip install -q plugboard[llm,websockets]\n</pre> # Install plugboard and dependencies for Google Colab !pip install -q plugboard[llm,websockets] In\u00a0[\u00a0]: Copied! <pre>import asyncio\nimport os\nimport typing as _t\nfrom getpass import getpass\n\nimport httpx\nfrom pydantic import BaseModel, Field\n\nfrom plugboard.component import Component, IOController\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.schemas import ConnectorSpec\nfrom plugboard.process import LocalProcess\nfrom plugboard.library import FileWriter, LLMChat, WebsocketReader\n</pre> import asyncio import os import typing as _t from getpass import getpass  import httpx from pydantic import BaseModel, Field  from plugboard.component import Component, IOController from plugboard.connector import AsyncioConnector from plugboard.schemas import ConnectorSpec from plugboard.process import LocalProcess from plugboard.library import FileWriter, LLMChat, WebsocketReader In\u00a0[\u00a0]: Copied! <pre>if \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n</pre> if \"OPENAI_API_KEY\" not in os.environ:     os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \") <p>We'll subscribe to BlueSky posts from the following news outlets.</p> <ul> <li>Reuters</li> <li>Bloomberg</li> <li>CNBC</li> <li>Financial Times</li> <li>Wall Street Journal</li> <li>Yahoo Finance</li> </ul> <p>The BlueSky API filters according to DIDs - a unique identifier for each user that we'll need to lookup.</p> In\u00a0[\u00a0]: Copied! <pre>async def fetch_bluesky_did(client: httpx.AsyncClient, user_name: str) -&gt; str:\n    response = await client.get(\n        \"https://bsky.social/xrpc/com.atproto.identity.resolveHandle\", params={\"handle\": user_name}\n    )\n    return response.json()[\"did\"]\n</pre> async def fetch_bluesky_did(client: httpx.AsyncClient, user_name: str) -&gt; str:     response = await client.get(         \"https://bsky.social/xrpc/com.atproto.identity.resolveHandle\", params={\"handle\": user_name}     )     return response.json()[\"did\"] In\u00a0[\u00a0]: Copied! <pre>user_handles = [\n    \"reuters.com\",\n    \"bloomberg.com\",\n    \"cnbc.com\",\n    \"financialtimes.com\",\n    \"wsj.com\",\n    \"yahoofinance.com\",\n]\nasync with httpx.AsyncClient() as client:\n    bluesky_dids = await asyncio.gather(\n        *[fetch_bluesky_did(client, handle) for handle in user_handles]\n    )\n# Bluesky uses the \"wantedDids\" parameter to specify the DIDs of the users we want to filter\nfilter_spec = \"&amp;\".join([f\"wantedDids={did}\" for did in bluesky_dids])\n</pre> user_handles = [     \"reuters.com\",     \"bloomberg.com\",     \"cnbc.com\",     \"financialtimes.com\",     \"wsj.com\",     \"yahoofinance.com\", ] async with httpx.AsyncClient() as client:     bluesky_dids = await asyncio.gather(         *[fetch_bluesky_did(client, handle) for handle in user_handles]     ) # Bluesky uses the \"wantedDids\" parameter to specify the DIDs of the users we want to filter filter_spec = \"&amp;\".join([f\"wantedDids={did}\" for did in bluesky_dids]) <p>Now we have the DIDs for BlueSky, setup a <code>WebsocketReader</code> to stream posts into a Plugboard process. Using the Jetstream instructions we'll filter on posts from the users we are interested in.</p> In\u00a0[\u00a0]: Copied! <pre>websocket = WebsocketReader(\n    name=\"bluesky-feed\",\n    uri=f\"wss://jetstream2.us-east.bsky.network/subscribe?wantedCollections=app.bsky.feed.post&amp;{filter_spec}\",\n    parse_json=True,\n)\n</pre> websocket = WebsocketReader(     name=\"bluesky-feed\",     uri=f\"wss://jetstream2.us-east.bsky.network/subscribe?wantedCollections=app.bsky.feed.post&amp;{filter_spec}\",     parse_json=True, ) <p>Next we need a <code>Component</code> to extract the post text and timestamp each message received from BlueSky.</p> In\u00a0[\u00a0]: Copied! <pre>class ExtractMessage(Component):\n    \"\"\"Extracts text and timestamp from a BlueSky message dictionary.\"\"\"\n\n    io = IOController(inputs=[\"message\"], outputs=[\"text\", \"time_stamp\"])\n\n    async def step(self) -&gt; None:\n        try:\n            # Surround text with quotes so that is is correctly formatted in CSV output\n            self.text = f'\"{websocket.message[\"commit\"][\"record\"][\"text\"].replace(\"\\n\", \" \")}\"'\n            self.time_stamp = websocket.message[\"commit\"][\"record\"][\"createdAt\"]\n        except KeyError:\n            # Skip messages that aren't correctly formatted\n            pass\n\n\nextract = ExtractMessage(name=\"extract-message\")\n</pre> class ExtractMessage(Component):     \"\"\"Extracts text and timestamp from a BlueSky message dictionary.\"\"\"      io = IOController(inputs=[\"message\"], outputs=[\"text\", \"time_stamp\"])      async def step(self) -&gt; None:         try:             # Surround text with quotes so that is is correctly formatted in CSV output             self.text = f'\"{websocket.message[\"commit\"][\"record\"][\"text\"].replace(\"\\n\", \" \")}\"'             self.time_stamp = websocket.message[\"commit\"][\"record\"][\"createdAt\"]         except KeyError:             # Skip messages that aren't correctly formatted             pass   extract = ExtractMessage(name=\"extract-message\") <p>Next, let's setup an LLM component to analyse the messages as they arrive from BlueSky and carry out sentiment analysis. We'll use the LLM in structured-output mode, so that we have known outputs from the component.</p> In\u00a0[\u00a0]: Copied! <pre>class MessageInformation(BaseModel):\n    category: _t.Literal[\"markets\", \"companies\", \"economics\", \"other\"]\n    market_relevance: float = Field(..., ge=0, le=100)\n    sentiment: _t.Literal[\"positive\", \"negative\", \"neutral\"]\n\n\nsystem_prompt = \"\"\"\nYou are going to be shown headlines from business news services. For each headline, please provide the following:\n- The category of the headline (markets, companies, economics, other)\n- The market relevance of the headline to financial markets on a scale of 0 (least relevant) to 100 (most relevant)\n- The sentiment of the headline (positive, negative, neutral).\n\"\"\"\n\nllm = LLMChat(\n    name=\"llm\",\n    system_prompt=system_prompt,\n    llm_kwargs={\"model\": \"gpt-4o\"},\n    response_model=MessageInformation,\n    # Expand the response into separate fields\n    expand_response=True,\n)\n</pre> class MessageInformation(BaseModel):     category: _t.Literal[\"markets\", \"companies\", \"economics\", \"other\"]     market_relevance: float = Field(..., ge=0, le=100)     sentiment: _t.Literal[\"positive\", \"negative\", \"neutral\"]   system_prompt = \"\"\" You are going to be shown headlines from business news services. For each headline, please provide the following: - The category of the headline (markets, companies, economics, other) - The market relevance of the headline to financial markets on a scale of 0 (least relevant) to 100 (most relevant) - The sentiment of the headline (positive, negative, neutral). \"\"\"  llm = LLMChat(     name=\"llm\",     system_prompt=system_prompt,     llm_kwargs={\"model\": \"gpt-4o\"},     response_model=MessageInformation,     # Expand the response into separate fields     expand_response=True, ) <p>Finally, we'll use the <code>FileWriter</code> component to save the output to CSV.</p> In\u00a0[\u00a0]: Copied! <pre># Set chunk size to 1 so that data is saved to disk as each message arrives\nsave = FileWriter(\n    name=\"save\",\n    path=\"bluesky-messages.csv\",\n    chunk_size=1,\n    field_names=[\"text\", \"time_stamp\", \"category\", \"market_relevance\", \"sentiment\"],\n)\n</pre> # Set chunk size to 1 so that data is saved to disk as each message arrives save = FileWriter(     name=\"save\",     path=\"bluesky-messages.csv\",     chunk_size=1,     field_names=[\"text\", \"time_stamp\", \"category\", \"market_relevance\", \"sentiment\"], ) <p>Now build the <code>LocalProcess</code> and connect all of the components together.</p> In\u00a0[\u00a0]: Copied! <pre>connect = lambda in_, out_: AsyncioConnector(spec=ConnectorSpec(source=in_, target=out_))\nprocess = LocalProcess(\n    components=[websocket, extract, llm, save],\n    connectors=[\n        # Connect websocket to extract\n        connect(\"bluesky-feed.message\", \"extract-message.message\"),\n        # Save the time_stamp and text from the extract component\n        connect(\"extract-message.time_stamp\", \"save.time_stamp\"),\n        connect(\"extract-message.text\", \"save.text\"),\n        # Connect the extracted message to the LLM\n        connect(\"extract-message.text\", \"llm.prompt\"),\n        # Connect the LLM outputs to the save component\n        connect(\"llm.category\", \"save.category\"),\n        connect(\"llm.market_relevance\", \"save.market_relevance\"),\n        connect(\"llm.sentiment\", \"save.sentiment\"),\n    ],\n)\n</pre> connect = lambda in_, out_: AsyncioConnector(spec=ConnectorSpec(source=in_, target=out_)) process = LocalProcess(     components=[websocket, extract, llm, save],     connectors=[         # Connect websocket to extract         connect(\"bluesky-feed.message\", \"extract-message.message\"),         # Save the time_stamp and text from the extract component         connect(\"extract-message.time_stamp\", \"save.time_stamp\"),         connect(\"extract-message.text\", \"save.text\"),         # Connect the extracted message to the LLM         connect(\"extract-message.text\", \"llm.prompt\"),         # Connect the LLM outputs to the save component         connect(\"llm.category\", \"save.category\"),         connect(\"llm.market_relevance\", \"save.market_relevance\"),         connect(\"llm.sentiment\", \"save.sentiment\"),     ], ) <p>Now run the model. The websocket input will run forever, continuing to stream new data, so when you are ready to stop the process you will need to manually interrupt it. Open the output CSV file to see the data that has been captured. Keep in mind that some of the news sources publish infrequently outside of their business hours, so depending on when you run the code you might need to leave it for a while to collect some data.</p> In\u00a0[\u00a0]: Copied! <pre>async with process:\n    await process.run()\n</pre> async with process:     await process.run()","tags":["llm","io","streaming"]},{"location":"examples/demos/llm/002_bluesky_websocket/bluesky-websocket/#streaming-data-processing-a-websocket-feed","title":"Streaming data: processing a websocket feed\u00b6","text":"<p>This model will run on a continuous stream of data provided by BlueSky's firehose websocket. We'll subscribe to posts from some business news feeds and then use an LLM to carry out sentiment analysis on each message.</p> <p>To run this model you will need to set the <code>OPENAI_API_KEY</code> environment variable.</p>","tags":["llm","io","streaming"]},{"location":"examples/demos/llm/003_rock_paper_scissors/rock-paper-scissors/","title":"Rock Paper Scissors","text":"In\u00a0[\u00a0]: Copied! <pre># Install plugboard and dependencies for Google Colab\n!pip install -q plugboard[llm]\n</pre> # Install plugboard and dependencies for Google Colab !pip install -q plugboard[llm] In\u00a0[\u00a0]: Copied! <pre># Setup and imports\nimport os\nimport typing as _t\nfrom enum import Enum\nfrom pydantic import BaseModel, Field\nfrom plugboard.component import Component, IOController as IO\nfrom plugboard.schemas import ComponentArgsDict, ConnectorSpec\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.process import LocalProcess\nfrom plugboard.library import LLMChat\n</pre> # Setup and imports import os import typing as _t from enum import Enum from pydantic import BaseModel, Field from plugboard.component import Component, IOController as IO from plugboard.schemas import ComponentArgsDict, ConnectorSpec from plugboard.connector import AsyncioConnector from plugboard.process import LocalProcess from plugboard.library import LLMChat In\u00a0[\u00a0]: Copied! <pre>from getpass import getpass\n\n\ndef set_api_key_from_user(env_var: str, service_name: str) -&gt; None:\n    \"\"\"Prompt user for an API key if not set in the environment.\"\"\"\n    if env_var not in os.environ or not os.environ[env_var]:\n        try:\n            key = getpass(f\"Enter your {service_name} API key (or press Enter to skip): \")\n            os.environ[env_var] = key or os.environ.get(env_var, \"\")\n        except EOFError:\n            # Can happen in non-interactive environments\n            pass\n\n\nset_api_key_from_user(\"OPENAI_API_KEY\", \"OpenAI\")\nset_api_key_from_user(\"GOOGLE_API_KEY\", \"Google\")\n</pre> from getpass import getpass   def set_api_key_from_user(env_var: str, service_name: str) -&gt; None:     \"\"\"Prompt user for an API key if not set in the environment.\"\"\"     if env_var not in os.environ or not os.environ[env_var]:         try:             key = getpass(f\"Enter your {service_name} API key (or press Enter to skip): \")             os.environ[env_var] = key or os.environ.get(env_var, \"\")         except EOFError:             # Can happen in non-interactive environments             pass   set_api_key_from_user(\"OPENAI_API_KEY\", \"OpenAI\") set_api_key_from_user(\"GOOGLE_API_KEY\", \"Google\") <p>Setup some Pydantic models to structure the output from the LLMs</p> In\u00a0[\u00a0]: Copied! <pre>class Result(str, Enum):\n    win = \"win\"\n    lose = \"lose\"\n    draw = \"draw\"\n\n\nclass Move(str, Enum):\n    rock = \"rock\"\n    paper = \"paper\"\n    scissors = \"scissors\"\n\n    def result_against(self, other: \"Move\") -&gt; Result:\n        if self == other:\n            return Result.draw\n\n        outcomes = {\n            (Move.rock, Move.paper): Result.lose,\n            (Move.rock, Move.scissors): Result.win,\n            (Move.paper, Move.rock): Result.win,\n            (Move.paper, Move.scissors): Result.lose,\n            (Move.scissors, Move.paper): Result.win,\n            (Move.scissors, Move.rock): Result.lose,\n        }\n        return outcomes[(self, other)]\n\n\nclass PlayerDecision(BaseModel):\n    choice: Move = Field(..., description=\"One of rock, paper, or scissors\")\n    rationale: str = Field(..., description=\"Brief reason for the choice\")\n</pre> class Result(str, Enum):     win = \"win\"     lose = \"lose\"     draw = \"draw\"   class Move(str, Enum):     rock = \"rock\"     paper = \"paper\"     scissors = \"scissors\"      def result_against(self, other: \"Move\") -&gt; Result:         if self == other:             return Result.draw          outcomes = {             (Move.rock, Move.paper): Result.lose,             (Move.rock, Move.scissors): Result.win,             (Move.paper, Move.rock): Result.win,             (Move.paper, Move.scissors): Result.lose,             (Move.scissors, Move.paper): Result.win,             (Move.scissors, Move.rock): Result.lose,         }         return outcomes[(self, other)]   class PlayerDecision(BaseModel):     choice: Move = Field(..., description=\"One of rock, paper, or scissors\")     rationale: str = Field(..., description=\"Brief reason for the choice\") In\u00a0[\u00a0]: Copied! <pre>class RoundIterator(Component):\n    io = IO(outputs=[\"round\"])\n\n    def __init__(self, rounds: int = 5, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._rounds = rounds\n        self._i = 0\n\n    async def step(self) -&gt; None:\n        if self._i &gt;= self._rounds:\n            await self.io.close()\n            return\n        self.round = self._i + 1\n        self._i += 1\n\n\nclass Judge(Component):\n    io = IO(inputs=[\"a_choice\", \"b_choice\"], outputs=[\"score_a\", \"score_b\", \"last_winner\"])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self.score_a = 0\n        self.score_b = 0\n\n    async def step(self) -&gt; None:\n        result = self.a_choice.result_against(self.b_choice)\n        if result == Result.lose:\n            self.score_b += 1\n            self.last_winner = \"Player B\"\n        elif result == Result.win:\n            self.score_a += 1\n            self.last_winner = \"Player A\"\n        else:\n            self.last_winner = \"Draw\"\n\n\n# Prompt builder to feed LLMChat\nclass PromptBuilder(Component):\n    io = IO(inputs=[\"round\", \"last_winner\"], outputs=[\"prompt\"])\n\n    def __init__(self, player_label: str, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._label = player_label\n\n    async def step(self) -&gt; None:\n        self.prompt = (\n            f\"Round {self.round}. You are player {self._label}. The last winner was: {self.last_winner}. \"\n            \"Choose your move now.\"\n        )\n</pre> class RoundIterator(Component):     io = IO(outputs=[\"round\"])      def __init__(self, rounds: int = 5, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._rounds = rounds         self._i = 0      async def step(self) -&gt; None:         if self._i &gt;= self._rounds:             await self.io.close()             return         self.round = self._i + 1         self._i += 1   class Judge(Component):     io = IO(inputs=[\"a_choice\", \"b_choice\"], outputs=[\"score_a\", \"score_b\", \"last_winner\"])      def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self.score_a = 0         self.score_b = 0      async def step(self) -&gt; None:         result = self.a_choice.result_against(self.b_choice)         if result == Result.lose:             self.score_b += 1             self.last_winner = \"Player B\"         elif result == Result.win:             self.score_a += 1             self.last_winner = \"Player A\"         else:             self.last_winner = \"Draw\"   # Prompt builder to feed LLMChat class PromptBuilder(Component):     io = IO(inputs=[\"round\", \"last_winner\"], outputs=[\"prompt\"])      def __init__(self, player_label: str, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._label = player_label      async def step(self) -&gt; None:         self.prompt = (             f\"Round {self.round}. You are player {self._label}. The last winner was: {self.last_winner}. \"             \"Choose your move now.\"         ) In\u00a0[\u00a0]: Copied! <pre>system_prompt = (\n    \"You are a rock-paper-scissors agent. Given the prompt, respond strictly as JSON with keys 'choice' and 'rationale'. \"\n    \"The 'choice' must be exactly one of: rock, paper, or scissors. You will be told who the winner was in the last round. \"\n    \"Your rival is another rock-paper-scissors from a rival provider, who may try to trick you. Be strategic in your choice.\"\n)\n\n# Components: set initial values on prompt builders to resolve model circularity\niterator = RoundIterator(name=\"iterator\", rounds=10)\nbuilder_a = PromptBuilder(name=\"builder_a\", player_label=\"A\", initial_values={\"last_winner\": [\"\"]})\nbuilder_b = PromptBuilder(name=\"builder_b\", player_label=\"B\", initial_values={\"last_winner\": [\"\"]})\n\nllm_a = LLMChat(\n    name=\"llm_a\",\n    system_prompt=system_prompt,\n    llm=\"llama_index.llms.openai.OpenAI\",\n    llm_kwargs={\"model\": \"gpt-5-mini\", \"temperature\": 0.9},\n    response_model=PlayerDecision,\n    expand_response=True,  # emits llm_a.choice and llm_a.rationale\n    context_window=3,\n)\n\nllm_b = LLMChat(\n    name=\"llm_b\",\n    system_prompt=system_prompt,\n    llm=\"llama_index.llms.gemini.Gemini\",\n    llm_kwargs={\"model\": \"models/gemini-2.5-flash\", \"temperature\": 0.9},\n    response_model=PlayerDecision,\n    expand_response=True,\n    context_window=3,\n)\n\njudge = Judge(name=\"judge\")\n\nconnect = lambda src, dst: AsyncioConnector(spec=ConnectorSpec(source=src, target=dst))\n\nprocess = LocalProcess(\n    components=[iterator, builder_a, builder_b, llm_a, llm_b, judge],\n    connectors=[\n        # Broadcast tick/round\n        connect(\"iterator.round\", \"builder_a.round\"),\n        connect(\"iterator.round\", \"builder_b.round\"),\n        # Feed prompts into LLMs\n        connect(\"builder_a.prompt\", \"llm_a.prompt\"),\n        connect(\"builder_b.prompt\", \"llm_b.prompt\"),\n        # Send choices to judge\n        connect(\"llm_a.choice\", \"judge.a_choice\"),\n        connect(\"llm_b.choice\", \"judge.b_choice\"),\n        # Feed the last winner information back into the prompt builders\n        connect(\"judge.last_winner\", \"builder_a.last_winner\"),\n        connect(\"judge.last_winner\", \"builder_b.last_winner\"),\n    ],\n)\n</pre> system_prompt = (     \"You are a rock-paper-scissors agent. Given the prompt, respond strictly as JSON with keys 'choice' and 'rationale'. \"     \"The 'choice' must be exactly one of: rock, paper, or scissors. You will be told who the winner was in the last round. \"     \"Your rival is another rock-paper-scissors from a rival provider, who may try to trick you. Be strategic in your choice.\" )  # Components: set initial values on prompt builders to resolve model circularity iterator = RoundIterator(name=\"iterator\", rounds=10) builder_a = PromptBuilder(name=\"builder_a\", player_label=\"A\", initial_values={\"last_winner\": [\"\"]}) builder_b = PromptBuilder(name=\"builder_b\", player_label=\"B\", initial_values={\"last_winner\": [\"\"]})  llm_a = LLMChat(     name=\"llm_a\",     system_prompt=system_prompt,     llm=\"llama_index.llms.openai.OpenAI\",     llm_kwargs={\"model\": \"gpt-5-mini\", \"temperature\": 0.9},     response_model=PlayerDecision,     expand_response=True,  # emits llm_a.choice and llm_a.rationale     context_window=3, )  llm_b = LLMChat(     name=\"llm_b\",     system_prompt=system_prompt,     llm=\"llama_index.llms.gemini.Gemini\",     llm_kwargs={\"model\": \"models/gemini-2.5-flash\", \"temperature\": 0.9},     response_model=PlayerDecision,     expand_response=True,     context_window=3, )  judge = Judge(name=\"judge\")  connect = lambda src, dst: AsyncioConnector(spec=ConnectorSpec(source=src, target=dst))  process = LocalProcess(     components=[iterator, builder_a, builder_b, llm_a, llm_b, judge],     connectors=[         # Broadcast tick/round         connect(\"iterator.round\", \"builder_a.round\"),         connect(\"iterator.round\", \"builder_b.round\"),         # Feed prompts into LLMs         connect(\"builder_a.prompt\", \"llm_a.prompt\"),         connect(\"builder_b.prompt\", \"llm_b.prompt\"),         # Send choices to judge         connect(\"llm_a.choice\", \"judge.a_choice\"),         connect(\"llm_b.choice\", \"judge.b_choice\"),         # Feed the last winner information back into the prompt builders         connect(\"judge.last_winner\", \"builder_a.last_winner\"),         connect(\"judge.last_winner\", \"builder_b.last_winner\"),     ], ) In\u00a0[\u00a0]: Copied! <pre># Run the process\nasync with process:\n    await process.run()\n</pre> # Run the process async with process:     await process.run() In\u00a0[\u00a0]: Copied! <pre>print(f\"Final scores \u2014 A: {judge.score_a}, B: {judge.score_b}\")\n</pre> print(f\"Final scores \u2014 A: {judge.score_a}, B: {judge.score_b}\")","tags":["llm"]},{"location":"examples/demos/llm/003_rock_paper_scissors/rock-paper-scissors/#rock-paper-scissors","title":"Rock Paper Scissors\u00b6","text":"<p>This model contains two LLM components (one OpenAI, one Gemini), which will play rock-paper-scissors against each other. A separate <code>Judge</code> component will compute the winner and keep track of the running total across rounds.</p> <p>To run this model you will need to set the <code>OPENAI_API_KEY</code> and <code>GOOGLE_API_KEY</code> environment variables, and install the <code>llama-index-llms-gemini</code> package from PyPI.</p> <p>The overall model looks like this:</p> <p></p>","tags":["llm"]},{"location":"examples/demos/llm/004_image_processing/local-and-remote-image-processing/","title":"Local and Remote Image Processing","text":"In\u00a0[\u00a0]: Copied! <pre>!pip install torchvision pillow requests\n</pre> !pip install torchvision pillow requests In\u00a0[\u00a0]: Copied! <pre>import os\nfrom getpass import getpass\nfrom io import BytesIO\nimport typing as _t\nfrom datetime import time\n\nimport pandas as pd\nfrom pydantic import BaseModel, ConfigDict, AnyUrl\nfrom PIL import Image\nimport httpx\nfrom torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n\nfrom torchvision import transforms\n\nfrom plugboard.component import Component\n\nfrom plugboard.connector import AsyncioConnector, ConnectorBuilder\nfrom plugboard.component import IOController as IO\nfrom plugboard.schemas import ComponentArgsDict, ConnectorSpec\nfrom plugboard.process import LocalProcess\nfrom plugboard.library import FileReader, FileWriter, LLMImageProcessor\nfrom plugboard.events import Event, EventConnectorBuilder\n</pre> import os from getpass import getpass from io import BytesIO import typing as _t from datetime import time  import pandas as pd from pydantic import BaseModel, ConfigDict, AnyUrl from PIL import Image import httpx from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights  from torchvision import transforms  from plugboard.component import Component  from plugboard.connector import AsyncioConnector, ConnectorBuilder from plugboard.component import IOController as IO from plugboard.schemas import ComponentArgsDict, ConnectorSpec from plugboard.process import LocalProcess from plugboard.library import FileReader, FileWriter, LLMImageProcessor from plugboard.events import Event, EventConnectorBuilder In\u00a0[\u00a0]: Copied! <pre>if \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n</pre> if \"OPENAI_API_KEY\" not in os.environ:     os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \") In\u00a0[\u00a0]: Copied! <pre>class LoadImage(Component):\n    \"\"\"Loads an image from a URL\"\"\"\n\n    io = IO(inputs=[\"url\"], outputs=[\"image\"])\n\n    async def step(self) -&gt; None:\n        headers = {\n            \"User-Agent\": \"PlugboardExample/1.0 (https://docs.plugboard.dev, hello@plugboard.dev)\"\n        }\n        async with httpx.AsyncClient() as client:\n            r = await client.get(self.url, headers=headers, follow_redirects=True)\n            r.raise_for_status()\n\n        self.image = Image.open(BytesIO(r.content)).convert(\"RGB\")\n\n\nclass LocalModel(Component):\n    \"\"\"Passes an image into a MobileNetV3 model\"\"\"\n\n    io = IO(inputs=[\"image\"], outputs=[\"classification\"])\n\n    async def init(self) -&gt; None:\n        self._model = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n        self._categories = MobileNet_V3_Small_Weights.IMAGENET1K_V1.meta[\"categories\"]\n        self._model.eval()\n        self._transform = transforms.Compose(\n            [\n                transforms.Resize((224, 224)),  # MobileNetV3 expects 224x224 input\n                transforms.ToTensor(),  # Convert PIL Image to torch.Tensor (CHW format, [0.0,1.0] range)\n                transforms.Normalize(\n                    mean=[0.485, 0.456, 0.406],  # Normalize to ImageNet means\n                    std=[0.229, 0.224, 0.225],  # Normalize to ImageNet stds\n                ),\n            ]\n        )\n\n    async def step(self) -&gt; None:\n        tensor_image = self._transform(self.image)\n        batch_tensor = tensor_image.unsqueeze(0)  # Add batch dimension\n        outputs = self._model(batch_tensor).squeeze(0).softmax(0)\n        self.classification = dict(zip(self._categories, outputs.detach().numpy()))\n</pre> class LoadImage(Component):     \"\"\"Loads an image from a URL\"\"\"      io = IO(inputs=[\"url\"], outputs=[\"image\"])      async def step(self) -&gt; None:         headers = {             \"User-Agent\": \"PlugboardExample/1.0 (https://docs.plugboard.dev, hello@plugboard.dev)\"         }         async with httpx.AsyncClient() as client:             r = await client.get(self.url, headers=headers, follow_redirects=True)             r.raise_for_status()          self.image = Image.open(BytesIO(r.content)).convert(\"RGB\")   class LocalModel(Component):     \"\"\"Passes an image into a MobileNetV3 model\"\"\"      io = IO(inputs=[\"image\"], outputs=[\"classification\"])      async def init(self) -&gt; None:         self._model = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)         self._categories = MobileNet_V3_Small_Weights.IMAGENET1K_V1.meta[\"categories\"]         self._model.eval()         self._transform = transforms.Compose(             [                 transforms.Resize((224, 224)),  # MobileNetV3 expects 224x224 input                 transforms.ToTensor(),  # Convert PIL Image to torch.Tensor (CHW format, [0.0,1.0] range)                 transforms.Normalize(                     mean=[0.485, 0.456, 0.406],  # Normalize to ImageNet means                     std=[0.229, 0.224, 0.225],  # Normalize to ImageNet stds                 ),             ]         )      async def step(self) -&gt; None:         tensor_image = self._transform(self.image)         batch_tensor = tensor_image.unsqueeze(0)  # Add batch dimension         outputs = self._model(batch_tensor).squeeze(0).softmax(0)         self.classification = dict(zip(self._categories, outputs.detach().numpy())) In\u00a0[\u00a0]: Copied! <pre>class MatchData(BaseModel):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    url: AnyUrl\n\n\nclass MatchEvent(Event):\n    type: _t.ClassVar[str] = \"match\"\n    data: MatchData\n\n\nclass NonMatchData(BaseModel):\n    classification: dict[str, float]\n    url: AnyUrl\n\n\nclass NonMatchEvent(Event):\n    type: _t.ClassVar[str] = \"non_match\"\n    data: NonMatchData\n</pre> class MatchData(BaseModel):     model_config = ConfigDict(arbitrary_types_allowed=True)     url: AnyUrl   class MatchEvent(Event):     type: _t.ClassVar[str] = \"match\"     data: MatchData   class NonMatchData(BaseModel):     classification: dict[str, float]     url: AnyUrl   class NonMatchEvent(Event):     type: _t.ClassVar[str] = \"non_match\"     data: NonMatchData In\u00a0[\u00a0]: Copied! <pre>class CheckClassification(Component):\n    \"\"\"Checks for a classification match.\"\"\"\n\n    io = IO(inputs=[\"url\", \"classification\"], output_events=[MatchEvent, NonMatchEvent])\n\n    def __init__(\n        self, classes: list[str], threshold: float = 0.5, **kwargs: _t.Unpack[ComponentArgsDict]\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self._class_names = classes\n        self._threshold = threshold\n\n    async def step(self) -&gt; None:\n        match = False\n        for c in self._class_names:\n            if self.classification.get(c, 0) &gt;= self._threshold:\n                match = True\n                break\n        if match:\n            self.io.queue_event(MatchEvent(source=self.name, data=MatchData(url=self.url)))\n        else:\n            self.io.queue_event(\n                NonMatchEvent(\n                    source=self.name,\n                    data=NonMatchData(classification=self.classification, url=self.url),\n                )\n            )\n\n\nclass MatchAdapter(Component):\n    \"\"\"Listens for match events and passes them on for further processing.\"\"\"\n\n    io = IO(outputs=[\"url\"], input_events=[MatchEvent])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._buffer = []\n\n    @MatchEvent.handler\n    async def handle_match(self, event: MatchEvent):\n        self._buffer.append(event.data)\n\n    async def step(self) -&gt; None:\n        if self._buffer:\n            data = self._buffer.pop(0)\n            self.url = str(data.url)\n\n\nclass NonMatchAdapter(Component):\n    \"\"\"Listens for non-match events and passes them on for further processing.\"\"\"\n\n    io = IO(outputs=[\"classification\", \"url\"], input_events=[NonMatchEvent])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._buffer = []\n\n    @NonMatchEvent.handler\n    async def handle_non_match(self, event: NonMatchEvent):\n        self._buffer.append(event.data)\n\n    async def step(self) -&gt; None:\n        if self._buffer:\n            data = self._buffer.pop(0)\n            self.classification = data.classification\n            self.url = str(data.url)\n</pre> class CheckClassification(Component):     \"\"\"Checks for a classification match.\"\"\"      io = IO(inputs=[\"url\", \"classification\"], output_events=[MatchEvent, NonMatchEvent])      def __init__(         self, classes: list[str], threshold: float = 0.5, **kwargs: _t.Unpack[ComponentArgsDict]     ) -&gt; None:         super().__init__(**kwargs)         self._class_names = classes         self._threshold = threshold      async def step(self) -&gt; None:         match = False         for c in self._class_names:             if self.classification.get(c, 0) &gt;= self._threshold:                 match = True                 break         if match:             self.io.queue_event(MatchEvent(source=self.name, data=MatchData(url=self.url)))         else:             self.io.queue_event(                 NonMatchEvent(                     source=self.name,                     data=NonMatchData(classification=self.classification, url=self.url),                 )             )   class MatchAdapter(Component):     \"\"\"Listens for match events and passes them on for further processing.\"\"\"      io = IO(outputs=[\"url\"], input_events=[MatchEvent])      def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._buffer = []      @MatchEvent.handler     async def handle_match(self, event: MatchEvent):         self._buffer.append(event.data)      async def step(self) -&gt; None:         if self._buffer:             data = self._buffer.pop(0)             self.url = str(data.url)   class NonMatchAdapter(Component):     \"\"\"Listens for non-match events and passes them on for further processing.\"\"\"      io = IO(outputs=[\"classification\", \"url\"], input_events=[NonMatchEvent])      def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._buffer = []      @NonMatchEvent.handler     async def handle_non_match(self, event: NonMatchEvent):         self._buffer.append(event.data)      async def step(self) -&gt; None:         if self._buffer:             data = self._buffer.pop(0)             self.classification = data.classification             self.url = str(data.url) In\u00a0[\u00a0]: Copied! <pre>class TimeReading(BaseModel):\n    time: str\n</pre> class TimeReading(BaseModel):     time: str In\u00a0[\u00a0]: Copied! <pre>connect = lambda src, dst: AsyncioConnector(spec=ConnectorSpec(source=src, target=dst))\n</pre> connect = lambda src, dst: AsyncioConnector(spec=ConnectorSpec(source=src, target=dst)) In\u00a0[\u00a0]: Copied! <pre># Create CSV with some image URLs\nimages_df = pd.DataFrame(\n    {\n        \"url\": [\n            # This is a clock\n            \"https://images.unsplash.com/photo-1541480601022-2308c0f02487?ixlib=rb-4.1.0&amp;q=85&amp;fm=jpg&amp;crop=entropy&amp;cs=srgb\",\n            # Not a clock (Train)\n            \"https://images.unsplash.com/photo-1535535112387-56ffe8db21ff?ixlib=rb-4.1.0&amp;q=85&amp;fm=jpg&amp;crop=entropy&amp;cs=srgb\",\n            # This is a clock\n            \"https://images.unsplash.com/photo-1563861826100-9cb868fdbe1c?ixlib=rb-4.1.0&amp;q=85&amp;fm=jpg&amp;crop=entropy&amp;cs=srgb\",\n            # Not a clock (Dog)\n            \"https://images.unsplash.com/photo-1530281700549-e82e7bf110d6?ixlib=rb-4.1.0&amp;q=85&amp;fm=jpg&amp;crop=entropy&amp;cs=srgb\",\n        ]\n    }\n)\nimages_df.to_csv(\"images.csv\", index=False)\n\n# Define Components\ncomponents = [\n    FileReader(name=\"reader\", path=\"images.csv\", field_names=[\"url\"]),\n    LoadImage(name=\"loader\"),\n    LocalModel(name=\"classifier\"),\n    CheckClassification(name=\"checker\", classes=[\"analog clock\", \"wall clock\", \"digital clock\"]),\n    MatchAdapter(name=\"match_adapter\"),\n    LLMImageProcessor(\n        name=\"llm_processor\",\n        prompt=\"Read the time on the clock\",\n        response_model=TimeReading,\n        expand_response=True,\n        llm_kwargs={\"model\": \"gpt-4o-mini\"},\n    ),\n    FileWriter(name=\"match_writer\", path=\"matches.csv\", field_names=[\"time\", \"url\"]),\n    NonMatchAdapter(name=\"non_match_adapter\"),\n    FileWriter(\n        name=\"non_match_writer\", path=\"non_matches.csv\", field_names=[\"classification\", \"url\"]\n    ),\n]\n\n# Define Connectors\nconnectors = [\n    connect(\"reader.url\", \"loader.url\"),\n    connect(\"loader.image\", \"classifier.image\"),\n    connect(\"reader.url\", \"checker.url\"),\n    connect(\"classifier.classification\", \"checker.classification\"),\n    # Adapter to Processor/Writer\n    connect(\"match_adapter.url\", \"llm_processor.image\"),\n    connect(\"llm_processor.time\", \"match_writer.time\"),\n    connect(\"match_adapter.url\", \"match_writer.url\"),\n    connect(\"non_match_adapter.classification\", \"non_match_writer.classification\"),\n    connect(\"non_match_adapter.url\", \"non_match_writer.url\"),\n]\n\n# Event Connectors\nbuilder = ConnectorBuilder(connector_cls=AsyncioConnector)\nevent_builder = EventConnectorBuilder(connector_builder=builder)\nevent_connectors = list(event_builder.build(components).values())\n\n# Define Process\nprocess = LocalProcess(components=components, connectors=connectors + event_connectors)\n\nasync with process:\n    await process.run()\n</pre> # Create CSV with some image URLs images_df = pd.DataFrame(     {         \"url\": [             # This is a clock             \"https://images.unsplash.com/photo-1541480601022-2308c0f02487?ixlib=rb-4.1.0&amp;q=85&amp;fm=jpg&amp;crop=entropy&amp;cs=srgb\",             # Not a clock (Train)             \"https://images.unsplash.com/photo-1535535112387-56ffe8db21ff?ixlib=rb-4.1.0&amp;q=85&amp;fm=jpg&amp;crop=entropy&amp;cs=srgb\",             # This is a clock             \"https://images.unsplash.com/photo-1563861826100-9cb868fdbe1c?ixlib=rb-4.1.0&amp;q=85&amp;fm=jpg&amp;crop=entropy&amp;cs=srgb\",             # Not a clock (Dog)             \"https://images.unsplash.com/photo-1530281700549-e82e7bf110d6?ixlib=rb-4.1.0&amp;q=85&amp;fm=jpg&amp;crop=entropy&amp;cs=srgb\",         ]     } ) images_df.to_csv(\"images.csv\", index=False)  # Define Components components = [     FileReader(name=\"reader\", path=\"images.csv\", field_names=[\"url\"]),     LoadImage(name=\"loader\"),     LocalModel(name=\"classifier\"),     CheckClassification(name=\"checker\", classes=[\"analog clock\", \"wall clock\", \"digital clock\"]),     MatchAdapter(name=\"match_adapter\"),     LLMImageProcessor(         name=\"llm_processor\",         prompt=\"Read the time on the clock\",         response_model=TimeReading,         expand_response=True,         llm_kwargs={\"model\": \"gpt-4o-mini\"},     ),     FileWriter(name=\"match_writer\", path=\"matches.csv\", field_names=[\"time\", \"url\"]),     NonMatchAdapter(name=\"non_match_adapter\"),     FileWriter(         name=\"non_match_writer\", path=\"non_matches.csv\", field_names=[\"classification\", \"url\"]     ), ]  # Define Connectors connectors = [     connect(\"reader.url\", \"loader.url\"),     connect(\"loader.image\", \"classifier.image\"),     connect(\"reader.url\", \"checker.url\"),     connect(\"classifier.classification\", \"checker.classification\"),     # Adapter to Processor/Writer     connect(\"match_adapter.url\", \"llm_processor.image\"),     connect(\"llm_processor.time\", \"match_writer.time\"),     connect(\"match_adapter.url\", \"match_writer.url\"),     connect(\"non_match_adapter.classification\", \"non_match_writer.classification\"),     connect(\"non_match_adapter.url\", \"non_match_writer.url\"), ]  # Event Connectors builder = ConnectorBuilder(connector_cls=AsyncioConnector) event_builder = EventConnectorBuilder(connector_builder=builder) event_connectors = list(event_builder.build(components).values())  # Define Process process = LocalProcess(components=components, connectors=connectors + event_connectors)  async with process:     await process.run() <p>Now open the output CSVs to see the time read from the clock images.</p> In\u00a0[\u00a0]: Copied! <pre>!cat matches.csv \n</pre> !cat matches.csv","tags":["llm"]},{"location":"examples/demos/llm/004_image_processing/local-and-remote-image-processing/#local-and-remote-image-processing","title":"Local and Remote Image Processing\u00b6","text":"<p>This example demonstrates a hybrid AI pipeline that combines a lightweight local model with a powerful remote LLM.</p> <p>The Goal:</p> <p>We want to process a stream of images, identify which ones contain clocks, and then read the time from those clocks.</p> <p>The Problem:</p> <p>Sending every image to a large multimodal model (like OpenAI) is expensive and slow.</p> <p>The Solution:</p> <ol> <li>Use a fast, local computer vision model (MobileNetV3) to classify images.</li> <li>Filter the stream:<ul> <li>If it's a clock -&gt; Send to GPT-5-nano to read the time.</li> <li>If it's not a clock -&gt; Log it and skip the expensive call.</li> </ul> </li> </ol> <p>This architecture demonstrates Event-driven routing in Plugboard, where data flows to different downstream components based on analysis results.</p> <p>The overall model will look like this:</p> <p></p>","tags":["llm"]},{"location":"examples/demos/llm/004_image_processing/local-and-remote-image-processing/#1-define-local-components","title":"1. Define Local Components\u00b6","text":"<p>First, we define the components that run locally.</p> <ul> <li><code>LoadImage</code>: Downloads an image from a URL and converts it to a format suitable for processing.</li> <li><code>LocalModel</code>: Uses <code>torchvision</code>'s pre-trained MobileNetV3 to classify the image. This runs entirely on your machine (or CPU/GPU) and is very fast.</li> </ul>","tags":["llm"]},{"location":"examples/demos/llm/004_image_processing/local-and-remote-image-processing/#2-define-events","title":"2. Define Events\u00b6","text":"<p>We define two types of events to handle the routing logic:</p> <ul> <li><code>MatchEvent</code>: Fired when the image matches our criteria (it is a clock). It carries the image data.</li> <li><code>NonMatchEvent</code>: Fired when the image does not match. It carries the classification results for logging.</li> </ul> <p>We use Pydantic models (<code>MatchData</code>, <code>NonMatchData</code>) to strictly type the event payloads.</p>","tags":["llm"]},{"location":"examples/demos/llm/004_image_processing/local-and-remote-image-processing/#3-logic-and-adapters","title":"3. Logic and Adapters\u00b6","text":"<p>Now we define the components that use these events.</p> <ul> <li><code>CheckClassification</code>: Takes the classification result from <code>LocalModel</code>. If the probability of any target class (e.g., \"analog clock\") is above a threshold, it fires a <code>MatchEvent</code>. Otherwise, it fires a <code>NonMatchEvent</code>.</li> <li><code>MatchAdapter</code> &amp; <code>NonMatchAdapter</code>: These components subscribe to the events and convert the event payload back into a standard output stream. This allows us to connect them to downstream components like <code>LLMImageProcessor</code> or <code>FileWriter</code>.</li> </ul> <p>Note: <code>MatchAdapter</code> also passes on the URL of time image to the <code>LLMImageProcessor</code>.</p>","tags":["llm"]},{"location":"examples/demos/llm/004_image_processing/local-and-remote-image-processing/#4-llm-configuration","title":"4. LLM Configuration\u00b6","text":"<p>We define a Pydantic model for the LLM's response. This ensures we get structured data (JSON) back from the model, rather than just free text.</p>","tags":["llm"]},{"location":"examples/demos/llm/004_image_processing/local-and-remote-image-processing/#5-define-and-run-process","title":"5. Define and Run Process\u00b6","text":"<p>Finally, we wire everything together in a <code>LocalProcess</code>.</p> <ol> <li>Input: We create a CSV with URLs of images (some clocks, some not).</li> <li>Pipeline:<ul> <li><code>FileReader</code> -&gt; <code>LoadImage</code> -&gt; <code>LocalModel</code> -&gt; <code>CheckClassification</code></li> <li><code>CheckClassification</code> fires events.</li> <li><code>MatchEvent</code> -&gt; <code>MatchAdapter</code> -&gt; <code>LLMImageProcessor</code> -&gt; <code>FileWriter</code> (matches.csv)</li> <li><code>NonMatchEvent</code> -&gt; <code>NonMatchAdapter</code> -&gt; <code>FileWriter</code> (non_matches.csv)</li> </ul> </li> </ol>","tags":["llm"]},{"location":"examples/demos/physics-models/001-hot-water-tank/hot-water-tank/","title":"Hot water tank model","text":"In\u00a0[\u00a0]: Copied! <pre># Install plugboard and dependencies for Google Colab\n!pip install -q plugboard plotly\n</pre> # Install plugboard and dependencies for Google Colab !pip install -q plugboard plotly In\u00a0[\u00a0]: Copied! <pre>import typing as _t\n\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.component import Component\nfrom plugboard.component import IOController as IO\nfrom plugboard.schemas import ComponentArgsDict, ConnectorSpec\nfrom plugboard.process import LocalProcess\nfrom plugboard.library import FileWriter\n</pre> import typing as _t  from plugboard.connector import AsyncioConnector from plugboard.component import Component from plugboard.component import IOController as IO from plugboard.schemas import ComponentArgsDict, ConnectorSpec from plugboard.process import LocalProcess from plugboard.library import FileWriter In\u00a0[\u00a0]: Copied! <pre>WATER_SPECIFIC_HEAT = 4186  # J/(kg\u00b0C)\nWATER_DENSITY = 1.0  # kg/L\n</pre> WATER_SPECIFIC_HEAT = 4186  # J/(kg\u00b0C) WATER_DENSITY = 1.0  # kg/L In\u00a0[\u00a0]: Copied! <pre>class HotWaterTank(Component):\n    \"\"\"This component represents an insulated hot water tank with an on/off heating element.\"\"\"\n\n    io = IO(inputs=[\"heating_element\", \"prev_temperature\"], outputs=[\"temperature\"])\n\n    def __init__(\n        self,\n        volume: float,\n        heater_power: float,\n        insulation_r: float,\n        ambient_temp: float,\n        delta_t: float = 60,\n        **kwargs: _t.Unpack[ComponentArgsDict],\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        # Set the initial running total to 0\n        self._heater_power_watts = heater_power * 1000  # W\n        self._water_mass = volume * WATER_DENSITY  # kg\n        self._heat_capacity = self._water_mass * WATER_SPECIFIC_HEAT  # J/\u00b0C\n        self._delta_t = delta_t  # s\n        self._insulation_r = insulation_r  # \u00b0C/W\n        self._ambient_temp = ambient_temp  # \u00b0C\n\n    async def step(self) -&gt; None:\n        # Apply heater power to the water\n        self.temperature = self.prev_temperature\n        if self.heating_element:\n            self.temperature += self._heater_power_watts * self._delta_t / self._heat_capacity\n        # Apply heat loss to the environment\n        heat_loss = (\n            (self.prev_temperature - self._ambient_temp) / self._insulation_r * self._delta_t\n        )\n        self.temperature -= heat_loss / self._heat_capacity\n</pre> class HotWaterTank(Component):     \"\"\"This component represents an insulated hot water tank with an on/off heating element.\"\"\"      io = IO(inputs=[\"heating_element\", \"prev_temperature\"], outputs=[\"temperature\"])      def __init__(         self,         volume: float,         heater_power: float,         insulation_r: float,         ambient_temp: float,         delta_t: float = 60,         **kwargs: _t.Unpack[ComponentArgsDict],     ) -&gt; None:         super().__init__(**kwargs)         # Set the initial running total to 0         self._heater_power_watts = heater_power * 1000  # W         self._water_mass = volume * WATER_DENSITY  # kg         self._heat_capacity = self._water_mass * WATER_SPECIFIC_HEAT  # J/\u00b0C         self._delta_t = delta_t  # s         self._insulation_r = insulation_r  # \u00b0C/W         self._ambient_temp = ambient_temp  # \u00b0C      async def step(self) -&gt; None:         # Apply heater power to the water         self.temperature = self.prev_temperature         if self.heating_element:             self.temperature += self._heater_power_watts * self._delta_t / self._heat_capacity         # Apply heat loss to the environment         heat_loss = (             (self.prev_temperature - self._ambient_temp) / self._insulation_r * self._delta_t         )         self.temperature -= heat_loss / self._heat_capacity In\u00a0[\u00a0]: Copied! <pre>class ThermostatController(Component):\n    \"\"\"This component represents a thermostat with hysteresis.\"\"\"\n\n    io = IO(inputs=[\"setpoint\", \"temperature\"], outputs=[\"heating_element\"])\n\n    def __init__(self, hysteresis: float, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._hysteresis = hysteresis\n\n    async def step(self) -&gt; None:\n        if self.temperature &lt; self.setpoint - self._hysteresis:\n            self.heating_element = True\n        elif self.temperature &gt; self.setpoint + self._hysteresis:\n            self.heating_element = False\n</pre> class ThermostatController(Component):     \"\"\"This component represents a thermostat with hysteresis.\"\"\"      io = IO(inputs=[\"setpoint\", \"temperature\"], outputs=[\"heating_element\"])      def __init__(self, hysteresis: float, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:         super().__init__(**kwargs)         self._hysteresis = hysteresis      async def step(self) -&gt; None:         if self.temperature &lt; self.setpoint - self._hysteresis:             self.heating_element = True         elif self.temperature &gt; self.setpoint + self._hysteresis:             self.heating_element = False <p>We'll use a <code>Constant</code> value to represent the setpoint and trigger the rest of the model.</p> In\u00a0[\u00a0]: Copied! <pre>class Constant(Component):\n    \"\"\"This component represents a constant value.\"\"\"\n\n    io = IO(outputs=[\"value\"])\n\n    def __init__(\n        self, value: float, n_iterations: int, **kwargs: _t.Unpack[ComponentArgsDict]\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self.value = value\n        self._remaining_iterations = n_iterations\n\n    async def step(self) -&gt; None:\n        self._remaining_iterations -= 1\n        if self._remaining_iterations &lt;= 0:\n            await self.io.close()\n</pre> class Constant(Component):     \"\"\"This component represents a constant value.\"\"\"      io = IO(outputs=[\"value\"])      def __init__(         self, value: float, n_iterations: int, **kwargs: _t.Unpack[ComponentArgsDict]     ) -&gt; None:         super().__init__(**kwargs)         self.value = value         self._remaining_iterations = n_iterations      async def step(self) -&gt; None:         self._remaining_iterations -= 1         if self._remaining_iterations &lt;= 0:             await self.io.close() In\u00a0[\u00a0]: Copied! <pre>setpoint = Constant(name=\"setpoint\", value=60, n_iterations=24 * 60)\ntank = HotWaterTank(\n    name=\"tank\",\n    initial_values={\"prev_temperature\": [58], \"heating_element\": [False]},\n    volume=150,\n    heater_power=1.1,\n    insulation_r=0.9,\n    ambient_temp=20,\n)\nthermostat = ThermostatController(name=\"controller\", hysteresis=1)\nsave = FileWriter(\n    name=\"save\", path=\"temperature.csv\", field_names=[\"heater\", \"temperature\", \"setpoint\"]\n)\n</pre> setpoint = Constant(name=\"setpoint\", value=60, n_iterations=24 * 60) tank = HotWaterTank(     name=\"tank\",     initial_values={\"prev_temperature\": [58], \"heating_element\": [False]},     volume=150,     heater_power=1.1,     insulation_r=0.9,     ambient_temp=20, ) thermostat = ThermostatController(name=\"controller\", hysteresis=1) save = FileWriter(     name=\"save\", path=\"temperature.csv\", field_names=[\"heater\", \"temperature\", \"setpoint\"] ) <p>Now connect the components together in a <code>LocalProcess</code>.</p> In\u00a0[\u00a0]: Copied! <pre>process = LocalProcess(\n    components=[setpoint, tank, thermostat, save],\n    connectors=[\n        # Connect setpoint to controller\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"setpoint.value\", target=\"controller.setpoint\"),\n        ),\n        # Connect controller to tank\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"controller.heating_element\", target=\"tank.heating_element\"),\n        ),\n        # Connect tank to controller\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"tank.temperature\", target=\"controller.temperature\"),\n        ),\n        # Connect tank to itself to save the previous temperature\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"tank.temperature\", target=\"tank.prev_temperature\"),\n        ),\n        # Connect tank, controller and setpoint to save\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"tank.temperature\", target=\"save.temperature\"),\n        ),\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"controller.heating_element\", target=\"save.heater\"),\n        ),\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"setpoint.value\", target=\"save.setpoint\"),\n        ),\n    ],\n)\n</pre> process = LocalProcess(     components=[setpoint, tank, thermostat, save],     connectors=[         # Connect setpoint to controller         AsyncioConnector(             spec=ConnectorSpec(source=\"setpoint.value\", target=\"controller.setpoint\"),         ),         # Connect controller to tank         AsyncioConnector(             spec=ConnectorSpec(source=\"controller.heating_element\", target=\"tank.heating_element\"),         ),         # Connect tank to controller         AsyncioConnector(             spec=ConnectorSpec(source=\"tank.temperature\", target=\"controller.temperature\"),         ),         # Connect tank to itself to save the previous temperature         AsyncioConnector(             spec=ConnectorSpec(source=\"tank.temperature\", target=\"tank.prev_temperature\"),         ),         # Connect tank, controller and setpoint to save         AsyncioConnector(             spec=ConnectorSpec(source=\"tank.temperature\", target=\"save.temperature\"),         ),         AsyncioConnector(             spec=ConnectorSpec(source=\"controller.heating_element\", target=\"save.heater\"),         ),         AsyncioConnector(             spec=ConnectorSpec(source=\"setpoint.value\", target=\"save.setpoint\"),         ),     ], ) <p>Now we can initialise and run the simulation.</p> In\u00a0[\u00a0]: Copied! <pre>async with process:\n    await process.run()\n</pre> async with process:     await process.run() <p>Finally check we have the output data saved in <code>temperature.csv</code>.</p> In\u00a0[\u00a0]: Copied! <pre>try:\n    import pandas as pd\n\n    fig = pd.read_csv(\"temperature.csv\").plot(\n        backend=\"plotly\",\n        y=[\"temperature\", \"setpoint\"],\n        title=\"Temperature vs. Setpoint\",\n        labels={\"index\": \"Time (min)\", \"value\": \"Temperature (\u00b0C)\"},\n    )\nexcept (ImportError, ValueError):\n    print(\"Please install plotly to run this cell.\")\n    fig = None\nfig\n</pre> try:     import pandas as pd      fig = pd.read_csv(\"temperature.csv\").plot(         backend=\"plotly\",         y=[\"temperature\", \"setpoint\"],         title=\"Temperature vs. Setpoint\",         labels={\"index\": \"Time (min)\", \"value\": \"Temperature (\u00b0C)\"},     ) except (ImportError, ValueError):     print(\"Please install plotly to run this cell.\")     fig = None fig","tags":["physics-models"]},{"location":"examples/demos/physics-models/001-hot-water-tank/hot-water-tank/#hot-water-tank-model","title":"Hot water tank model\u00b6","text":"<p>This model demonstrates how Plugboard can be used to connect physics-based models. We'll build a component to simulate the temperature of an insulated hot-water tank, along with another to control the tank's heating element.</p>","tags":["physics-models"]},{"location":"examples/tutorials/event-driven-models/","title":"Event-driven models","text":"<p>So far everything we have built in Plugboard has been a discrete-time model. This means that the whole model advances step-wise, i.e. <code>step</code> gets called on each <code>Component</code>, calculating all of their outputs before advancing the simulation on.</p> <p>In this tutorial we're going to introduce an event-driven model, where data can be passed around between components based on triggers that you can define. Event-based models can be useful in a variety of scenarios, for example when modelling parts moving around a production line, or to trigger expensive computation only when certain conditions are met in the model.</p>","tags":["tutorial","events"]},{"location":"examples/tutorials/event-driven-models/#event-based-model","title":"Event-based model","text":"<p>Here's the model that we're going to build. Given a stream of random numbers, we'll trigger <code>HighEvent</code> whenever the value is above <code>0.8</code> and <code>LowEvent</code> whenever the value is below <code>0.2</code>. This allows us to funnel data into different parts of the model: in this case we'll just save the latest high/low values to a file at each step. In the diagram the dotted lines represent the flow of event data: <code>FindHighLowValues</code> will publish events, while <code>CollectHigh</code> and <code>CollectLow</code> will subscribe to receive high and low events respectively.</p> <pre><code>flowchart LR\n    collect-high@{ shape: rounded, label: CollectHigh&lt;br&gt;**collect-high** } --&gt; save-high@{ shape: rounded, label: FileWriter&lt;br&gt;**save-high** }\n    collect-low@{ shape: rounded, label: CollectLow&lt;br&gt;**collect-low** } --&gt; save-low@{ shape: rounded, label: FileWriter&lt;br&gt;**save-low** }\n    random-generator@{ shape: rounded, label: Random&lt;br&gt;**random-generator** } --&gt; find-high-low@{ shape: rounded, label: FindHighLowValues&lt;br&gt;**find-high-low** }\n    low_event@{ shape: hex, label: LowEvent } -.-&gt; collect-low@{ shape: rounded, label: CollectLow&lt;br&gt;**collect-low** }\n    high_event@{ shape: hex, label: HighEvent } -.-&gt; collect-high@{ shape: rounded, label: CollectHigh&lt;br&gt;**collect-high** }\n    find-high-low@{ shape: rounded, label: FindHighLowValues&lt;br&gt;**find-high-low** } -.-&gt; high_event@{ shape: hex, label: HighEvent }\n    find-high-low@{ shape: rounded, label: FindHighLowValues&lt;br&gt;**find-high-low** } -.-&gt; low_event@{ shape: hex, label: LowEvent }</code></pre>","tags":["tutorial","events"]},{"location":"examples/tutorials/event-driven-models/#defining-events","title":"Defining events","text":"<p>First we need to define the events that are going to get used in the model. Each event needs a name, in this case <code>\"high_event\"</code> and <code>\"low_event\"</code> and a <code>data</code> type associated with it. Use a Pydantic model to define the format of this <code>data</code> field.</p> <pre><code>class ExtremeValue(BaseModel):\n    \"\"\"Data for event_A.\"\"\"\n\n    value: float\n    extreme_type: _t.Literal[\"high\", \"low\"]\n\n\nclass HighEvent(Event):\n    \"\"\"High value event type.\"\"\"\n\n    type: _t.ClassVar[str] = \"high_event\"\n    data: ExtremeValue\n\n\nclass LowEvent(Event):\n    \"\"\"Low value event type.\"\"\"\n\n    type: _t.ClassVar[str] = \"low_event\"\n    data: ExtremeValue\n</code></pre>","tags":["tutorial","events"]},{"location":"examples/tutorials/event-driven-models/#building-components-to-create-and-consume-events","title":"Building components to create and consume events","text":"<p>So far all of our process models have run step-by-step until completion. When a model contains event-driven components, we need a way to tell them to stop at the end of the simulation, otherwise they will stay running and listening for events forever.</p> <p>In this example, our <code>Random</code> component will drive the process by generating input random values. When it has completed <code>iters</code> iterations, we call <code>self.io.close()</code> to stop the model, causing other components in the model to shutdown.</p> <pre><code>class Random(Component):\n    \"\"\"Generates random numbers.\"\"\"\n\n    io = IOController(outputs=[\"value\"])\n\n    def __init__(self, iters: int = 50, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self.max_iters = iters\n        self.completed_iters = 0\n\n    async def step(self) -&gt; None:\n        self.completed_iters += 1\n        self.value = random.random()\n        if self.completed_iters &gt;= self.max_iters:\n            await self.io.close()\n</code></pre> <p>Next, we will define <code>FindHighLowValues</code> to identify high and low values in the stream of random numbers and publish <code>HighEvent</code> and <code>LowEvent</code> respectively.</p> <pre><code>class FindHighLowValues(Component):\n    \"\"\"Publishes an event on high or low values.\"\"\"\n\n    io = IOController(inputs=[\"value\"], output_events=[LowEvent, HighEvent])  # (1)!\n\n    def __init__(\n        self,\n        low_limit: float = 0.2,\n        high_limit: float = 0.8,\n        **kwargs: _t.Unpack[ComponentArgsDict],\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self.low_limit = low_limit\n        self.high_limit = high_limit\n\n    async def step(self) -&gt; None:\n        if self.value &gt;= self.high_limit:\n            self.io.queue_event(  # (2)!\n                HighEvent(\n                    source=self.name, data=ExtremeValue(value=self.value, extreme_type=\"high\")\n                )\n            )\n        if self.value &lt;= self.low_limit:\n            self.io.queue_event(\n                LowEvent(source=self.name, data=ExtremeValue(value=self.value, extreme_type=\"low\"))\n            )\n</code></pre> <ol> <li>See how we use the <code>IOController</code> to declare that this <code>Component</code> will publish events.</li> <li>Use <code>self.io.queue_event</code> to send an event from a <code>Component</code>. Here we are senging the <code>HighEvent</code> or <code>LowEvent</code> depending on the input value.</li> </ol> <p>Finally, we need components to subscribe to these events and process them. Use the <code>Event.handler</code> decorator to identify the method on each <code>Component</code> that will do this processing.</p> <pre><code>class CollectHigh(Component):\n    \"\"\"Collects values from high events.\"\"\"\n\n    io = IOController(input_events=[HighEvent], outputs=[\"value\"])  # (1)!\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self.latest_event: _t.Optional[ExtremeValue] = None\n\n    async def step(self) -&gt; None:\n        self.value = self.latest_event.value if self.latest_event else None\n\n    @HighEvent.handler  # (2)!\n    async def handle_event(self, event: HighEvent) -&gt; None:\n        self.latest_event = event.data\n\n\nclass CollectLow(Component):\n    \"\"\"Collects values from low events.\"\"\"\n\n    io = IOController(input_events=[LowEvent], outputs=[\"value\"])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self.latest_event: _t.Optional[ExtremeValue] = None\n\n    async def step(self) -&gt; None:\n        self.value = self.latest_event.value if self.latest_event else None\n\n    @LowEvent.handler  # (3)!\n    async def handle_event(self, event: LowEvent) -&gt; None:\n        self.latest_event = event.data\n</code></pre> <ol> <li>Specify the events that this <code>Component</code> will subscribe to.</li> <li>Use this decorator to indicate that we handle <code>HighEvent</code> here...</li> <li>...and we handle <code>LowEvent</code> here.</li> </ol> <p>Note</p> <p>In a real model you could define whatever logic you need inside your event handler, e.g. create a file, publish another event, etc. Here we just store the event on an attribute so that its value can be output via the <code>step()</code> method.</p>","tags":["tutorial","events"]},{"location":"examples/tutorials/event-driven-models/#putting-it-all-together","title":"Putting it all together","text":"<p>Now we can create a <code>Process</code> from all these components. The outputs from <code>CollectLow</code> and <code>CollectHigh</code> are connected to separate <code>FileWriter</code> components so that we'll get a CSV file containing the latest high and low values at each step of the simulation.</p> <p>Info</p> <p>We need a few extra lines of code to create connectors for the event-based parts of the model. If you define your process in YAML this will be done automatically for you, but if you are defining the process in code then you will need to use the <code>EventConnectorBuilder</code> to do this.</p> <pre><code>components = [\n    Random(name=\"random-generator\"),\n    FindHighLowValues(name=\"find-high-low\", low_limit=0.2, high_limit=0.8),\n    CollectHigh(name=\"collect-high\"),\n    CollectLow(name=\"collect-low\"),\n    FileWriter(name=\"save-high\", path=\"high.csv\", field_names=[\"value\"]),\n    FileWriter(name=\"save-low\", path=\"low.csv\", field_names=[\"value\"]),\n]\nconnect = lambda in_, out_: AsyncioConnector(spec=ConnectorSpec(source=in_, target=out_))\nconnectors = [  # (1)!\n    connect(\"random-generator.value\", \"find-high-low.value\"),\n    connect(\"collect-high.value\", \"save-high.value\"),\n    connect(\"collect-low.value\", \"save-low.value\"),\n]\nconnector_builder = ConnectorBuilder(connector_cls=AsyncioConnector)  # (2)!\nevent_connector_builder = EventConnectorBuilder(connector_builder=connector_builder)\nevent_connectors = list(event_connector_builder.build(components).values())\n\nprocess = LocalProcess(\n    components=components,\n    connectors=connectors + event_connectors,\n)\n\nasync with process:\n    await process.run()\n</code></pre> <ol> <li>These connectors are for the normal, non-event driven parts of the model and connect <code>Component</code>` inputs and outputs.</li> <li>These lines will set up connectors for the events in the model.</li> </ol> <p>Take a look at the <code>high.csv</code> and <code>low.csv</code> files: the first few rows will usually be empty, and then as soon as high or low values are identified they will start to appear in the CSVs. As usual, you can run this model from the CLI using <code>plugboard process run model.yaml</code>.</p>","tags":["tutorial","events"]},{"location":"examples/tutorials/hello-world/","title":"Hello world","text":"<p>Plugboard is built to help you with two things: defining process models, and executing those models. There are two main ways to interact with Plugboard: via the Python API; or, via the CLI using model definitions saved in yaml format. In this introductory tutorial we'll do both, before building up to more complex models in later tutorials.</p>","tags":["tutorial"]},{"location":"examples/tutorials/hello-world/#building-models-with-the-python-api","title":"Building models with the Python API","text":"<p>First we start by defining each <code>Component</code> we want in our model. Components can have only inputs, only outputs, or both. To keep it simple we just have two components here, showing the most basic functionality. Each component has several methods which are called at different stages during model execution: <code>init</code> for optional initialisation actions; <code>step</code> to take a single step forward through time; <code>run</code> to execute all steps; and <code>destroy</code> for optional teardown actions.</p> <p>Info</p> <p>A model is made up of one or more components, though Plugboard really shines when you have many!</p>","tags":["tutorial"]},{"location":"examples/tutorials/hello-world/#defining-components","title":"Defining components","text":"<p>Let's define two components, <code>A</code> and <code>B</code>. <code>A</code> puts data into the model by generating numbers from a sequence. <code>B</code> takes input from <code>A</code>, doubles it, then saves it to a file. We build each component as a reusable Python class, implementing the main logic in a <code>step</code> method. <pre><code>import asyncio\nimport typing as _t\n\nfrom plugboard.component import Component, IOController as IO\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.process import LocalProcess\nfrom plugboard.schemas import ComponentArgsDict, ConnectorSpec\n\nclass A(Component):\n    io = IO(outputs=[\"out_1\"]) # (1)!\n\n    def __init__(self, iters: int, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._iters = iters\n\n    async def init(self) -&gt; None:\n        self._seq = iter(range(self._iters)) # (2)!\n\n    async def step(self) -&gt; None:\n        try:\n            self.out_1 = next(self._seq) # (3)!\n        except StopIteration:\n            await self.io.close() # (5)!\n\nclass B(Component):\n    io = IO(inputs=[\"in_1\"])\n\n    def __init__(self, path: str, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._path = path\n\n    async def init(self) -&gt; None:\n        self._f = open(self._path, \"w\")\n\n    async def step(self) -&gt; None:\n        out = 2 * self.in_1\n        self._f.write(f\"{out}\\n\")\n\n    async def destroy(self) -&gt; None:\n        self._f.close() # (4)!\n</code></pre></p> <ol> <li>This is where we configure the inputs and outputs for each <code>Component</code>.</li> <li><code>init</code> gets called before we run the model. It is optional, and used for any setup required on the <code>Component</code>.</li> <li><code>step</code> gets called at each step forward throughout the model execution. This is where the main business logic must be defined.</li> <li><code>destroy</code> is optional, and can be used to clean up any resources used by the <code>Component</code>.</li> <li><code>A</code> is responsible for stopping the model when it is complete, which we can do by calling <code>self.io.close()</code>.</li> </ol> <p>Note</p> <ul> <li>Each component has an <code>io</code> attribute in its definition, where we specify the names of the inputs and outputs. In this simple example, <code>A</code> has a single output, while <code>B</code> has a single input.</li> <li>During the <code>step</code> method, the inputs and outputs are available as attributes: so assigning to <code>self.out_1</code> lets us set the output of <code>A</code>, and reading <code>self.in_1</code> allows us to read the input of <code>B</code>.</li> <li>Notice how each component can have additional parameters in the <code>__init__</code> constructor, allowing us to give our components configurable settings like the output file path.</li> </ul>","tags":["tutorial"]},{"location":"examples/tutorials/hello-world/#setting-up-a-process","title":"Setting up a <code>Process</code>","text":"<p>Now we take these components, connect them up as a <code>Process</code>, and fire off the model. When instantiating each component we must provide a <code>name</code>, which we can use to help define the connections between them. Using a <code>ConnectorSpec</code> object, we tell Plugboard to connect the <code>out_1</code> output of the <code>a</code> component to the <code>in_1</code> input of <code>b</code>. Visually, the model will look like this:</p> <pre><code>flowchart LR\n    a@{ shape: rounded, label: A&lt;br&gt;**a** } --&gt; b@{ shape: rounded, label: B&lt;br&gt;**b** }</code></pre> <p>The rest of the code is boilerplate: calling <code>run()</code> on the <code>Process</code> object triggers all the components to start iterating through all their inputs until a termination condition is reached. We're using <code>LocalProcess</code> here, because we are running this model locally with no parallel computation (will explore this in a later tutorial).</p> <p>Simulations proceed in an event-driven manner: when inputs arrive, the components are triggered to step forward in time. The framework handles the details of the inter-component communication, you just need to specify the logic of your components, and the connections between them. <pre><code>process = LocalProcess(\n    components=[A(name=\"a\", iters=5), B(name=\"b\", path=\"b.txt\")],\n    connectors=[\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"a.out_1\", target=\"b.in_1\"),\n        )\n    ],\n)\nasync with process:\n    await process.run()\n</code></pre></p>","tags":["tutorial"]},{"location":"examples/tutorials/hello-world/#executing-pre-defined-models-on-the-cli","title":"Executing pre-defined models on the CLI","text":"<p>In many cases, we want to define components once, with suitable parameters, and then use them repeatedly in different simulations. Plugboard enables this workflow with model specification files yaml format. Once the components have been defined, the simple model above can be represented with a yaml file like this: <pre><code>plugboard:\n  process:\n    args:\n      components:\n      - type: hello_world.A  # (1)!\n        args:\n          name: \"a\"\n          iters: 10  # (2)!\n      - type: hello_world.B\n        args:\n          name: \"b\"\n          path: \"./b.txt\"\n      connectors:\n      - source: \"a.out_1\"\n        target: \"b.in_1\"\n</code></pre></p> <ol> <li>This identifies the <code>A</code> class within the <code>hello_world</code> module.</li> <li>The <code>iters</code> parameter is required for the component - try adjusting to change how long the model runs for.</li> </ol> <p>Note</p> <p>Notice how we use <code>type</code> to tell Plugboard where our components are defined within Python code (within the <code>hello_world</code> module). Creating models in yaml format like this also makes it easy to track and adjust their configurable parameters: try editing the file path or <code>iters</code> parameter to change the behaviour of the model.</p> <p>Tip</p> <p>If you have already defined a model in code, you can export it to YAML by calling the <code>dump</code> method on your <code>Process</code> object.</p> <p>We can now run this model using the plugboard CLI with the command: <pre><code>plugboard process run model.yaml\n</code></pre></p> <p>You should see that an output <code>.txt</code> file has been created, showing the the model as run successfully. Congratulations - you have built and run your first Plugboard model!</p> <p>In the following tutorials we will build up some more complex components and processes to demonstrate the power of the framework.</p>","tags":["tutorial"]},{"location":"examples/tutorials/more-complex-process/","title":"A more complex process","text":"<p>In the last example our <code>Process</code> consisted of just two components. Usually we use many more components, allowing you to break down your model into separate parts that you can build/test individually. Plugboard allows for branching and looping connections between your components.</p> <p>In this tutorial we'll also demonstrate how to make components reusable between different processes.</p>","tags":["tutorial"]},{"location":"examples/tutorials/more-complex-process/#define-some-components","title":"Define some components","text":"<p>First of all, let's define five different components:</p> <ul> <li><code>Random</code> will generate random numbers to feed into our model;</li> <li><code>Offset</code> adds a fixed offset to its inputs;</li> <li><code>Scale</code> will multiple its input by a fixed scale factor;</li> <li><code>Sum</code> will take in two inputs and add them together;</li> <li><code>Save</code> will write its input to a text file.</li> </ul> <p>We can put the code for each of these in <code>components.py</code>. <pre><code>import random\nimport typing as _t\n\nfrom plugboard.component import Component, IOController as IO\nfrom plugboard.schemas import ComponentArgsDict\n\nclass Random(Component):\n    io = IO(outputs=[\"x\"])\n\n    def __init__(\n            self,\n            iters: int,  # (1)!\n            low: float = 0,\n            high: float = 10,\n            **kwargs: _t.Unpack[ComponentArgsDict]\n        ) -&gt; None:\n        super().__init__(**kwargs)\n        self._iters = 0\n        self._low = low\n        self._high = high\n        self._max_iters = iters\n\n    async def step(self) -&gt; None:\n        if self._iters &lt; self._max_iters:\n            self.x = random.uniform(self._low, self._high)\n            self._iters += 1\n            return\n        await self.io.close()\n\nclass Offset(Component):\n    \"\"\"Implements `x = a + offset`.\"\"\"\n    io = IO(inputs=[\"a\"], outputs=[\"x\"]) # (2)!\n\n    def __init__(self, offset: float = 0, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._offset = offset\n\n    async def step(self) -&gt; None:\n        self.x = self.a + self._offset\n\nclass Scale(Component):\n    \"\"\"Implements `x = a * scale`.\"\"\"\n    io = IO(inputs=[\"a\"], outputs=[\"x\"])\n\n    def __init__(self, scale: float = 1, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._scale = scale\n\n    async def step(self) -&gt; None:\n        self.x = self.a * self._scale\n\nclass Sum(Component):\n    \"\"\"Implements `x = a + b`.\"\"\"\n    io = IO(inputs=[\"a\", \"b\"], outputs=[\"x\"]) # (3)!\n\n    async def step(self) -&gt; None:\n        self.x = self.a + self.b\n\nclass Save(Component):\n    io = IO(inputs=[\"value_to_save\"])\n\n    def __init__(self, path: str, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._path = path\n\n    async def init(self) -&gt; None:\n        self._f = open(self._path, \"w\")\n\n    async def step(self) -&gt; None:\n        self._f.write(f\"{self.value_to_save}\\n\")\n\n    async def destroy(self) -&gt; None:\n        self._f.close()\n</code></pre></p> <ol> <li>The <code>Component</code> needs three different parameters: <code>iters</code> to control how many iterations the model runs for, <code>low</code> and <code>high</code> to control the range of the random number generator.</li> <li>A <code>Component</code> with both inputs and outputs.</li> <li>Here we have multiple inputs.</li> </ol>","tags":["tutorial"]},{"location":"examples/tutorials/more-complex-process/#create-branching-connections-in-a-process","title":"Create branching connections in a <code>Process</code>","text":"<p>Next, we'll connect the components together to form this model:</p> <pre><code>flowchart LR\n    offset@{ shape: rounded, label: Offset&lt;br&gt;**offset** } --&gt; sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** }\n    random@{ shape: rounded, label: Random&lt;br&gt;**random** } --&gt; offset@{ shape: rounded, label: Offset&lt;br&gt;**offset** }\n    random@{ shape: rounded, label: Random&lt;br&gt;**random** } ----&gt; save-input@{ shape: rounded, label: Save&lt;br&gt;**save-input** }\n    random@{ shape: rounded, label: Random&lt;br&gt;**random** } --&gt; scale@{ shape: rounded, label: Scale&lt;br&gt;**scale** }\n    scale@{ shape: rounded, label: Scale&lt;br&gt;**scale** } --&gt; sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** }\n    sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** } --&gt; save-output@{ shape: rounded, label: Save&lt;br&gt;**save-output** }</code></pre> <p>Note</p> <p>See how we branch the output of the <code>Random</code> component into three different places: a <code>Save</code> component (so that we can record our model input), <code>Offset</code> and <code>Scale</code>.</p> <p>Now in <code>branching.py</code> we import these components, connect them together and run the model. <pre><code>import asyncio\n\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.process import LocalProcess\nfrom plugboard.schemas import ConnectorSpec\n\nfrom components import Offset, Random, Save, Scale, Sum\n\n\nasync def main() -&gt; None:\n    connect = lambda in_, out_: AsyncioConnector(  # (1)!\n        spec=ConnectorSpec(source=in_, target=out_)\n    )\n    process = LocalProcess(\n        components=[  # (2)!\n            Random(name=\"random\", iters=5, low=0, high=10),\n            Offset(name=\"offset\", offset=10),\n            Scale(name=\"scale\", scale=2),\n            Sum(name=\"sum\"),\n            Save(name=\"save-input\", path=\"input.txt\"),\n            Save(name=\"save-output\", path=\"output.txt\"),\n        ],\n        connectors=[  # (3)!\n            connect(\"random.x\", \"save-input.value_to_save\"),\n            connect(\"random.x\", \"offset.a\"),\n            connect(\"random.x\", \"scale.a\"),\n            connect(\"offset.x\", \"sum.a\"),\n            connect(\"scale.x\", \"sum.b\"),\n            connect(\"sum.x\", \"save-output.value_to_save\"),\n        ],\n    )\n    async with process:  # (3)!\n        await process.run()\n</code></pre></p> <ol> <li>We'll use this lambda to abbreviate the connectors below.</li> <li>Instantiate each of the components here with any necessary parameters.</li> <li>Here is where we define all of the connections in our model: <code>source</code> and <code>target</code> are of the form <code>component_name.io_name</code>. So the first item connects the <code>x</code> output on the <code>random</code> component to the <code>value_to_save</code> input on <code>save-input</code>.</li> <li>As in the previous tutorial, this is equivalent to calling <code>await process.init()</code>, followed by <code>await process.run()</code> and then <code>await process.destroy()</code>.</li> </ol> <p>Now run <code>python branching.py</code> and you will see the <code>input.txt</code> and <code>output.txt</code> files generated showing that the model has run.</p>","tags":["tutorial"]},{"location":"examples/tutorials/more-complex-process/#create-a-loop-connection","title":"Create a loop connection","text":"<p>In some cases you might want to create a loop in your model. This is commonly the case where you need to include feedback: for example you might have a component modelling the temperature of a heated hot-water tank and another one representing an automatic controller that turns the heating element on and off.</p> <p>To make models like this work in Plugboard you will need to specify <code>initial_values</code> somewhere in the loop: this ensures that each of the <code>Component</code> objects can get all their inputs at the first call to <code>process.step()</code>, allowing the model to start running.</p> <p>Consider this model in which the <code>Sum</code> component will accumulate a scaled part of its value at every iteration:</p> <pre><code>flowchart LR\n    random@{ shape: rounded, label: Random&lt;br&gt;**random** } --&gt; sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** }\n    scale@{ shape: rounded, label: Scale&lt;br&gt;**scale** } --&gt; sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** }\n    sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** } --&gt; save-output@{ shape: rounded, label: Save&lt;br&gt;**save-output** }\n    sum@{ shape: rounded, label: Sum&lt;br&gt;**sum** } --&gt;|\"&lt;i&gt;a&lt;sub&gt;t=0&lt;/sub&gt;=0&lt;/i&gt;\"| scale@{ shape: rounded, label: Scale&lt;br&gt;**scale** }</code></pre> <p>Tip</p> <p>The diagrams in these tutorials are created in Mermaid syntax. You can make them directly in Plugboard using the <code>markdown_diagram</code> function. Alternatively if you have a YAML config file you can run <code>plugboard process diagram your-yaml-file.yaml</code> on the command line.</p> <p>Creating diagrams can be a useful way to keep track of the different parts of your model as you build it out, and also helps to you to document how the model works.</p> <p>We'll provide an initial input value of <code>a = 0</code> to the <code>Scale</code> component, allowing the model to run. Implementing this in <code>loop.py</code> we have: <pre><code>import asyncio\n\nfrom plugboard.connector import AsyncioConnector\nfrom plugboard.process import LocalProcess\nfrom plugboard.schemas import ConnectorSpec\n\nfrom components import Random, Save, Scale, Sum\n\n\nasync def main() -&gt; None:\n    connect = lambda in_, out_: AsyncioConnector(\n        spec=ConnectorSpec(source=in_, target=out_)\n    )\n    process = LocalProcess(\n        components=[\n            Random(name=\"random\", iters=5, low=0, high=10),\n            Sum(name=\"sum\"),\n            Scale(name=\"scale\", initial_values={\"a\": [0]}, scale=0.5),  # (1)!\n            Save(name=\"save-output\", path=\"cumulative-sum.txt\"),\n        ],\n        connectors=[\n            connect(\"random.x\", \"sum.a\"),\n            connect(\"sum.x\", \"scale.a\"),\n            connect(\"scale.x\", \"sum.b\"),\n            connect(\"sum.x\", \"save-output.value_to_save\"),\n        ],\n    )\n    async with process:\n        await process.run()\n</code></pre></p> <ol> <li>We specify our initial value for the <code>Scale</code> input here.</li> </ol> <p>Note</p> <p>Initial values are specified as lists in Plugboard, allowing you to specify a sequence of them. The component will read the first element in the initial value at the first call to <code>step()</code> and so on until there are no more initial values left to consume. Usually you won't need more than one initial value, so the list typically contains a single element as in this example.</p> <p>Setting <code>initial_values = {\"a\": [0]}</code> means that we want the <code>a</code> input to be set to <code>0</code> on the first step and then revert to reading its input as usual.</p>","tags":["tutorial"]},{"location":"examples/tutorials/more-complex-process/#using-parameters","title":"Using parameters","text":"<p>Sometimes you might need to use a parameter value repeatedly across many <code>Component</code> objects. The <code>Process</code> object allows you to supply a single dictionary of parameter values that are then supplied to all the components before they start running. For example, we can rewrite the <code>Scale</code> component like this:</p> <pre><code>class ScaleFromParameter(Component):\n    \"\"\"Implements `x = a * scale` using parameters.\"\"\"\n    io = IO(inputs=[\"a\"], outputs=[\"x\"])\n\n    async def step(self) -&gt; None:\n        self.x = self.a * self.parameters.get(\"scale\", 1)\n</code></pre> <p>Now we can supply the <code>scale</code> value when we create the <code>Process</code>, and use it many places within the model.</p> <pre><code>connect = lambda in_, out_: AsyncioConnector(\n    spec=ConnectorSpec(source=in_, target=out_)\n)\nprocess = LocalProcess(\n    components=[\n        Random(name=\"random\", iters=5, low=0, high=10),\n        ScaleFromParameter(name=\"scale_a\"),\n        ScaleFromParameter(name=\"scale_b\", parameters={\"scale\": 2.0}),  # (2)!\n        Sum(name=\"sum\"),\n        Save(name=\"save-input\", path=\"input.txt\"),\n        Save(name=\"save-output\", path=\"output.txt\"),\n    ],\n    connectors=[\n        connect(\"random.x\", \"save-input.value_to_save\"),\n        connect(\"random.x\", \"scale_a.a\"),\n        connect(\"random.x\", \"scale_b.a\"),\n        connect(\"scale_a.x\", \"sum.a\"),\n        connect(\"scale_b.x\", \"sum.b\"),\n        connect(\"sum.x\", \"save-output.value_to_save\"),\n    ],\n    parameters={\"scale\": 0.5},  # (1)!\n)\nasync with process:\n    await process.run()\n</code></pre> <ol> <li>Supply a dictionary of common parameter values to the <code>Process</code> here. They are accessible from within all components.</li> <li>If you need to override a parameter on a specific component, you can supply it via the component-level <code>parameters</code> argument.</li> </ol>","tags":["tutorial"]},{"location":"examples/tutorials/more-complex-process/#next-steps","title":"Next steps","text":"<p>You've now learned how to build up complex model layouts in Plugboard. In the next tutorial we'll show how powerful a Plugboard model can be as we start to include different types of <code>Component</code>.</p>","tags":["tutorial"]},{"location":"examples/tutorials/more-components/","title":"More components","text":"<p>Plugboard's <code>Component</code> objects can run anything you can code in Python. This includes:</p> <ul> <li>Using your own or third-party Python packages;</li> <li>External calls to APIs, e.g. data sources or hosted models;</li> <li>Shell commands on your own machine, for example to execute third-party binaries that you want to integrate with.</li> </ul> <p>It even ships with some pre-built components in <code>plugboard.library</code> to help you with common tasks.</p> <p>Info</p> <p>Plugboard was originally built to help data scientists working on industrial process simulations. Python provides a familar environment to integrate different parts of a simulation, for example combining the output of a traditional process control simulation with a machine-learning model.</p> <p>In this tutorial we'll build a model to process data through an LLM and showcase some different components along the way.</p>","tags":["tutorial","logging","llm","io"]},{"location":"examples/tutorials/more-components/#using-an-llm-in-plugboard","title":"Using an LLM in Plugboard","text":"<p>We're going to build a model that loads rows of data from a CSV and then uses an LLM to extract information about the geographical place referred to in each row. We'll then query an API to get the latest weather for each location.</p> <pre><code> flowchart LR\n    llm@{ shape: rounded, label: LLMChat&lt;br&gt;**llm** } --&gt; weather@{ shape: rounded, label: WeatherAPI&lt;br&gt;**weather** }\n    llm@{ shape: rounded, label: LLMChat&lt;br&gt;**llm** } --&gt; save-results@{ shape: rounded, label: FileWriter&lt;br&gt;**save-results** }\n    load-text@{ shape: rounded, label: FileReader&lt;br&gt;**load-text** } --&gt; llm@{ shape: rounded, label: LLMChat&lt;br&gt;**llm** }\n    weather@{ shape: rounded, label: WeatherAPI&lt;br&gt;**weather** } --&gt; save-results@{ shape: rounded, label: FileWriter&lt;br&gt;**save-results** }</code></pre>","tags":["tutorial","logging","llm","io"]},{"location":"examples/tutorials/more-components/#loading-and-saving-data","title":"Loading and saving data","text":"<p>In previous tutorials we wrote our own components for reading/writing files. Here we are going to use the built-in <code>FileReader</code> and <code>FileWriter</code> components. These are much more useful for building practical models, as they can access a variety of file formats both locally and in cloud storage. <pre><code>load_text = FileReader(name=\"load-text\", path=\"input.csv\", field_names=[\"text\"])\nsave_output = FileWriter(\n    name=\"save-results\",\n    path=\"output.csv\",\n    field_names=[\"location\", \"temperature\", \"wind_speed\"],\n)\n</code></pre></p>","tags":["tutorial","logging","llm","io"]},{"location":"examples/tutorials/more-components/#sending-the-data-to-an-llm","title":"Sending the data to an LLM","text":"<p>We're going to use the <code>LLMChat</code> to access OpenAI: <pre><code>llm = LLMChat(\n    name=\"llm\",\n    system_prompt=\"Identify a geographical location from the input and provide its latitude and longitude\",\n    response_model=Location,\n    expand_response=True,  # (2)!\n)\n</code></pre></p> <ol> <li><code>LLMChat</code> can use structured output to process the LLM response into a known format. Here we define a Pydantic model that specifies everything we're expecting back.</li> <li>Setting <code>expand_response = True</code> will unpack <code>location</code>, <code>latitude</code> and <code>longitude</code> into separate outputs on the component.</li> </ol> <p>Info</p> <p>To run this tutorial you'll need an API key for OpenAI. Set the <code>OPENAI_API_KEY</code> environment variable to provide it to the model.</p> <p>Since <code>LLMChat</code> is based on LlamaIndex you can even try reconfiguring <code>LLMChat</code> to use a different LLM.</p>","tags":["tutorial","logging","llm","io"]},{"location":"examples/tutorials/more-components/#querying-a-weather-api","title":"Querying a weather API","text":"<p>We can now define a component to query a weather API and get temperature and wind speed for a given location. <pre><code>class WeatherAPI(Component):\n    \"\"\"Get current weather for a location.\"\"\"\n\n    io = IO(inputs=[\"latitude\", \"longitude\"], outputs=[\"temperature\", \"wind_speed\"])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._client = httpx.AsyncClient()\n\n    async def step(self) -&gt; None:\n        response = await self._client.get(\n            \"https://api.open-meteo.com/v1/forecast\",\n            params={\n                \"latitude\": self.latitude,\n                \"longitude\": self.longitude,\n                \"current\": \"temperature_2m,wind_speed_10m\",\n            },\n        )\n        try:\n            response.raise_for_status()\n        except httpx.HTTPStatusError:\n            self._logger.error(\n                \"Error querying weather API\",\n                code=response.status_code,\n                message=response.text,\n            )\n            return\n        data = response.json()\n        self.temperature = data[\"current\"][\"temperature_2m\"]\n        self.wind_speed = data[\"current\"][\"wind_speed_10m\"]\n\nweather = WeatherAPI(name=\"weather\")\n</code></pre></p> <p>Info</p> <p>See how we used <code>self._logger</code> to record log messages. All Plugboard <code>Component</code> objects have a structlog logger on the <code>_logger</code> attribute. See configuration for more information on configuring the logging.</p>","tags":["tutorial","logging","llm","io"]},{"location":"examples/tutorials/more-components/#putting-it-all-together","title":"Putting it all together","text":"<p>As usual, we can link all our components together in a <code>LocalProcess</code> and run them as follows: <pre><code>connect = lambda in_, out_: AsyncioConnector(\n    spec=ConnectorSpec(source=in_, target=out_)\n)\nprocess = LocalProcess(\n    components=[load_text, llm, weather, save_output],\n    connectors=[\n        connect(\"load-text.text\", \"llm.prompt\"),\n        connect(\"llm.latitude\", \"weather.latitude\"),\n        connect(\"llm.longitude\", \"weather.longitude\"),\n        connect(\"llm.location\", \"save-results.location\"),\n        connect(\"weather.temperature\", \"save-results.temperature\"),\n        connect(\"weather.wind_speed\", \"save-results.wind_speed\"),\n    ],\n)\nasync with process:\n    await process.run()\n</code></pre></p> <p>Check out the <code>output.csv</code> file to see all of the collected model output.</p>","tags":["tutorial","logging","llm","io"]},{"location":"examples/tutorials/running-in-parallel/","title":"Running in parallel","text":"<p>Up until now we have running all our models in a single computational process. This is perfectly sufficient for simple models, or when your components can make use of Python's asyncio to avoid blocking.</p> <p>As your models get larger and more computationally intensive you may benefit from running parts of the model in parallel. Plugboard integrates with the Ray framework, allowing you to split your computation across multiple CPU cores, or even across nodes in a Ray cluster.</p> <p>Tip</p> <p>Keep in mind that parallelising a model has a cost associated with it: the communication between the different components will be slower on Ray than it is locally.</p> <p>For small models, or when a single component is the computational bottleneck then this overhead may not be worth it. However, when you have multiple computationally-intensive components in different branches of your <code>Process</code> then moving to Ray can give you a performance boost.</p> <p>Before running this tutorial be sure to install Ray with pip, or install plugboard with its optional <code>ray</code> extra.</p>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#parallelising-a-model","title":"Parallelising a model","text":"<p>For demonstration purposes we're going to use a model with two branches that containing <code>Sleep</code> components to simulate computationally intensive activity. In real scenarios these might instead be calls to simulation software or machine-learning model inference.</p> <pre><code>flowchart LR\n    input@{ shape: rounded, label: Iterator&lt;br&gt;**input** } --&gt; slow-sleep@{ shape: rounded, label: Sleep&lt;br&gt;**slow-sleep** }\n    input@{ shape: rounded, label: Iterator&lt;br&gt;**input** } --&gt; very-slow-sleep@{ shape: rounded, label: Sleep&lt;br&gt;**very-slow-sleep** }\n    slow-sleep@{ shape: rounded, label: Sleep&lt;br&gt;**slow-sleep** } --&gt; timestamper@{ shape: rounded, label: Timestamper&lt;br&gt;**timestamper** }\n    timestamper@{ shape: rounded, label: Timestamper&lt;br&gt;**timestamper** } --&gt; save-results@{ shape: rounded, label: FileWriter&lt;br&gt;**save-results** }\n    very-slow-sleep@{ shape: rounded, label: Sleep&lt;br&gt;**very-slow-sleep** } --&gt; timestamper@{ shape: rounded, label: Timestamper&lt;br&gt;**timestamper** }</code></pre>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#defining-the-components","title":"Defining the components","text":"<p>Let's define the various components that we need. The <code>Timestamper</code> component simply emits the current time in ISO format so that our output file will contain a record of how long each step of the model took. We can again use <code>FileWriter</code> to save the output to CSV. <pre><code>class Iterator(Component):\n    \"\"\"Creates a sequence of numbers.\"\"\"\n\n    io = IO(outputs=[\"x\"])\n\n    def __init__(self, iters: int, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._iters = iters\n\n    async def init(self) -&gt; None:\n        self._seq = iter(range(self._iters))\n\n    async def step(self) -&gt; None:\n        try:\n            self.out_1 = next(self._seq)\n        except StopIteration:\n            await self.io.close()\n\n\nclass Sleep(Component):\n    \"\"\"Passes through input to output after a delay.\"\"\"\n\n    io = IO(inputs=[\"x\"], outputs=[\"y\"])\n\n    def __init__(self, sleep_seconds: float, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._duration = sleep_seconds\n\n    async def step(self) -&gt; None:\n        time.sleep(self._duration)  # (1)!\n        self.y = self.x\n\n\nclass Timestamper(Component):\n    \"\"\"Emits the current time when all inputs are ready.\"\"\"\n\n    io = IO(inputs=[\"x\", \"y\"], outputs=[\"timestamp\"])\n\n    async def step(self) -&gt; None:\n        self.timestamp = datetime.datetime.now().isoformat()\n</code></pre></p> <ol> <li>We're using <code>time.sleep</code> here and not <code>asyncio.sleep</code> because we're deliberately blocking execution to simulate a computationally intensive component.</li> </ol>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#running-normally-in-a-localprocess","title":"Running normally in a <code>LocalProcess</code>","text":"<p>First we can setup the <code>LocalProcess</code> and run it as we have in previous tutorials. <pre><code>process = LocalProcess(\n    components=[\n        Iterator(name=\"input\", iters=20),\n        Sleep(name=\"slow-sleep\", sleep_seconds=0.5),\n        Sleep(name=\"very-slow-sleep\", sleep_seconds=1),\n        Timestamper(name=\"timestamper\"),\n        FileWriter(name=\"save-results\", path=\"ray.csv\", field_names=[\"timestamp\"]),\n    ],\n    connectors=[\n        AsyncioConnector(spec=ConnectorSpec(source=\"input.x\", target=\"slow-sleep.x\")),\n        AsyncioConnector(spec=ConnectorSpec(source=\"input.x\", target=\"very-slow-sleep.x\")),\n        AsyncioConnector(spec=ConnectorSpec(source=\"slow-sleep.y\", target=\"timestamper.x\")),\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"very-slow-sleep.y\", target=\"timestamper.y\")\n        ),\n        AsyncioConnector(\n            spec=ConnectorSpec(source=\"timestamper.timestamp\", target=\"save-results.timestamp\")\n        ),\n    ],\n)\nasync with process:\n    await process.run()\n</code></pre></p> <p>Running 20 iterations takes around 30 seconds, because each step of the model contains 1.5s of computation.</p>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#running-in-parallel-using-rayprocess","title":"Running in parallel using <code>RayProcess</code>","text":"<p>With some small changes we can make the same model run in parallel on Ray. First we change the <code>Process</code> class to <code>RayProcess</code>. Then when creating the <code>Connector</code> objects we need to change the channel type to <code>RayChannel</code>.</p> <p>Info</p> <p><code>Channel</code> objects are used by Plugboard to handle the communication between components. So far we have used <code>AsyncioChannel</code>, which is the best option for simple models that don't require parallelisation.</p> <p>Plugboard provides different channel classes for use in parallel environments: <code>RayChannel</code> is suitable for single and multi-host Ray environments. <code>ZMQChannel</code> is faster, but currently only works on a single host.</p> <pre><code>process = RayProcess(\n    components=[\n        Iterator(name=\"input\", iters=20),\n        Sleep(name=\"slow-sleep\", sleep_seconds=0.5),\n        Sleep(name=\"very-slow-sleep\", sleep_seconds=1),\n        Timestamper(name=\"timestamper\"),\n        FileWriter(name=\"save-results\", path=\"ray.csv\", field_names=[\"timestamp\"]),\n    ],\n    connectors=[\n        RayConnector(spec=ConnectorSpec(source=\"input.x\", target=\"slow-sleep.x\")),\n        RayConnector(spec=ConnectorSpec(source=\"input.x\", target=\"very-slow-sleep.x\")),\n        RayConnector(spec=ConnectorSpec(source=\"slow-sleep.y\", target=\"timestamper.x\")),\n        RayConnector(spec=ConnectorSpec(source=\"very-slow-sleep.y\", target=\"timestamper.y\")),\n        RayConnector(\n            spec=ConnectorSpec(source=\"timestamper.timestamp\", target=\"save-results.timestamp\")\n        ),\n    ],\n)\nasync with process:\n    await process.run()\n</code></pre> <p>Now the 20 iteration model takes around 23s, because the two different <code>Sleep</code> components are being executed in parallel (20s compute time plus a little overhead).</p>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#using-yaml-config","title":"Using YAML config","text":"<p>Defining your model as a YAML config file is particularly useful when you want to use more computational resources: the config file is portable and lets you easily move the model to different compute environments.</p> <p>Specifying the process type and channel builder type in the YAML is the only change needed to get the example above to run on Ray. <pre><code>plugboard:\n  process:\n    type: \"plugboard.process.RayProcess\"  # (1)!\n    connector_builder:\n      type: \"plugboard.connector.RayConnector\"  # (2)!\n    args:\n      components:\n      - type: hello_ray.Iterator\n        args:\n          name: \"input\"\n          iters: 10\n      - type: hello_ray.Sleep\n        args:\n          name: \"slow-sleep\"\n          sleep_seconds: 0.5\n      - type: hello_ray.Sleep\n        args:\n          name: \"very-slow-sleep\"\n          sleep_seconds: 1\n      - type: hello_ray.Timestamper\n        args:\n          name: \"timestamper\"\n      - type: plugboard.library.file_io.FileWriter\n        args:\n          name: \"save-results\"\n          path: \"ray.csv\"\n          field_names:\n          - timestamp\n      connectors:\n      - source: \"input.x\"\n        target: \"slow-sleep.x\"\n      - source: \"input.x\"\n        target: \"very-slow-sleep.x\"\n      - source: \"slow-sleep.y\"\n        target: \"timestamper.x\"\n      - source: \"very-slow-sleep.y\"\n        target: \"timestamper.y\"\n      - source: \"timestamper.timestamp\"\n        target: \"save-results.timestamp\"\n</code></pre></p> <ol> <li>Tell Plugboard to use a <code>RayProcess</code> instead of the default <code>LocalProcess</code>.</li> <li>Also change the connector builder to <code>RayConnector</code>, which will build <code>RayChannel</code> objects when creating the <code>Process</code>.</li> </ol>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#specifying-resource-requirements","title":"Specifying resource requirements","text":"<p>When running components on Ray, you can specify resource requirements for each component to control how Ray allocates computational resources. This is particularly useful when you have components with different resource needs (e.g., CPU-intensive vs GPU-intensive tasks) and you are running on a Ray cluster.</p> <p>Tip</p> <p>Normally Ray will start automatically when you are using Plugboard locally. If you want to start a separate Ray instance, for example so that you can control the configuration options, you can launch it from the CLI. For example, this command will start a Ray instance with enough resources to run the example below.</p> <pre><code>uv run ray start --head --num-cpus=4 --num-gpus=1 --resources='{\"custom_hardware\": 5}'\n</code></pre>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#declaring-resources-at-component-definition","title":"Declaring resources at component definition","text":"<p>The recommended way to specify resource requirements is to declare them as a class attribute when defining your component. This makes the <code>Resource</code> requirements explicit and part of the component's definition:</p> <pre><code>class CPUIntensiveTask(Component):\n    \"\"\"Component that requires more CPU resources.\n\n    Resource requirements are declared as a class attribute.\n    \"\"\"\n\n    io = IO(inputs=[\"x\"], outputs=[\"y\"])\n    resources = Resource(cpu=2.0)   # (1)!\n\n    async def step(self) -&gt; None:\n        \"\"\"Execute CPU-intensive computation.\"\"\"\n        # Simulate CPU-intensive work\n        result = sum(i**2 for i in range(int(self.x * 10000)))\n        self.y = result\n</code></pre> <ol> <li>Declare resources when defining the class.</li> </ol>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#overriding-resources-at-instantiation","title":"Overriding resources at instantiation","text":"<p>You can also override resource requirements when creating component instances. This is useful when you want to use the same component class with different resource requirements:</p> <pre><code>CPUIntensiveTask(name=\"cpu-task\", resources=Resource(cpu=1.0)),  # (1)!\n</code></pre> <ol> <li>Pass a <code>Resource</code> object to override the CPU requirements for this component.</li> </ol>","tags":["tutorial","ray"]},{"location":"examples/tutorials/running-in-parallel/#example","title":"Example","text":"<p>For example, you can specify <code>Resource</code> requirements like this when defining components:</p> <pre><code># Resources can be declared at the class level (see CPUIntensiveTask and GPUTask above)\n# or overridden when instantiating components\nprocess = RayProcess(\n    components=[\n        CPUIntensiveTask(name=\"cpu-task\", resources=Resource(cpu=1.0)),  # (1)!\n        GPUTask(name=\"gpu-task\"),  # (2)!\n        DataProducer(name=\"producer\", iters=5),  # (3)!\n    ],\n    connectors=[\n        RayConnector(spec=ConnectorSpec(source=\"producer.output\", target=\"cpu-task.x\")),\n        RayConnector(spec=ConnectorSpec(source=\"cpu-task.y\", target=\"gpu-task.data\")),\n    ],\n)\n</code></pre> <ol> <li>Override the resource requirement on this instance.</li> <li>Use resources specified in class definition.</li> <li>Use default resources.</li> </ol> <p>Or override them in YAML configuration:</p> <pre><code>plugboard:\n  process:\n    type: plugboard.process.RayProcess\n    connector_builder:\n      type: plugboard.connector.RayConnector\n    args:\n      name: resource-example-process\n      components:\n        - type: examples.tutorials.004_using_ray.resources_example.DataProducer\n          args:\n            name: producer\n            iters: 10\n            resources:\n              cpu: 1.0   # (1)!\n        - type: examples.tutorials.004_using_ray.resources_example.CPUIntensiveTask\n          args:\n            name: cpu-task\n            # CPUIntensiveTask has class-level resources (cpu: 2.0)\n            # Override to use more memory\n            resources:\n              cpu: 2.0  # (2)!\n              memory: \"512Mi\"  # (3)!\n        - type: examples.tutorials.004_using_ray.resources_example.GPUTask\n          args:\n            name: gpu-task\n            # GPUTask has class-level resources (cpu: \"500m\", gpu: 1)\n            # Can override or extend with custom resources\n            resources:\n              cpu: \"500m\"  # (4)!\n              gpu: 1  # (5)!\n              resources:\n                custom_hardware: 2  # (6)!\n      connectors:\n        - source: producer.output\n          target: cpu-task.x\n        - source: cpu-task.y\n          target: gpu-task.data\n</code></pre> <ol> <li>Override DataProducer to require 1 CPU (instead of the default 0.001).</li> <li>CPUIntensiveTask already declares cpu: 2.0 at the class level, so this matches the class definition.</li> <li>Add 512MB memory requirement to CPUIntensiveTask (extending the class-level resources).</li> <li>Requires 0.5 CPU, specified in Kubernetes-style format (500 milli CPUs). This matches the class-level declaration.</li> <li>Requires 1 GPU, matching the class-level declaration.</li> <li>Add a custom resource called <code>custom_hardware</code>. This needs to be specified in the configuration of your Ray cluster to make it available.</li> </ol> <p>See the Ray documentation for more information about specifying resource requirements.</p>","tags":["tutorial","ray"]},{"location":"examples/tutorials/tuning-a-process/","title":"Tuning a process","text":"<p>Once you have built a model of your process, a common problem you might face is tuning its parameters. Plugboard includes a built-in optimisation utility based on Ray Tune and Optuna. Using this tool you can do things like:</p> <ul> <li>Calibrate the parameters of a process model to match observed results; and</li> <li>Optimise a process model to maximise or minimise its output.</li> </ul> <p>These capabilities are particularly useful when working with digital twins: for example given a model of a production line, you could use the tuner to work out how to maximise its output.</p> <p>Tip</p> <p>By using Ray Tune, Plugboard allows you to run optimisations in parallel within a Ray cluster, allowing you to explore the parameter space quickly even when working with long simulations.</p>","tags":["tutorial","optimisation"]},{"location":"examples/tutorials/tuning-a-process/#define-a-model-to-optimise","title":"Define a model to optimise","text":"<p>As a simple example, we'll create a simple 3-component model to calculate the maximum height of a projectile launched at a given angle and velocity. <pre><code> flowchart LR\n   horizontal@{ shape: rounded, label: Iterator&lt;br&gt;**horizontal** } --&gt; trajectory@{ shape: rounded, label: Trajectory&lt;br&gt;**trajectory** }\n   trajectory@{ shape: rounded, label: Trajectory&lt;br&gt;**trajectory** } --&gt; max-height@{ shape: rounded, label: MaxHeight&lt;br&gt;**max-height** }</code></pre></p> <p>Running the model with different values of the angle and velocity parameters configured on the <code>Trajectory</code> component will result in different heights being found on the <code>MaxHeight</code> component at the end of the simulation. We will use the <code>Tuner</code> class to explore this parameter space and maximise the projectile height.</p>","tags":["tutorial","optimisation"]},{"location":"examples/tutorials/tuning-a-process/#setting-up-the-components","title":"Setting up the components","text":"<p>We'll need the following components to implement the model above: <pre><code>class Iterator(Component):\n    \"\"\"Creates a sequence of x values.\"\"\"\n\n    io = IO(outputs=[\"x\"])\n\n    def __init__(self, iters: int, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self._iters = iters\n\n    async def init(self) -&gt; None:\n        self._seq = iter(range(self._iters))\n\n    async def step(self) -&gt; None:\n        try:\n            self.x = next(self._seq)\n        except StopIteration:\n            await self.io.close()\n\n\nclass Trajectory(Component):\n    \"\"\"Computes the height of a projectile.\"\"\"\n\n    io = IO(inputs=[\"x\"], outputs=[\"y\"])\n\n    def __init__(\n        self, angle: float = 30, velocity: float = 20, **kwargs: _t.Unpack[ComponentArgsDict]\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self._angle_radians = math.radians(angle)\n        self._v0 = velocity\n\n    async def step(self) -&gt; None:\n        self._logger.info(\"Calculating trajectory\", x=self.x)\n        self.y = self.x * math.tan(self._angle_radians) - (9.81 * self.x**2) / (\n            2 * self._v0**2 * math.cos(self._angle_radians) ** 2\n        )\n\n\nclass MaxHeight(Component):\n    \"\"\"Record the maximum height achieved.\"\"\"\n\n    io = IO(inputs=[\"y\"], outputs=[\"max_y\"])\n\n    def __init__(self, **kwargs: _t.Unpack[ComponentArgsDict]) -&gt; None:\n        super().__init__(**kwargs)\n        self.max_y: float = 0\n\n    async def step(self) -&gt; None:\n        self.max_y = max(self.y, self.max_y)\n</code></pre></p> <p>Instead of building a <code>Process</code> as we would normally do to run the model directly, we'll instead define the <code>ProcessSpec</code> for the model. <pre><code>process_spec = ProcessSpec(\n    args=ProcessArgsSpec(\n        components=[\n            {\"type\": \"hello_tuner.Iterator\", \"args\": {\"name\": \"horizontal\", \"iters\": 100}},\n            {\n                \"type\": \"hello_tuner.Trajectory\",\n                \"args\": {\"name\": \"trajectory\", \"angle\": 30, \"velocity\": 20},\n            },\n            {\"type\": \"hello_tuner.MaxHeight\", \"args\": {\"name\": \"max-height\"}},\n        ],\n        connectors=[\n            {\"source\": \"horizontal.x\", \"target\": \"trajectory.x\"},\n            {\"source\": \"trajectory.y\", \"target\": \"max-height.y\"},\n        ],\n    ),\n    type=\"plugboard.process.LocalProcess\",\n)\n# Check that the process spec can be built\n_ = ProcessBuilder.build(spec=process_spec)\n</code></pre></p>","tags":["tutorial","optimisation"]},{"location":"examples/tutorials/tuning-a-process/#setting-up-the-tuner","title":"Setting up the Tuner","text":"<p>Next, we set up a <code>Tuner</code> object by configuring the <code>angle</code> and <code>velocity</code> arguments as floating point parameters, along with constraints.</p> <p>Info</p> <p>Plugboard supports floating point, integer and categorical variables as tunable model parameters. See the definition of <code>ParameterSpec</code> for details.</p> <p>When building the tuner, we also specify the number of optimisation samples and how many we will allow to run in parallel on Ray. <pre><code>tuner = Tuner(\n    objective=ObjectiveSpec(  # (1)!\n        object_type=\"component\",\n        object_name=\"max-height\",\n        field_type=\"field\",\n        field_name=\"max_y\",\n    ),\n    parameters=[\n        FloatParameterSpec(  # (2)!\n            object_type=\"component\",\n            object_name=\"trajectory\",\n            field_type=\"arg\",\n            field_name=\"angle\",\n            lower=0,\n            upper=90,\n        ),\n        FloatParameterSpec(\n            object_type=\"component\",\n            object_name=\"trajectory\",\n            field_type=\"arg\",\n            field_name=\"velocity\",\n            lower=0,\n            upper=100,\n        ),\n    ],\n    num_samples=40,  # (3)!\n    max_concurrent=4,  # (4)!\n    mode=\"max\",  # (5)!\n)\nresult = tuner.run(spec=process_spec)\nprint(\n    \"Best parameters: \"\n    f\"angle={result.config['component.trajectory.arg.angle']}, \"\n    f\"velocity={result.config['component.trajectory.arg.velocity']}\"\n)\nprint(f\"Best max height: {result.metrics['component.max-height.field.max_y']}\")\n</code></pre></p> <ol> <li>Set the objective, i.e. what we want our optimisation to target. In this case it is a field  on the <code>max-height</code> component. This can be a list of objectives if you need to do multi-objective optimisation.</li> <li>List the tunable parameters here. The <code>field_type</code> can be <code>\"arg\"</code> or <code>\"initial_value\"</code>. This is also where you can specify constraints on the parameters.</li> <li>Set the number of trials to run. More trials will take longer, but may get closer to finding the true optimum.</li> <li>The level of concurrency to use in Ray.</li> <li>Whether to minimise or maximise the objective. This must be set as a list for multi-objective optimisation.</li> </ol> <p>Running this code will execute an optimisation job and print out information on each trial, along with the final optimisation result.</p> <p>Tip</p> <p>Since Optuna is used under the hood, you can configure the optional <code>algorithm</code> argument on the <code>Tuner</code> with additional configuration defined in <code>OptunaSpec</code>. For example, the <code>storage</code> argument allows you to save the optimisation results to a database or SQLite file. You can then use a tool like Optuna Dashboard to study the optimisation output in more detail.</p> <p>Tip</p> <p>You can impose arbitary constraints on variables within a <code>Process</code>. In your <code>step</code> method you can raise a <code>ConstraintError</code> to indicate to the <code>Tuner</code> that a constraint has been breached. This will cause the trial to be stopped, and the optimisation will continue trying to find parameters that don't cause the constraint violation.</p> <p>Tip</p> <p>You can optimise over process parameters if you have them in your model. Set <code>object_type=\"process\"</code> and <code>field_type=\"parameter\"</code> when specifying your tunable parameter.</p>","tags":["tutorial","optimisation"]},{"location":"examples/tutorials/tuning-a-process/#using-yaml-config","title":"Using YAML config","text":"<p>Plugboard's YAML config supports an optional <code>tune</code> section, allowing you to define optimisation jobs alongside your model configuration: <pre><code>plugboard:\n  process:  # (1)!\n    args:\n      components:\n      - type: hello_tuner.Iterator\n        args:\n          name: horizontal\n          iters: 100\n      - type: hello_tuner.Trajectory\n        args:\n          name: trajectory\n          angle: 25\n          velocity: 20\n      - type: hello_tuner.MaxHeight\n        args:\n          name: max-height\n      connectors:\n      - source: horizontal.x\n        target: trajectory.x\n      - source: trajectory.y\n        target: max-height.y\n  tune:  # (2)!\n    args:\n      objective:\n        object_name: max-height\n        field_type: field\n        field_name: max_y\n      parameters:\n      - type: ray.tune.uniform  # (3)!\n        object_type: component\n        object_name: trajectory\n        field_type: arg\n        field_name: angle\n        lower: 0\n        upper: 90\n      - type: ray.tune.uniform\n        object_type: component\n        object_name: trajectory\n        field_type: arg\n        field_name: velocity\n        lower: 0\n        upper: 100\n      num_samples: 40\n      mode: max\n      max_concurrent: 4\n</code></pre></p> <ol> <li>As usual, this section defines the <code>Process</code>. It can also be replaced by a path to another YAML file.</li> <li>This section is optional, and configures the <code>Tuner</code>.</li> <li>Parameters need to reference a type, so that Plugboard knows the type of parameter to build.</li> </ol> <p>Now run <code>plugboard process tune model-with-tuner.yaml</code> to execute the optimisation job from the CLI.</p>","tags":["tutorial","optimisation"]},{"location":"examples/tutorials/tuning-a-process/#advanced-usage-complex-search-spaces","title":"Advanced usage: complex search spaces","text":"<p>Occasionally you may need to define more complex search spaces, which go beyond what can be defined with a simple parameter configuration. For example:</p> <ul> <li>Conditional parameters, e.g. where parameter <code>a</code> must be greater than parameter <code>b</code>; or</li> <li>Looping, e.g. building up a list of tunable parameters that is of variable length.</li> </ul> <p>These conditional search space functions are supported by Ray Tune and can be defined as described in the Ray documentation. To use such a function you will need to:</p> <ol> <li>Setup the <code>Tuner</code>, defining your parameters as usual;</li> <li>Write a custom function to define the search space, where each tunable parameter has a name of the form <code>\"{component_name.field_or_arg_name}\"</code>; then</li> <li>Supply your custom function to the <code>OptunaSpec</code> algorithm configuration.</li> </ol> <p>For example, the following search space makes the velocity depend on the angle: <pre><code>def custom_space(trial: Trial) -&gt; dict[str, _t.Any] | None:\n    \"\"\"Defines a custom search space for Optuna.\"\"\"\n    angle = trial.suggest_int(\"trajectory.angle\", 0, 90)\n    # Make velocity depend on angle\n    trial.suggest_int(\"trajectory.velocity\", angle, 100)\n</code></pre></p> <p>Then use this configuration to point the  tuner to the <code>custom_space</code> function. <pre><code>plugboard:\n  process: model-with-tuner.yaml  # (1)!\n  tune:\n    args:\n      objective:\n        object_name: max-height\n        field_type: field\n        field_name: max_y\n      parameters:\n      - type: ray.tune.uniform\n        object_type: component\n        object_name: trajectory\n        field_type: arg\n        field_name: angle\n        lower: 0\n        upper: 90\n      - type: ray.tune.uniform\n        object_type: component\n        object_name: trajectory\n        field_type: arg\n        field_name: velocity\n        lower: 0\n        upper: 100\n      num_samples: 40\n      mode: max\n      max_concurrent: 4\n      algorithm:  # (2)!\n        type: ray.tune.search.optuna.OptunaSearch\n        space: hello_tuner.custom_space\n</code></pre></p> <ol> <li>We can reference a <code>Process</code> from another YAML file here to avoid repetition.</li> <li>Add the algorithm configuration here.</li> </ol> <p>Then run using <code>plugboard process tune model-with-tuner-custom.yaml</code>.</p>","tags":["tutorial","optimisation"]},{"location":"usage/configuration/","title":"Configuration","text":""},{"location":"usage/configuration/#main-configuration-options","title":"Main configuration options","text":"<p>Plugboard can either be configured via shell environment variables or using a <code>.env</code> file. Full details on the settings and feature flags can be found in <code>plugboard.utils.settings.Settings</code>.</p>"},{"location":"usage/configuration/#logging","title":"Logging","text":"<p>Logging can be configured via the following environment variables:</p> Option Name Description Default Value <code>PLUGBOARD_LOG_LEVEL</code> Sets the logging level (e.g., <code>DEBUG</code>, <code>INFO</code>, <code>ERROR</code>) <code>WARNING</code> <code>PLUGBOARD_LOG_STRUCTURED</code> Enables logging in JSON format. <code>PLUGBOARD_IO_READ_TIMEOUT</code> Time in seconds between periodic status checks during io reads 20.0 <p>Plugboard uses structlog as its logging library. For basic changes you can adjust the options above, but for more advanced configuration you may need to call <code>structlog.configure()</code> and set the options yourself.</p>"},{"location":"usage/configuration/#message-brokers","title":"Message brokers","text":"<p>Plugboard can make use of a message broker for data exchange between components in a distributed setting such as a Ray cluster. To allow components to connect to a broker, a connection string containing the broker url (and credentials if required) should be set in the the environment. Below are the recognised environment variables for the supported message brokers. In general, only one broker would be used per plugboard run.</p> Option Name Description Default Value <code>RABBITMQ_URL</code> URL for RabbitMQ AMQP message broker (must include credentials if required)"},{"location":"usage/configuration/#job-id","title":"Job ID","text":"<p>Each plugboard run has a unique job ID associated with it. This is used to: track state for each run; and separate data messages between runs when using a message broker. Typically, a run would be started without explicitly setting the job ID, in which case a unique job ID will be created automatically. However, there are instances when it may be desirable to specify the job ID, such as stopping a run and resuming the same run later with the existing persisted state. In these scenarios the job ID can be set with the below environment variable which will then be used by any <code>StateBackend</code>, <code>Process</code> and <code>Component</code> while the value is set.</p> Option Name Description Default Value <code>PLUGBOARD_JOB_ID</code> Unique job ID for plugboard runs to track state and message broker topics"},{"location":"usage/key-concepts/","title":"Key Concepts","text":"<p>If you enjoy learning by following examples, we recommend diving straight into the tutorials section. All of the tutorials and demos can be found in our Github repo.</p> <p>This section introduces some of the key concepts in Plugboard and how to apply them when building your own models.</p>"},{"location":"usage/key-concepts/#terminology","title":"Terminology","text":""},{"location":"usage/key-concepts/#components","title":"Components","text":"<p>The basic building blocks of Plugboard models are <code>Component</code> objects. Typical uses of components are:</p> <ul> <li>Loading data into and saving data out of models;</li> <li>Preparing data and/or running calculations;</li> <li>Modelling a particular physical entity, e.g. within a model of a factory production line, you might define separate components representing the conveyor belts, sensors and workstations;</li> <li>Making calls to external systems, e.g. fetching data from the internet, calling an LLM, spinning up a subprocess to run some third-party simulation software.</li> </ul> <p>When implementing your own components, you will need to:</p> <ul> <li>Subclass the base <code>Component</code>;</li> <li>Specify its inputs and ouputs using an <code>IOController</code>;</li> <li>Define a <code>step()</code> method the executes the main logic of your component for a single step; and</li> <li>Optionally define an <code>init()</code> method to do any required preparatory steps before the model in run.</li> <li>In the case of event based models, define custom <code>Event</code> subclasses and corresponding event handler methods decorated with <code>Event.handler</code>.</li> </ul>"},{"location":"usage/key-concepts/#connectors","title":"Connectors","text":"<p>Data flows between components via Connectors. You will need to use these to tell Plugboard how data should flow between your components. Your overall model might be very simple, for example:</p> <pre><code>graph LR;\n    A(Load input data)--&gt;B(Process data)--&gt;C(Save output data);</code></pre> <p>However Plugboard supports much more complex model structures, including looping and branching:</p> <pre><code>graph LR;\n    A(Load data)--&gt;B(Simulate process);\n    B(Simulate process)--&gt;C(Process controller);\n    C(Process controller)--&gt;B(Simulate process);\n    B(Simulate process)--&gt;D(Record output);\n    C(Process controller)--&gt;D(Record output);\n    A(Load data)--&gt;D(Record output);</code></pre> <p>For models with explicitly declared input and output fields, connectors for each input-output pair must be defined explicitly using one of the <code>Connector</code> implementations. Connectors required for any events used in the model will be created for you automatically. </p>"},{"location":"usage/key-concepts/#processes","title":"Processes","text":"<p>Components and connectors are collected together under a Process. This top-level class takes care of starting the model and running it until completion. Model execution is broken down into discrete steps. Running a model means executing all steps for each component until all of the available data has flowed through the model. The <code>step()</code> method advances the model forward by a single step. The <code>run()</code> method will repeatedly call <code>step()</code> until completion.</p> <p>Plugboard supports both bounded and unbounded data streams. That is to say, you can either run a model with a fixed size input data set until completion, or run a model indefinitely which will continuously process new inputs as they arrive until a shutdown signal is received.</p> <p>Plugboard uses Python's asynchronous concurrency to schedule execution of each of the components. Don't worry if asynchronous Python is unfamiliar to you: Plugboard takes care of all the details, so that you can focus on the logic of your model.</p> <p>These Process classes are currently available which can be extended with custom implementations:</p> <ul> <li><code>LocalProcess</code> runs models in a single Python process on your computer. This is useful for initial development, and is often sufficient for models are not computationally demanding.</li> <li><code>RayProcess</code> allows you to execute components on different Python processes using the Ray Framework. This supports parallel computation on a single machine and scales out to large-scale compute clusters.</li> </ul>"},{"location":"usage/key-concepts/#running-models","title":"Running models","text":"<p>Most models start out life in a Jupyter notebook or Python script. Later on in development you may choose to convert the Plugboard process definition to a YAML file. This allows you to:</p> <ul> <li>Separate your model code from its configuration;</li> <li>Run the model via Plugboard's CLI - see <code>plugboard process run --help</code> for details;</li> <li>Transfer your model to a cluster to take advantage of larger-scale computational resources.</li> </ul>"},{"location":"usage/topics/","title":"Topic index","text":"<p>To find information on a specific topic, you can look for pages under one of the tags below.</p>"},{"location":"usage/topics/#tag:events","title":"events","text":"<ul> <li>            Event-driven models          </li> <li>            Momentum trading          </li> </ul>"},{"location":"usage/topics/#tag:finance","title":"finance","text":"<ul> <li>            Momentum trading          </li> </ul>"},{"location":"usage/topics/#tag:io","title":"io","text":"<ul> <li>            More components          </li> <li>            Streaming data: processing a websocket feed          </li> </ul>"},{"location":"usage/topics/#tag:llm","title":"llm","text":"<ul> <li>            LLM for data filtering          </li> <li>            Local and Remote Image Processing          </li> <li>            More components          </li> <li>            Rock Paper Scissors          </li> <li>            Streaming data: processing a websocket feed          </li> </ul>"},{"location":"usage/topics/#tag:logging","title":"logging","text":"<ul> <li>            More components          </li> </ul>"},{"location":"usage/topics/#tag:optimisation","title":"optimisation","text":"<ul> <li>            Production line          </li> <li>            Production process optimisation          </li> <li>            Tuning a process          </li> </ul>"},{"location":"usage/topics/#tag:physics-models","title":"physics-models","text":"<ul> <li>            Hot water tank model          </li> </ul>"},{"location":"usage/topics/#tag:ray","title":"ray","text":"<ul> <li>            Running in parallel          </li> </ul>"},{"location":"usage/topics/#tag:streaming","title":"streaming","text":"<ul> <li>            Streaming data: processing a websocket feed          </li> </ul>"},{"location":"usage/topics/#tag:tutorial","title":"tutorial","text":"<ul> <li>            A more complex process          </li> <li>            Event-driven models          </li> <li>            Hello world          </li> <li>            More components          </li> <li>            Running in parallel          </li> <li>            Tuning a process          </li> </ul>"}]}